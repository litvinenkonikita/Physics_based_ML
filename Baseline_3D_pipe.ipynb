{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJkKJ83igGYb"
   },
   "source": [
    "# **Physics-based loss and machine learing approach in application to fluids flow modelling: 3D flow in a pipe**\n",
    "It is supposed that the Newtonian fluid flows through a cylindrical pipe with radius $R$. The flow is steady, the Reynolds number is smaller than the critical one $Re < Re^* {\\approx} 1100...1400$ and the pipe length is greater than the critical one $L_3 > 0.16RRe$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydwhZV95sFoN"
   },
   "source": [
    "# Initialization\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Go3JwW4hICsK"
   },
   "outputs": [],
   "source": [
    "# Pytorch modules\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import transforms\n",
    "import numpy as np\n",
    "\n",
    "# Python functions\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "from collections import OrderedDict\n",
    "#from scipy import integrate\n",
    "\n",
    "# Status bar\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Work with files and images\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os, fnmatch\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "#Log\n",
    "import neptune.new as neptune\n",
    "from neptune.new.types import File\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neptune project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = neptune.init(\n",
    "    project=\"avkornaev/PhysicsBasedDL\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJiMmRjMGY4Ny1hYTI1LTQxZmEtYjRmZC02YzNkYWZjYzNiNjIifQ==\",\n",
    ")  # your credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzMpruhsYD38"
   },
   "source": [
    "## Download and preprocess image of the flow domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzMpruhsYD38"
   },
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =  Path('/root/Physics_based_loss')\n",
    "imgPath = path/'ToyDataset'\n",
    "imgList = fnmatch.filter(os.listdir(imgPath), '*.pt') #imgPath.ls()\n",
    "imgList\n",
    "#Image number from the imgList\n",
    "imgNo = 0\n",
    "print(imgList, imgNo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download 3D image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.load(os.path.join(imgPath, imgList[imgNo]))\n",
    "imgDim = img.shape[1:]\n",
    "print(f'image shape: {imgDim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzMpruhsYD38"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YsKHT1J2Ibx9"
   },
   "outputs": [],
   "source": [
    "SIZE = imgDim\n",
    "#Training\n",
    "EPOCHS = 40000\n",
    "NoOfFeatures = 32 #32\n",
    "WORK_DIR = '/root/Physics_based_loss'\n",
    "IN_CH = 1 #number of input channels\n",
    "OUT_CH = 1#number of output channels\n",
    "#Loss regularization\n",
    "REG_LOSS_COEF = 1000000\n",
    "\n",
    "#SCALE_FACTOR = 1 # muliplier for the loss function\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_NAME = \"unet\"\n",
    "EARLY_STOP_PATIENCE = EPOCHS\n",
    "DECAY = 1e-4\n",
    "PATIENCE = 0\n",
    "\n",
    "parameters = {'image_size':SIZE,\n",
    "             'Epochs':EPOCHS,\n",
    "             'Model':MODEL_NAME,\n",
    "             'No_of_features':NoOfFeatures}\n",
    "\n",
    "HYPS = []\n",
    "\n",
    "hyps = {\"Epochs\":[EPOCHS],\n",
    "        \"learning_rate\": [1e-3],\n",
    "        \"scheduler\": [\"step\"],\n",
    "        \"scheduler_factor\": [0.5],\n",
    "        \"scheduler_patience\": [int(EPOCHS*0.05)],\n",
    "        \"use_bn\": [True],\n",
    "        \"Early_stop_patience\": [EARLY_STOP_PATIENCE],\n",
    "        \"Decay\": [DECAY]} # Use or not batchnorm\n",
    "    \n",
    "for i in product(*[hyps[j] for j in hyps]):\n",
    "    HYPS.append({a:b for a, b in zip(hyps, i)})\n",
    "#\"scheduler\": [\"None\", \"step\", \"cycle\"]\n",
    "#\"use_bn\": [True, False]\n",
    "\n",
    "#Visualization\n",
    "slices = [int(imgDim[0]/2), int(imgDim[1]/2), int(imgDim[2]/2)]\n",
    "vps = 10 #vector plot step \n",
    "FIGSIZE = 5 # figure size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run[\"config/parameters\"] = parameters\n",
    "run[\"config/hyperparameters\"] = hyps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORhTWZZvVw7c"
   },
   "source": [
    "## Geometry of the flow domain, fluid properties and boundary conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometry\n",
    "\n",
    "It is convenient to present the flow domain $\\Omega$ in the form of a parallelepiped $x_i^- < x_i < x_i^+$ ($\\boldsymbol{L} = [l_i] = [x_i^+ - x_i^-]$, $i = 1,2,3$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L_1 x L_2 x L_3 flow domain\n",
    "L = [0.012, 0.012, 0.5]#, [m]\n",
    "R = L[0]/2 #, [m]\n",
    "\n",
    "# Normalized coordinates, normalized finite diferences, limits and elementary volume\n",
    "X1N = torch.linspace(0, 1, SIZE[0])\n",
    "X2N = torch.linspace(0, 1, SIZE[1])\n",
    "X3N = torch.linspace(0, 1, SIZE[2])\n",
    "\n",
    "DX1N = X1N[1] - X1N[0]\n",
    "DX2N = X2N[1] - X2N[0]\n",
    "DX3N = X3N[1] - X3N[0]\n",
    "\n",
    "LIM1 = [0, L[0]]\n",
    "LIM2 = [0, L[1]]\n",
    "LIM3 = [0, L[2]]\n",
    "\n",
    "dOmega = DX1N * DX2N * DX3N * L[0] * L[1] * L[2] # elementary volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boundary conditions\n",
    "1. The values of the flow rates $Q_i(x_i^-)$, $Q_i(x_i^+)$ through the edges $x_i = x_i^-$, $x_i = x_i^+$ of the flow domain are given:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flow rates Q1-,Q2-,Q3-\n",
    "Qm = [0, 0, -2E-5]\n",
    "\n",
    "#Flow rates Q1+,Q2+,Q3+\n",
    "Qp = [0, 0, 2E-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. NL layers have fixed values of the unknown function $\\boldsymbol\\Psi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DVTEMP = 'sc' #template for the velocity function differentiation\n",
    "if  DVTEMP == 'sc':\n",
    "    NL = 3\n",
    "elif DVTEMP == 'fc':\n",
    "    NL = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Properties of non-Newtonian fluid and walls that are relatively rigid body.\n",
    "The Herschel-Bulkley law is applied:\n",
    "\\begin{equation}\n",
    "    \\mu(H)=q_0+q_1H^{z-1},\n",
    "\\end{equation}\n",
    "where $q_0$, $q_1$, $z$ are the parameters obtained from rheological tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Newtonian fluid viscosity\n",
    "Q0 = 1e-3\n",
    "Q1 = 0\n",
    "Z = 1\n",
    "# Fluid density, kg/m**3\n",
    "RHO = 1000\n",
    "#Newtonian fluid analogue\n",
    "MU = Q0\n",
    "\n",
    "#Critical Reynolds number\n",
    "Re_cr = 1100\n",
    "\n",
    "#Walls viscosity\n",
    "Q0W = 1e+3#1e-0#1e+3eye \n",
    "Q1W = 0#1e-0\n",
    "ZW =1#0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hw2AD3oWsfJb"
   },
   "source": [
    "## Additional functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JAf1YAHtV15"
   },
   "source": [
    "3D numerical derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_diff(f,dx1,dx2,dx3,template='sc'):\n",
    "    '''The following templates are applied:\n",
    "    sc - second-order central difference,\n",
    "    fc - fifth-order central difference.\n",
    "    Indexing:\n",
    "    i - index along x_1,\n",
    "    j - index along x_2,\n",
    "    k - index along x_3.\n",
    "    '''\n",
    "    #Shape\n",
    "    n1, n2, n3 = f.shape\n",
    "    \n",
    "    df_dx1, df_dx2, df_dx3 = torch.zeros(n1, n2, n3), torch.zeros(n1, n2, n3), torch.zeros(n1, n2, n3)\n",
    "    \n",
    "    #Device\n",
    "    if torch.cuda.is_available():\n",
    "        df_dx1 = df_dx1.to('cuda')\n",
    "        df_dx2 = df_dx2.to('cuda')\n",
    "        df_dx3 = df_dx3.to('cuda')\n",
    "    \n",
    "    #Derivatives\n",
    "    if template == 'sc':\n",
    "        # x1 derivative:\n",
    "        df_dx1[1:n1-1,:,:] = (f[2:,:,:] - f[:-2,:,:]) / (2 * dx1)\n",
    "        df_dx1[0,:,:] = (-f[2,:,:] + 4 * f[1,:,:] - 3 * f[0,:,:]) / (2 * dx1)\n",
    "        df_dx1[n1-1,:,:] = (3 * f[n1-1,:,:] - 4 * f[n1-2,:,:] + f[n1-3,:,:]) / (2 * dx1)\n",
    "        # x2 derivative:\n",
    "        df_dx2[:,1:n2-1, :] = (f[:, 2:, :] - f[:, :-2, :]) / (2 * dx2)\n",
    "        df_dx2[:,0, :] = (- f[:,2,:] + 4 * f[:,1,:] - 3 * f[:, 0, :]) / (2 * dx2)\n",
    "        df_dx2[:,n2-1, :] = (3 * f[:, n2 - 1, :] - 4 * f[:, n2 - 2, :] + f[:, n2 - 3, :]) / (2 * dx2)\n",
    "        # x3 derivative:\n",
    "        df_dx3[:, :, 1:n3-1] = (f[:,:,2:] - f[:,:,:-2]) / (2 * dx3)\n",
    "        df_dx3[:, :, 0] = (- f[:, :, 2] + 4 * f[:, :, 1] - 3 * f[:, :, 0]) / (2 * dx3)\n",
    "        df_dx3[:, :, n3-1] = (3 * f[:, :, n3 - 1] - 4 * f[:, :, n3 - 2] + f[:, :, n3 - 3]) / (2 * dx3)\n",
    "    elif template == 'fc':\n",
    "        # x1 derivative\n",
    "        df_dx1[2:n1-2, :, :] = (-f[4:, :,:] + 8 * f[3:n1-1, :, :] - 8 * f[1:n1-3, :, :] + f[:n1-4, :, :]) / (12 * dx1)\n",
    "        df_dx1[0, :, :] = (-3 * f[4, :, :] + 16 * f[3, :, :] - 36 * f[2, :, :] + 48 * f[1, :,:] - 25 * f[0, :, :]) / (12 * dx1)\n",
    "        df_dx1[1, :, :] = (f[4, :, :] - 6 * f[3, :, :] + 18 * f[2, :, :] - 10 * f[1, :, :] - 3 * f[0, :, :]) / (12 * dx1)\n",
    "        df_dx1[n1-2, :, :] = (3 * f[n1-1, :, :] + 10 * f[n1-2, :, :] - 18 * f[n1-3, :, :] + 6 * f[n1-4, :, :] - f[n1-5, :, :]) / (12 * dx1)\n",
    "        df_dx1[n1-1, :, :] = (25 * f[n1-1, :, :] - 48 * f[n1-2, :, :] + 36 * f[n1-3, :, :] - 16 * f[n1-4, :, :] + 3*f[n1-5, :, :]) / (12 * dx1)\n",
    "        \n",
    "        # x2 derivative\n",
    "        df_dx2[:, 2:n2-2, :] = (-f[:, 4:, :] + 8 * f[:, 3:n2-1, :] - 8 * f[:, 1:n2-3, :] + f[:, :n2-4, :]) / (12 * dx2)\n",
    "        df_dx2[:, 0, :] = (-3 * f[:,4, :] + 16 * f[:, 3, :] - 36 * f[:, 2, :] + 48 * f[:, 1, :] - 25 * f[:, 0, :]) / (12*dx2)\n",
    "        df_dx2[:, 1, :] = (f[:, 4, :] - 6 * f[:, 3, :] + 18 * f[:, 2, :] - 10 * f[:, 1, :] - 3 * f[:, 0, :]) / (12*dx2)\n",
    "        df_dx2[:, n2-2, :] = (3 * f[:, n2-1, :] + 10 * f[:, n2-2, :] - 18 * f[:, n2-3, :] + 6 * f[:, n2-4, :] - f[:, n2-5, :]) / (12*dx2)\n",
    "        df_dx2[:, n2-1, :] = (25 * f[:, n2-1, :] - 48 * f[:, n2-2, :] + 36 * f[:, n2-3, :] - 16 * f[:, n2-4, :] + 3 * f[:,n2-5, :]) / (12*dx2)       \n",
    "        # x3 derivative\n",
    "        df_dx3[:, :, 2:n3-2] = (-f[:, :, 4:] + 8 * f[:, :, 3:n3-1] - 8 * f[:, :, 1:n3-3] + f[:, :, :n3-4]) / (12 * dx3)\n",
    "        df_dx3[:, :, 0] = (-3 * f[:, :, 4] + 16 * f[:, :, 3] - 36 * f[:, :, 2] + 48 * f[:, :, 1] - 25 * f[:, :, 0]) / (12 * dx3)\n",
    "        df_dx3[:, :, 1] = (f[:, :, 4] - 6 * f[:, :, 3] + 18 * f[:, :, 2] - 10 * f[:, :, 1] - 3 * f[:, :, 0]) / (12 * dx3)\n",
    "        df_dx3[:, :, n3-2] = (3 * f[:, :, n3-1] + 10 * f[:, :, n3-2] - 18 * f[:, :, n3-3] + 6 * f[:,:,n3-4] - f[:, :, n3-5]) / (12 * dx3)\n",
    "        df_dx3[:, :, n3-1] = (25 * f[:,:, n3-1] - 48 * f[:,:, n3-2] + 36 * f[:,:, n3-3] - 16 * f[:,:, n3-4] + 3*f[:,:, n3-5]) / (12 * dx3)\n",
    "    \n",
    "    return df_dx1, df_dx2, df_dx3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D numerical derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_diff2D(f,dx1,dx2,template=DVTEMP):\n",
    "    '''The following templates are applied:\n",
    "    sc - second-order central difference,\n",
    "    fc - fifth-order central difference.\n",
    "    Indexing:\n",
    "    i - index along x_1,\n",
    "    j - index along x_2.\n",
    "    '''\n",
    "    #Shape\n",
    "    n1, n2 = f.shape\n",
    "    \n",
    "    df_dx1, df_dx2 = torch.zeros(n1, n2), torch.zeros(n1, n2)\n",
    "    \n",
    "    #Device\n",
    "    if torch.cuda.is_available():\n",
    "        df_dx1 = df_dx1.to('cuda')\n",
    "        df_dx2 = df_dx2.to('cuda')\n",
    "            \n",
    "    #Derivatives\n",
    "    if template == 'sc':\n",
    "        # x1 derivative:\n",
    "        df_dx1[1:n1-1,:] = (f[2:,:] - f[:-2,:]) / (2 * dx1)\n",
    "        df_dx1[0,:] = (-f[2,:] + 4 * f[1,:] - 3 * f[0,:]) / (2 * dx1)\n",
    "        df_dx1[n1-1,:] = (3 * f[n1-1,:] - 4 * f[n1-2,:] + f[n1-3,:]) / (2 * dx1)\n",
    "        # x2 derivative:\n",
    "        df_dx2[:,1:n2-1] = (f[:, 2:] - f[:, :-2]) / (2 * dx2)\n",
    "        df_dx2[:,0] = (- f[:,2] + 4 * f[:,1] - 3 * f[:, 0]) / (2 * dx2)\n",
    "        df_dx2[:,n2-1] = (3 * f[:, n2 - 1] - 4 * f[:, n2 - 2] + f[:, n2 - 3]) / (2 * dx2)\n",
    "    elif template == 'fc':\n",
    "        # 1st order x1 derivative:\n",
    "        # x1 derivative\n",
    "        df_dx1[2:n1-2, :] = (-f[4:, :] + 8 * f[3:n1-1, :] - 8 * f[1:n1-3, :] + f[:n1-4, :]) / (12 * dx1)\n",
    "        df_dx1[0, :] = (-3 * f[4, :] + 16 * f[3, :] - 36 * f[2, :] + 48 * f[1, :] - 25 * f[0, :]) / (12 * dx1)\n",
    "        df_dx1[1, :] = (f[4, :] - 6 * f[3, :] + 18 * f[2, :] - 10 * f[1, :] - 3 * f[0, :]) / (12 * dx1)\n",
    "        df_dx1[n1-2, :] = (3 * f[n1-1, :] + 10 * f[n1-2, :] - 18 * f[n1-3, :] + 6 * f[n1-4, :] - f[n1-5, :]) / (12 * dx1)\n",
    "        df_dx1[n1-1, :] = (25 * f[n1-1, :] - 48 * f[n1-2, :] + 36 * f[n1-3, :] - 16 * f[n1-4, :] + 3*f[n1-5, :]) / (12 * dx1)\n",
    "        \n",
    "        # x2 derivative\n",
    "        df_dx2[:, 2:n2-2] = (-f[:, 4:] + 8 * f[:, 3:n2-1] - 8 * f[:, 1:n2-3] + f[:, :n2-4]) / (12 * dx2)\n",
    "        df_dx2[:, 0] = (-3 * f[:,4] + 16 * f[:, 3] - 36 * f[:, 2] + 48 * f[:, 1] - 25 * f[:, 0]) / (12*dx2)\n",
    "        df_dx2[:, 1] = (f[:, 4] - 6 * f[:, 3] + 18 * f[:, 2] - 10 * f[:, 1] - 3 * f[:, 0]) / (12*dx2)\n",
    "        df_dx2[:, n2-2] = (3 * f[:, n2-1] + 10 * f[:, n2-2] - 18 * f[:, n2-3] + 6 * f[:, n2-4] - f[:, n2-5]) / (12*dx2)\n",
    "        df_dx2[:, n2-1] = (25 * f[:, n2-1] - 48 * f[:, n2-2] + 36 * f[:, n2-3] - 16 * f[:, n2-4] + 3 * f[:,n2-5]) / (12*dx2)    \n",
    "    \n",
    "    return df_dx1, df_dx2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D numerical integration (Simpson method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_func_simpson_3d(f, dx, dy, dz):\n",
    "  '''\n",
    "  f - 3d-dimentional tensor\n",
    "  dx, dy, dz - constant step along the corresponding coordinate\n",
    "  '''\n",
    "  n1,n2,n3 = f.shape\n",
    "  # integrate by dz:\n",
    "  if n3%2 == 0:\n",
    "    J3 = (f[:,:,0:n3-2:2] + 4*f[:,:,1:n3-2:2] + f[:,:,2::2]).sum(dim=2)*dz/3 + (f[:,:,-1]+f[:,:,-2])*dz/2\n",
    "  else:\n",
    "    J3 = (f[:,:,0:n3-1:2] + 4*f[:,:,1:n3-1:2] + f[:,:,2::2]).sum(dim=2)*dz/3\n",
    "\n",
    "  # integrate by dy:\n",
    "  if n2%2 == 0:\n",
    "    J2 = (J3[:,0:n2-2:2] + 4*J3[:,1:n2-2:2] + J3[:,2::2]).sum(dim=1)*dy/3 + (J3[:,-1]+J3[:,-2])*dy/2\n",
    "  else:\n",
    "    J2 = (J3[:,0:n2-1:2] +4 *J3[:,1:n2-1:2] + J3[:,2::2]).sum(dim=1)*dy/3\n",
    "\n",
    "  # integrate by dx:\n",
    "  if n1%2 == 0:\n",
    "    J1 = (J2[0:n1-2:2] + 4*J2[1:n1-2:2] + J2[2::2]).sum(dim=0)*dx/3 + (J2[-1]+J2[-2])*dx/2\n",
    "  else:\n",
    "    J1 = (J2[0:n1-1:2] + 4*J2[1:n1-1:2] + J2[2::2]).sum(dim=0)*dx/3\n",
    "\n",
    "  return J1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D numerical integration (Simpson method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_func_simpson_2d(f, dx, dy):\n",
    "  '''\n",
    "  f - 2d-dimentional tensor\n",
    "  dx, dy - constant step along the corresponding coordinate\n",
    "  '''\n",
    "  n1, n2 = f.shape\n",
    "  # integrate by dy:\n",
    "  if n2%2 == 0:\n",
    "    J2 = (f[:,0:n2-2:2]+ 4*f[:,1:n2-2:2] + f[:,2::2]).sum(dim=1)*dy/3 + (f[:,-1]+f[:,-2])*dy/2\n",
    "  else:\n",
    "    J2 = (f[:,0:n2-1:2] +4*f[:,1:n2-1:2]+f[:,2::2]).sum(dim=1)*dy/3\n",
    "  # integrate by dx:\n",
    "  if n1%2 == 0:\n",
    "    J1 = (J2[0:n1-2:2]+ 4*J2[1:n1-2:2] + J2[2::2]).sum(dim=0)*dx/3 + (J2[-1]+J2[-2])*dx/2\n",
    "  else:\n",
    "    J1 = (J2[0:n1-1:2] +4*J2[1:n1-1:2]+J2[2::2]).sum(dim=0)*dx/3\n",
    "  return J1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_plot(x, y, u, v, FIGSIZE, vptitle='vector_plot', xlabel='$x_i$', ylabel='$x_j$',step=10):\n",
    "    gradmag = np.sqrt(u**2 + v**2)\n",
    "    plt.pcolor(x, y, gradmag, cmap='rainbow')\n",
    "    plt.colorbar()\n",
    "    plt.quiver(x[::step,::step], y[::step,::step], u[::step,::step], v[::step,::step])\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(vptitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flowVisualization(psi,step=15,slices=slices):\n",
    "    nr=2\n",
    "    nc=len(SIZE)\n",
    "    \n",
    "    #Velocity distribution\n",
    "    v1, v2, v3 = velocityDistr(psi[0,0,:,:].to('cpu'), psi[0,1,:,:].to('cpu'), psi[0,2,:,:].to('cpu'),\n",
    "                               DX1N.to('cpu'), DX2N.to('cpu'), DX3N.to('cpu'),\n",
    "                               L[0], L[1], L[2])\n",
    "    V = torch.stack([v1.to('cpu'),v2.to('cpu'),v3.to('cpu')])\n",
    "    \n",
    "    print('Psi function Visualization')\n",
    "    fig = plt.figure(figsize=(FIGSIZE*nc, FIGSIZE*nr))\n",
    "    for i in range(len(SIZE)):\n",
    "        plt.subplot(nr,nc,i+1)\n",
    "        plt.imshow(psi[0,i,::].to('cpu'))\n",
    "        plt.title(f'$\\psi_{i+1}$')\n",
    "        plt.subplot(nr,nc,i+1+nc)\n",
    "        plt.plot(psi[0,i,:,slices[i]].to('cpu'))\n",
    "        plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'Q1+ = {- (psi[0,1,-1,-1] - psi[0,1,-1,0])*L[1] + (psi[0,2,-1,-1] - psi[0,2,-1,0])*L[2]}, target value: {Qp[0]},')\n",
    "    print(f'Q2+ = {- (psi[0,2,-1,-1] - psi[0,2,0,-1])*L[2] + (psi[0,0,-1,-1] - psi[0,0,-1,0])*L[0]}, target value: {Qp[1]},')\n",
    "    print(f'Q3+ = {- (psi[0,0,-1,-1] - psi[0,0,0,-1])*L[0] + (psi[0,1,-1,-1] - psi[0,1,0,-1])*L[1]}, target value: {Qp[2]}')\n",
    "    \n",
    "    print()\n",
    "    print('Velocity distribution visualization without flow domain mask (first line) and with mask (second line)')\n",
    "\n",
    "    XN = torch.meshgrid(X1N,X2N,X3N)\n",
    "    \n",
    "    fig1 = plt.figure(figsize=(FIGSIZE*nc, FIGSIZE*nr))\n",
    "    #without flow domain mask \n",
    "    plt.subplot(nr,nc,1)\n",
    "    vector_plot(XN[1][0,:,:], XN[2][0,:,:], V[1,slices[0],:,:], V[2,slices[0],:,:],\n",
    "                FIGSIZE, vptitle='$x_1 = const$', xlabel='$x_3$', ylabel='$x_2$', step=step)\n",
    "    plt.subplot(nr,nc,2)\n",
    "    vector_plot(XN[0][:,0,:], XN[2][:,0,:], V[0,:,slices[1],:], V[2,:,slices[1],:],\n",
    "                FIGSIZE, vptitle='$x_2 = const$', xlabel='$x_3$', ylabel='$x_1$', step=step)\n",
    "    plt.subplot(nr,nc,3)\n",
    "    vector_plot(XN[0][:,:,0], XN[1][:,:,0], V[0,:,:,slices[2]], V[1,:,:,slices[2]],\n",
    "                FIGSIZE, vptitle='$x_3 = const$', xlabel='$x_2$', ylabel='$x_1$', step=step)\n",
    "    #with flow domain mask \n",
    "    plt.subplot(nr,nc,4)\n",
    "    vector_plot(XN[1][0,:,:], XN[2][0,:,:], V[1,slices[0],:,:]*img[0,slices[0],:,:].to('cpu'), V[2,slices[0],:,:]*img[0,slices[0],:,:].to('cpu'),\n",
    "                FIGSIZE, vptitle='$x_1 = const$', xlabel='$x_3$', ylabel='$x_2$', step=step)\n",
    "    plt.subplot(nr,nc,5)\n",
    "    vector_plot(XN[0][:,0,:], XN[2][:,0,:], V[0,:,slices[1],:]*img[0,:,slices[1],:].to('cpu'), V[2,:,slices[1],:]*img[0,:,slices[1],:].to('cpu'),\n",
    "                FIGSIZE, vptitle='$x_2 = const$', xlabel='$x_3$', ylabel='$x_1$', step=step)\n",
    "    plt.subplot(nr,nc,6)\n",
    "    vector_plot(XN[0][:,:,0], XN[1][:,:,0], V[0,:,:,slices[2]]*img[0,:,:,slices[2]].to('cpu'), V[1,:,:,slices[2]]*img[0,:,:,slices[2]].to('cpu'),\n",
    "                FIGSIZE, vptitle='$x_3 = const$', xlabel='$x_2$', ylabel='$x_1$', step=step)\n",
    "    \n",
    "    #Check the flow rates Q3-,Q3+\n",
    "    Q1mch = int_func_simpson_2d(V[0, 0, :, :], L[1]*DX2N.to('cpu'), L[2]*DX3N.to('cpu'))\n",
    "    Q1pch = int_func_simpson_2d(V[0,-1, :, :], L[1]*DX2N.to('cpu'), L[2]*DX3N.to('cpu'))\n",
    "    \n",
    "    Q2mch = int_func_simpson_2d(V[1, :, 0, :], L[0]*DX1N.to('cpu'), L[2]*DX3N.to('cpu'))\n",
    "    Q2pch = int_func_simpson_2d(V[1, :,-1, :], L[0]*DX1N.to('cpu'), L[2]*DX3N.to('cpu'))\n",
    "    \n",
    "    Q3mch = int_func_simpson_2d(V[2, :, :, 0], L[0]*DX1N.to('cpu'), L[1]*DX2N.to('cpu'))\n",
    "    Q3pch = int_func_simpson_2d(V[2, :, :,-1], L[0]*DX1N.to('cpu'), L[1]*DX2N.to('cpu'))\n",
    "    \n",
    "    print(f'{V[0].min()} < v_1 < {V[0].max()},')\n",
    "    print(f'{V[1].min()} < v_2 < {V[1].max()},')\n",
    "    print(f'{V[2].min()} < v_3 < {V[2].max()},')\n",
    "    print(f'Q1- = {Q1mch}, Q1+ = {Q1pch}')\n",
    "    print(f'Q2- = {Q2mch}, Q2+ = {Q2pch}')\n",
    "    print(f'Q3- = {Q3mch}, Q3+ = {Q3pch}')\n",
    "  \n",
    "    return    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mH8zURs8A1Sr"
   },
   "source": [
    "## Major functions\n",
    "\n",
    "For any given function $\\boldsymbol\\Psi = [\\psi_i]$ that has fixed values on the boundaries of the flow domain together with its first, second, and third derivatives, the velocity distribution can be expressed in compact or in expanded form, respectively:\n",
    "\\begin{equation} \n",
    "    \\boldsymbol{V} = \n",
    "    \\begin{bmatrix}\n",
    "    \\epsilon_{ijk}\n",
    "    \\frac{\\partial \\psi_k(x_i,x_j)}{\\partial x_j}\n",
    "    \\end{bmatrix},\n",
    "\\end{equation}\n",
    "where $\\epsilon_{ijk}$ is the Levi-Civita symbol,\n",
    "\n",
    "\\begin{equation} \n",
    "    \\boldsymbol{V} = \n",
    "    \\begin{bmatrix}\n",
    "    \\frac{\\partial \\psi_3}{\\partial x_2} - \\frac{\\partial \\psi_2}{\\partial x_3}, &\n",
    "    \\frac{\\partial \\psi_1}{\\partial x_3} - \\frac{\\partial \\psi_3}{\\partial x_1}, &\n",
    "    \\frac{\\partial \\psi_2}{\\partial x_1} - \\frac{\\partial \\psi_1}{\\partial x_2}\n",
    "    \\end{bmatrix}.\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMUIipgs5t3Q"
   },
   "outputs": [],
   "source": [
    "def velocityDistr(psi1,psi2,psi3,dx1n,dx2n,dx3n,deltax1,deltax2,deltax3):\n",
    "    '''Velocity distribution [v_i] in the flow domain\n",
    "    '''\n",
    "    \n",
    "    #Psi function and it's partial derivatives are 2D functions\n",
    "    dpsi1dx2, dpsi1dx3 = num_diff2D(psi1, dx2n, dx3n)\n",
    "    dpsi2dx1, dpsi2dx3 = num_diff2D(psi2, dx1n, dx3n)\n",
    "    dpsi3dx1, dpsi3dx2 = num_diff2D(psi3, dx1n, dx2n)\n",
    "    \n",
    "    #Expand into 3D, then calculate the velocity distribution\n",
    "    dpsi1dx2 = torch.unsqueeze(dpsi1dx2,0)\n",
    "    dpsi1dx3 = torch.unsqueeze(dpsi1dx3,0)\n",
    "    \n",
    "    dpsi2dx1 = torch.unsqueeze(dpsi2dx1,1)\n",
    "    dpsi2dx3 = torch.unsqueeze(dpsi2dx3,1)\n",
    "    \n",
    "    dpsi3dx1 = torch.unsqueeze(dpsi3dx1,2)\n",
    "    dpsi3dx2 = torch.unsqueeze(dpsi3dx2,2)\n",
    "    \n",
    "    v1 = (dpsi3dx2.expand(-1,-1,SIZE[2]) / deltax2) - (dpsi2dx3.expand(-1,SIZE[1],-1) / deltax3)\n",
    "    v2 = (dpsi1dx3.expand(SIZE[0],-1,-1) / deltax3) - (dpsi3dx1.expand(-1,-1,SIZE[2]) / deltax1)\n",
    "    v3 = (dpsi2dx1.expand(-1,SIZE[1],-1) / deltax1) - (dpsi1dx2.expand(SIZE[0],-1,-1) / deltax2)\n",
    "    \n",
    "    return v1, v2, v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking into account the symmetry of the shear rate tensor $\\xi_{i,j}=\\xi_{i,j}$, the tensor has the following form:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\boldsymbol{T}_\\xi= \\frac{1}{2}   \n",
    "    \\begin{bmatrix}\n",
    "    2\\frac{\\partial v_1}{\\partial x_1}, & \\frac{\\partial v_1}{\\partial x_2} - \\frac{\\partial v_2}{\\partial x_1}, & \\frac{\\partial v_1}{\\partial x_3} - \\frac{\\partial v_3}{\\partial x_1} \\\\\n",
    "     \\frac{\\partial v_1}{\\partial x_2} - \\frac{\\partial v_2}{\\partial x_1}, & 2\\frac{\\partial v_2}{\\partial x_2}, & \\frac{\\partial v_2}{\\partial x_3} - \\frac{\\partial v_3}{\\partial x_2}  \\\\\n",
    "    \\frac{\\partial v_1}{\\partial x_3} - \\frac{\\partial v_3}{\\partial x_1}, & \\frac{\\partial v_2}{\\partial x_3} - \\frac{\\partial v_3}{\\partial x_2},  & 2\\frac{\\partial v_3}{\\partial x_3}  \\\\\n",
    "    \\end{bmatrix}.\n",
    "\\end{equation}\n",
    "\n",
    "In the general case of a three dimensional flow the shear strain rate intensity $H$ depends on all the components of the shear rate tensor:\n",
    "\\begin{equation}\n",
    "    H =\\sqrt{2(\\xi_{11}^2 + \\xi_{22}^2 + \\xi_{33}^2 + 2\\xi_{12}^2 + 2\\xi_{13}^2 + 2\\xi_{23}^2)}. \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "716qlRJoNglx"
   },
   "outputs": [],
   "source": [
    "def TksiDistr(v1,v2,v3,dx1n,dx2n,dx3n,deltax1,deltax2,deltax3):\n",
    "    '''Strain rate tensor Txi and the shear rate intensity Eta squared\n",
    "    '''    \n",
    "    \n",
    "    dv1dx1, dv1dx2, dv1dx3 = num_diff(v1, dx1n, dx2n, dx3n)\n",
    "    dv2dx1, dv2dx2, dv2dx3 = num_diff(v2, dx1n, dx2n, dx3n)\n",
    "    dv3dx1, dv3dx2, dv3dx3 = num_diff(v3, dx1n, dx2n, dx3n)\n",
    "    \n",
    "    #Txi\n",
    "    xi11 = dv1dx1 / deltax1\n",
    "    xi12 = 0.5 * ((dv1dx2 / deltax2) + (dv2dx1 / deltax1))\n",
    "    xi13 = 0.5 * ((dv1dx3 / deltax3) + (dv3dx1 / deltax1))\n",
    "    \n",
    "    xi22 = dv2dx2 / deltax2\n",
    "    xi23 = 0.5 * ((dv2dx3 / deltax3) + (dv3dx2 / deltax2))\n",
    "    \n",
    "    xi33 = dv3dx3 / deltax3\n",
    "    \n",
    "    #Eta^2    \n",
    "    EtaEta = (2 * (xi11 * xi11 + xi22 * xi22 + xi33 * xi33 + \n",
    "                   2 * (xi12 * xi12 + xi13 * xi13 + xi23 * xi23)))\n",
    "  \n",
    "    return xi11, xi12, xi13, xi22, xi23, xi33, EtaEta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divVel(v1,v2,v3,dx1n,dx2n,dx3n,deltax1,deltax2,deltax3):\n",
    "    \n",
    "    dv1dx1, dv1dx2, dv1dx3 = num_diff(v1, dx1n, dx2n, dx3n)\n",
    "    dv2dx1, dv2dx2, dv2dx3 = num_diff(v2, dx1n, dx2n, dx3n)\n",
    "    dv3dx1, dv3dx2, dv3dx3 = num_diff(v3, dx1n, dx2n, dx3n)\n",
    "    \n",
    "    divV = dv1dx1 + dv2dx2 + dv3dx3\n",
    "    \n",
    "    return dv1dx1, dv2dx2, dv3dx3, divV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStop():\n",
    "    \"\"\"Callback for early stop train process.\n",
    "    \n",
    "    Args:\n",
    "        monitor (str): value for monitoring.\n",
    "        patience (int): Number of epochs with no improvement after which training will be stopped.\n",
    "        mode (str): One of {\"min\", \"max\"}. In min mode, training will stop when the quantity monitored has stopped decreasing.\n",
    "            In \"max\" mode it will stop when the quantity monitored has stopped increasing.\n",
    "    \n",
    "    Attributes:\n",
    "        history (dict): Dict of lists with train history. Key \"monitor\" contains list of monitoring values. \n",
    "        steps (int): Number of passed epoches. \n",
    "        best_step (int): Number of best epoch. \n",
    "        best_monitor (float): Best of monitoring value.\n",
    "        model (Model): Training model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, monitor, patience, mode):\n",
    "        self.monitor = monitor\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.history = None\n",
    "        self.steps = -1\n",
    "        self.best_step = -1\n",
    "        if self.mode == 'max':\n",
    "            self.best_monitor = 0\n",
    "        elif self.mode == 'min':\n",
    "            self.best_monitor = 1e99999\n",
    "            \n",
    "    def start(self, history, model):\n",
    "        \"\"\"Start and init callback.\n",
    "        \n",
    "        Args:\n",
    "            history (dict): Dict of lists with train history. Key \"monitor\" contains list of monitoring values. \n",
    "            model (Model): Training model.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.history = history\n",
    "        self.model = model\n",
    "        \n",
    "    def step(self):\n",
    "        \"\"\"Make a step of callback.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (event, stop):\n",
    "                event (str): Decription of event. If event not did not happen then event = ''.\n",
    "                stop (bool): Flag of stopping train process.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.steps += 1\n",
    "        \n",
    "        if self.mode == 'max':\n",
    "            if self.history[self.monitor][-1] > self.best_monitor:\n",
    "                self.best_monitor = self.history[self.monitor][-1]\n",
    "                self.best_step = self.steps\n",
    "        elif self.mode == 'min':\n",
    "            if self.history[self.monitor][-1] < self.best_monitor:\n",
    "                self.best_monitor = self.history[self.monitor][-1]\n",
    "                self.best_step = self.steps\n",
    "        \n",
    "        if self.steps - self.best_step > self.patience:\n",
    "            return 'Early stop with {}: {:.4f}'.format(self.monitor, self.history[self.monitor][self.best_step]), True\n",
    "        return None, False\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"Delete model from callback.\"\"\"\n",
    "        \n",
    "        self.model = None\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "class SaveBest():\n",
    "    \"\"\"Callback for save model if there is an improvement.\n",
    "    \n",
    "    Args:\n",
    "        monitor (str): value for monitoring.\n",
    "        model_path (str): Path for saving model.\n",
    "        mode (str): One of {\"min\", \"max\"}. In min mode, training will stop when the quantity monitored has stopped decreasing.\n",
    "            In \"max\" mode it will stop when the quantity monitored has stopped increasing.\n",
    "    \n",
    "    Attributes:\n",
    "        history (dict): Dict of lists with train history. Key \"monitor\" contains list of monitoring values. \n",
    "        steps (int): Number of passed epoches. \n",
    "        best_step (int): Number of best epoch. \n",
    "        best_monitor (float): Best of monitoring value.\n",
    "        model (Model): Training model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, monitor, model_path, mode):\n",
    "        self.monitor = monitor\n",
    "        self.model_path = model_path\n",
    "        self.mode = mode\n",
    "        self.history = None\n",
    "        self.steps = -1\n",
    "        self.best_step = -1\n",
    "        if self.mode == 'max':\n",
    "            self.best_monitor = 0\n",
    "        elif self.mode == 'min':\n",
    "            self.best_monitor = 1e99999\n",
    "    \n",
    "    def start(self, history, model):\n",
    "        \"\"\"Start and init callback. Save first version of model.\n",
    "        \n",
    "        Args:\n",
    "            history (dict): Dict of lists with train history. Key \"monitor\" contains list of monitoring values. \n",
    "            model (Model): Training model\n",
    "        \"\"\"\n",
    "        \n",
    "        self.history = history\n",
    "        self.model = model\n",
    "        torch.save(self.model.state_dict(), self.model_path)\n",
    "    \n",
    "    def step(self):\n",
    "        \"\"\"Make a step of callback.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (event, stop):\n",
    "                event (str): Decription of event. If event not did not happen then event = ''.\n",
    "                stop (bool): Flag of stopping train process.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.steps += 1\n",
    "        \n",
    "        if self.mode == 'max':\n",
    "            if self.history[self.monitor][-1] > self.best_monitor:\n",
    "                self.best_monitor = self.history[self.monitor][-1]\n",
    "                self.best_step = self.steps\n",
    "        elif self.mode == 'min':\n",
    "            if self.history[self.monitor][-1] < self.best_monitor:\n",
    "                self.best_monitor = self.history[self.monitor][-1]\n",
    "                self.best_step = self.steps\n",
    "        \n",
    "        if self.steps == self.best_step:\n",
    "            torch.save(self.model.state_dict(), self.model_path)\n",
    "            return 'Save model with {}: {:.4f}'.format(self.monitor, self.history[self.monitor][self.best_step]), False\n",
    "        return None, False\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"Delete model from callback.\"\"\"\n",
    "        \n",
    "        self.model = None\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, inp, optimizer,\n",
    "          criterion, epochs, print_every, callbacks, lr_scheduler):\n",
    "    \"\"\"Make model prediction on image.\n",
    "    \n",
    "    Args:\n",
    "        model (Model): Model for training.\n",
    "        inp (Tensor): Inpu image.\n",
    "        optimizer (Optimizer): Optimizer. \n",
    "        criterion (callable): Function for loss calculation.\n",
    "        epochs (int): Number of epoches.\n",
    "        print_every (int): Number of iteration for update statusbar.\n",
    "        callbacks (list): List of callbacks\n",
    "    \n",
    "    Returns:\n",
    "        history (dict): Dict of lists with train history.\n",
    "    \"\"\"\n",
    "    \n",
    "    history = {'Train loss':[]}\n",
    "    \n",
    "    if callbacks:\n",
    "        for i in callbacks:\n",
    "            i.start(history, model)\n",
    "    \n",
    "    train_print = ''\n",
    "    state_text_last = ''\n",
    "    bar = tqdm(range(epochs), desc=\"Epoch\", postfix=train_print)\n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0\n",
    "\n",
    "        stop = False\n",
    "        \n",
    "        steps = 0\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model.forward(inp)\n",
    "            \n",
    "        loss = criterion(out)\n",
    "        if e > PATIENCE:\n",
    "            run[\"training/batch/loss_training\"].log(loss)\n",
    "\n",
    "        loss.backward()\n",
    "                \n",
    "        optimizer.step()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            running_loss = loss.item()\n",
    "        \n",
    "        if (e + 1) % print_every == 0:\n",
    "            print(f'epoch {e+1}/{epochs}, loss = {running_loss:.4f}')\n",
    "            train_print = \"Train loss: {:.4f}\".format(running_loss) + ', ' + state_text_last\n",
    "            bar.postfix = train_print\n",
    "            model.train()\n",
    "            \n",
    "        \n",
    "        history['Train loss'].append(running_loss)\n",
    "        \n",
    "        if lr_scheduler:\n",
    "            if \"OneCycleLR\" in str(lr_scheduler):\n",
    "                lr_scheduler.step()\n",
    "            else:\n",
    "                lr_scheduler.step(running_loss)\n",
    "        \n",
    "        if callbacks:\n",
    "            for i in callbacks:\n",
    "                state_text, state = i.step()\n",
    "                if state_text:\n",
    "                    state_text_last = state_text\n",
    "                if state:\n",
    "                    stop = True\n",
    "        if stop:\n",
    "            train_print = \"Train loss: {:.4f}\".format(running_loss) + ', ' + state_text_last\n",
    "            bar.postfix = train_print\n",
    "            if callbacks:\n",
    "                for i in callbacks:\n",
    "                    i.stop()\n",
    "            model = None\n",
    "            inputs = None\n",
    "            targets = None\n",
    "            outputs = None\n",
    "            loss = None\n",
    "            sm = None\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            break\n",
    "            \n",
    "        if e + 1 != epochs:\n",
    "            bar.update()\n",
    "                        \n",
    "        inputs = None\n",
    "        targets = None\n",
    "        outputs = None\n",
    "        loss = None\n",
    "        sm = None\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "      \n",
    "    bar.update()\n",
    "    bar.close()\n",
    "    \n",
    "    if callbacks:\n",
    "        for i in callbacks:\n",
    "            i.stop()\n",
    "    \n",
    "    model = None\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "def plot_train_history(history):\n",
    "    \"\"\"Plot train history.\n",
    "    \n",
    "    Args:\n",
    "        history (dict): Dict of lists with train history..\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (FIGSIZE * 2, FIGSIZE))\n",
    "    \n",
    "    ax.plot(history['Train loss'], c = 'r')\n",
    "    ax.set_title('Loss')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend(['Train'])\n",
    "    ax.set_yscale('log')\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def dict2str(dict1):\n",
    "    out = str(dict1).replace(\"}\", \"\")\n",
    "    out = str(out).replace(\"{\", \"\")\n",
    "    out = str(out).replace(\"\\\"\", \"\")\n",
    "    out = str(out).replace(\"\\'\", \"\")\n",
    "    out = str(out).replace(\":\", \"\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical solution in case if the fluid is Newtonian\n",
    "\n",
    "The task of fluid flow through a pipe is known as Poiseuille flow and it has a simple analytical solution given in **cylindrical coordinates** $[\\rho, \\theta, x_3]$:\n",
    "\n",
    "\\begin{equation}\n",
    "    {v_3} = - \\frac{1}{4\\mu}\\frac{\\partial p}{\\partial x_3}(R^2 - \\rho^2),\n",
    "\\end{equation}\n",
    "where ${\\partial p}/{\\partial x_3}$ is the pressure drop along the axis of the cylinder.\n",
    "\n",
    "The flow rate trough the pipe cross section (surface $S_3$) is equal to:\n",
    "\n",
    "\\begin{equation}\n",
    "    {Q_3} = \\iint_{S_3} v_3 \\rho\\,d\\rho\\,d\\theta =  - \\frac{\\pi}{8}\\frac{\\partial p}{\\partial x_3}\\frac{R^4}{\\mu}.\n",
    "\\end{equation}\n",
    "\n",
    "Given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'fluid viscosity: mu = {MU},')\n",
    "print(f'flow rate along x_3 axis: Q3 = {Qp[2]}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpdx3a = - Qp[2]*8*MU/(np.pi*(R**4))\n",
    "v3amax = -1/(4*MU)*dpdx3a*(R**2)\n",
    "Int = 0\n",
    "\n",
    "Re = RHO*v3amax*2*R/MU\n",
    "Lcr = 0.16*R*Re\n",
    "\n",
    "#v3a = -1/(4*mu)*dpdx_3*(R**2 - x_1**2 - x_2**2)\n",
    "\n",
    "print(f'pressure drop along x_3 axis: dpdx3 = {dpdx3a},')\n",
    "print(f'maximum velocity: v3 = {v3amax},')\n",
    "print(f'internal power: Int = {Int},')\n",
    "print(f'Reynolds number Re = {Re} is smaller than critical Re < {Re_cr}: {Re<Re_cr}')\n",
    "print(f'Pipe length L_3 = {L[2]} is longer than critical L_cr = {Lcr}: {L[2]>Lcr}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning solution\n",
    "## Flow domain visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr=1\n",
    "nc=len(SIZE)\n",
    "\n",
    "plt.figure(figsize=(nc*FIGSIZE,nr*FIGSIZE))\n",
    "\n",
    "plt.subplot(nr,nc,1)\n",
    "plt.contourf(img[0,slices[0],:,:])\n",
    "plt.title('$x_1 = const$')\n",
    "\n",
    "plt.subplot(nr,nc,2)\n",
    "plt.contourf(img[0,:,slices[1],:])\n",
    "plt.title('$x_2 = const$')\n",
    "\n",
    "plt.subplot(nr,nc,3)\n",
    "plt.contourf(img[0,:,:,slices[2]])\n",
    "plt.title('$x_3 = const$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.min(),img.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaVb_Ejsmynq"
   },
   "source": [
    "## Kinematic properties\n",
    "The flow rate through a cross-section $x_i = const$ can be expressed as follows:\n",
    "\n",
    "\\begin{equation} \n",
    "    \\label{eq:flowRate}\n",
    "    Q_i(x_i) = -\\epsilon_{ijk}(\\psi_j(x_i,x_k^+) - \\psi_j(x_i,x_k^-))l_j,\n",
    "\\end{equation}\n",
    "where $\\epsilon_{ijk}$ is the Levi-Civita symbol, $l_j = (x_j^+ - x_j^-)$.\n",
    "\n",
    "The array of right-side parts and the matrix of coefficeints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array of right-side parts\n",
    "b = np.concatenate((np.zeros(6), np.asarray(Qm + Qp)), axis=0) \n",
    "\n",
    "#Matrix of coefficients\n",
    "Lambda = np.array([[ 1,-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                   [ 0, 0, 1,-1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                   [ 0, 0, 0, 0, 1,-1, 0, 0, 0, 0, 0, 0],\n",
    "                   [ 0, 0, 0, 0, 0, 0, 1,-1, 0, 0, 0, 0],\n",
    "                   [ 0, 0, 0, 0, 0, 0, 0, 0, 1,-1, 0, 0],\n",
    "                   [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,-1],\n",
    "                   [    0,    0,    0,    0, L[1],-L[1],    0,    0,-L[2], L[2],    0,    0],\n",
    "                   [-L[0], L[0],    0,    0,    0,    0,    0,    0,-L[2],    0,-L[2],    0],\n",
    "                   [ L[0],    0,-L[0],    0,-L[1],    0, L[1],    0,    0,    0,    0,    0],\n",
    "                   [    0,    0,    0,    0,    0,    0, L[1],-L[1],    0,    0,-L[2], L[2]],\n",
    "                   [    0,    0,-L[0], L[0],    0,    0,    0,    0,    0, L[2],    0,-L[2]],\n",
    "                   [    0, L[0],    0,-L[0],    0,-L[1],    0, L[1],    0,    0,    0,    0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.det(Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Array of unknowns $y$:\n",
    "\\begin{equation}\n",
    "    \\begin{bmatrix}\n",
    "    \\psi_1^{--}, & \\psi_1^{-+}, & \\psi_1^{+-}, & \\psi_1^{++}, & \\psi_2^{--}, & \\psi_2^{-+}, & \\psi_2^{+-}, & \\psi_2^{++}, & \\psi_3^{--}, & \\psi_3^{-+}, & \\psi_3^{+-}, & \\psi_3^{++}\n",
    "    \\end{bmatrix}.\n",
    "\\end{equation}\n",
    "\n",
    "Solution of the system of linear equations $\\boldsymbol\\Lambda \\cdot y = b$. DOESN'T WORK SO FAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = np.linalg.solve(Lambda, b)\n",
    "# y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psimm = torch.tensor([0, 0, 0])\n",
    "psipp = torch.tensor([ -Qp[2]/(L[0] + L[1]), Qp[2]/(L[0] + L[1]), 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\boldsymbol\\Psi$ initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#psi1(x_2,x_3)\n",
    "psi1 = torch.linspace(psimm[0], psipp[0], SIZE[1], dtype=torch.float32)\n",
    "psi1 = torch.unsqueeze(psi1,1)\n",
    "psi1 = psi1.expand(-1,SIZE[2])\n",
    "\n",
    "#psi2(x_1,x_3)\n",
    "psi2 = torch.linspace(psimm[1], psipp[1], SIZE[0], dtype=torch.float32)\n",
    "psi2 = torch.unsqueeze(psi2,1)\n",
    "psi2 = psi2.expand(-1,SIZE[2])\n",
    "\n",
    "#psi3(x_1,x_2)\n",
    "psi3 = torch.linspace(psimm[2], psipp[2], SIZE[0], dtype=torch.float32)\n",
    "psi3 = torch.unsqueeze(psi3,1)\n",
    "psi3 = psi3.expand(-1,SIZE[1])\n",
    "\n",
    "psi = [psi1, psi2, psi3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psi1 = (torch.linspace(psimm[0], psipp[0], SIZE[1], dtype=torch.float32) * torch.ones(SIZE[1],SIZE[2])).T\n",
    "# psi2 = (torch.linspace(psimm[1], psipp[1], SIZE[1], dtype=torch.float32) * torch.ones(SIZE[0],SIZE[2])).T\n",
    "# psi3 = (torch.linspace(psimm[2], psipp[2], SIZE[1], dtype=torch.float32) * torch.ones(SIZE[0],SIZE[1])).T\n",
    "\n",
    "#psi = [psi1, psi2, psi3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert $\\boldsymbol\\Psi$ into tensor 3 x 1 x SIZE[0] x SIZE[1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi = torch.stack(psi)\n",
    "psi = torch.unsqueeze(psi,1)\n",
    "psi.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix constant values in NL first and last layers and set the boundary conditions (set flow rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(SIZE)):\n",
    "    psi[i,0,:NL,:]  = psimm[i]\n",
    "    psi[i,0,-NL:,:] = psipp[i]\n",
    "psi[2,0,:,0] = psimm[2]\n",
    "psi[2,0,:,-1] = psipp[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "Gb4BFZNWnBsh",
    "outputId": "0dde0211-4908-4885-e6ac-4fc8f130ed54"
   },
   "outputs": [],
   "source": [
    "flowVisualization(psi.permute(1,0,2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPeLHoR31p1D"
   },
   "source": [
    "## Create model\n",
    "Unet architecture [2] is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PID82zl-cxN4"
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=1, init_features=4, use_bn=True):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\", use_bn=use_bn)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\", use_bn=use_bn)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\", use_bn=use_bn)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\", use_bn=use_bn)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\", use_bn=use_bn)\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(\n",
    "            features * 16, features * 8, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\", use_bn=use_bn)\n",
    "        self.upconv3 = nn.ConvTranspose2d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\", use_bn=use_bn)\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features * 4, features * 2, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\", use_bn=use_bn)\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features * 2, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\", use_bn=use_bn)\n",
    "        self.decoder0 = UNet._block(features, features, name=\"dec1\", use_bn=use_bn)\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        dec0 = self.decoder0(dec1)\n",
    "        return torch.tanh(self.conv(dec0))*psipp.max()#torch.sigmoid(self.conv(dec0))*psipp.max()\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name, use_bn):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    *[(name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                      (name + \"relu1\", nn.ReLU(inplace=True))][0 if use_bn else 1:],\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    *[(name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                      (name + \"relu2\", nn.ReLU(inplace=True))][0 if use_bn else 1:],\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_loss(psi):\n",
    "    \n",
    "    #Fix psi function on the boundaries\n",
    "    psi_masked = psi.clone()\n",
    "    for i in range(len(SIZE)):\n",
    "        psi_masked[i,:,:NL,:]  = psimm[i]\n",
    "        #psi_masked[i,:,-NL:,:] = psipp[i]\n",
    "    psi_masked[2,:,-NL:,:] = psipp[2]\n",
    "    psi_masked[2,0,:,0] = psimm[2]\n",
    "    psi_masked[2,0,:,-1] = psipp[2]\n",
    "\n",
    "    v1, v2, v3 = velocityDistr(psi_masked[0,0,:,:], psi_masked[1,0,:,:], psi_masked[2,0,:,:], DX1N, DX2N, DX3N, L[0], L[1], L[2])\n",
    "    \n",
    "    xi11, xi12, xi13, xi22, xi23, xi33, EtaEta = TksiDistr(v1, v2, v3, DX1N, DX2N, DX3N, L[0], L[1], L[2])\n",
    "    \n",
    "    #Subintegral expression with masks for fluid and walls, respectively:\n",
    "    subInt = ((0.5*Q0*EtaEta + ((Q1/(Z+1))*EtaEta**((Z+1)*0.5)))*img[0,:,:,:] + \n",
    "              (0.5*Q0W*EtaEta + ((Q1W/(ZW+1))*EtaEta**((ZW+1)*0.5)))*(1-img[0,:,:,:])) + \n",
    "            REG_LOSS_COEF*(Qp[2] + psi_masked[0,0,-1,-1]*L[0] - psi_masked[1,0,-1,-1]*L[1])**2\n",
    "#    subInt = 0.5*Q0*EtaEta     \n",
    "    #Integral\n",
    "    out = int_func_simpson_3d(subInt, DX1N*L[0], DX2N*L[1], DX3N*L[2])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhZutgNIyYhH"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(WORK_DIR + '/models', exist_ok=True)\n",
    "os.makedirs(WORK_DIR + '/history', exist_ok=True)\n",
    "\n",
    "x = psi\n",
    "\n",
    "# Перемещение на GPU\n",
    "x = x.to(DEVICE)\n",
    "dOmega = dOmega.to(DEVICE)\n",
    "REG_LOSS_COEF = REG_LOSS_COEF.to(DEVICE)\n",
    "Qp = Qp.to(DEVICE)\n",
    "\n",
    "psimm = psimm.to(DEVICE)\n",
    "psipp = psipp.to(DEVICE)\n",
    "\n",
    "img = img.to(DEVICE)\n",
    "\n",
    "DX1N = DX1N.to(DEVICE)\n",
    "DX2N = DX2N.to(DEVICE)\n",
    "DX3N = DX3N.to(DEVICE)\n",
    "\n",
    "run_record = {}\n",
    "\n",
    "for hyp in HYPS:\n",
    "    print('hyperparams: \\n', dict2str(hyp)) \n",
    "\n",
    "    model_path = (f'{WORK_DIR}/models/{MODEL_NAME}_{dict2str(hyp)}.pth')\n",
    "\n",
    "    callbacks = [SaveBest(f'Train loss', model_path, 'min'),\n",
    "                 EarlyStop(f'Train loss', EARLY_STOP_PATIENCE, 'min')]\n",
    "\n",
    "    model = UNet(in_channels=IN_CH, out_channels=OUT_CH, init_features=NoOfFeatures, use_bn=hyp[\"use_bn\"])\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=hyp[\"learning_rate\"], weight_decay=DECAY)\n",
    "    \n",
    "    criterion = power_loss\n",
    "    \n",
    "    #Log model, criterion, and optimizer\n",
    "    run[\"config/model\"] = type(model).__name__\n",
    "    run[\"config/criterion\"] = type(criterion).__name__\n",
    "    run[\"config/optimizer\"] = type(optimizer).__name__\n",
    "\n",
    "    \n",
    "    if hyp[\"scheduler\"] == \"step\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "                                                                  patience=hyp[\"scheduler_patience\"],\n",
    "                                                                  min_lr=1e-6, factor=hyp[\"scheduler_factor\"])\n",
    "    elif hyp[\"scheduler\"] == \"cycle\":\n",
    "        lr_scheduler = scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hyp[\"learning_rate\"] * 20,\n",
    "                                                                       steps_per_epoch=1, epochs=EPOCHS,\n",
    "                                                                       pct_start=0.125,\n",
    "                                                                       div_factor=hyp[\"scheduler_factor\"] ** -1,\n",
    "                                                                       final_div_factor=(hyp[\"scheduler_factor\"] ** -1) * 50)\n",
    "    else:\n",
    "        lr_scheduler = None\n",
    "\n",
    "    history = train(model, x, optimizer, power_loss,\n",
    "                    epochs=EPOCHS, print_every=100,\n",
    "                    callbacks=callbacks, lr_scheduler=lr_scheduler)\n",
    "\n",
    "    run_record[model_path] = {'hyperparams': hyp,\n",
    "                              'history': history,\n",
    "                              'final_val_metric': callbacks[1].best_monitor}\n",
    "\n",
    "    print(f\"Best Train loss %4.4f\" % (callbacks[1].best_monitor))\n",
    "\n",
    "    model = None\n",
    "    optimizer = None\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "best_val_metric = None\n",
    "best_hyperparams = None\n",
    "best_run = None\n",
    "best_model_path = None\n",
    "\n",
    "for key, train_info in run_record.items():\n",
    "    if best_val_metric is None or best_val_metric > train_info['final_val_metric']:\n",
    "        best_val_metric = train_info['final_val_metric']\n",
    "        best_hyperparams = train_info['hyperparams']\n",
    "        best_run = train_info\n",
    "        best_model_path = key\n",
    "\n",
    "with open(f'{WORK_DIR}/history/{MODEL_NAME}_history.json', 'w') as fp:\n",
    "    json.dump(run_record, fp)\n",
    "\n",
    "best_hyp = str(best_hyperparams).replace(\"}\", \"\")\n",
    "best_hyp = best_hyp.replace(\"{\", \"\")\n",
    "best_hyp = best_hyp.replace(\"'\", \"\")\n",
    "\n",
    "print(f\"Best Train loss: %4.4f, best hyperparams: %s\" % (best_val_metric, best_hyp))\n",
    "\n",
    "model = UNet(in_channels=IN_CH, out_channels=OUT_CH, init_features=NoOfFeatures, use_bn=best_hyperparams[\"use_bn\"])\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "torch.save(model.state_dict(), f'{WORK_DIR}/models/{MODEL_NAME}_best.pth')\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "psi = model.forward(x)\n",
    "\n",
    "plot_train_history(best_run['history'])\n",
    "\n",
    "simulation_time = time.time() - start_time\n",
    "print(f'Final loss: {power_loss(psi).cpu().item() :.3f}')\n",
    "print('simulation time:{:.0f}m {:.0f}s'.format(\n",
    "      simulation_time // 60, simulation_time % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhZutgNIyYhH"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet(in_channels=IN_CH, out_channels=OUT_CH, init_features=NoOfFeatures, use_bn=best_hyperparams[\"use_bn\"])\n",
    "# model.load_state_dict(torch.load(best_model_path))\n",
    "# model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix psi function on the boundaries\n",
    "psi_masked = psi.clone().detach()\n",
    "for i in range(len(SIZE)):\n",
    "    psi_masked[i,0,:NL,:]   = psimm[i].to('cpu')\n",
    "    psi_masked[i,0,-NL:,:] = psipp[i].to('cpu')\n",
    "psi[2,0,:,0] = psimm[2].to('cpu')\n",
    "psi[2,0,:,-1] = psipp[2].to('cpu')\n",
    "        \n",
    "v1, v2, v3 = velocityDistr(psi_masked[0,0,:,:], psi_masked[1,0,:,:], psi_masked[2,0,:,:], DX1N, DX2N, DX3N, L[0], L[1], L[2])\n",
    "\n",
    "dv1dx1, dv2dx2, dv3dx3, divV  = divVel(v1, v2, v3, DX1N, DX2N, DX3N, L[0], L[1], L[2])\n",
    "\n",
    "V = torch.stack([v1,v2,v3])\n",
    "Vabs = torch.sqrt(v1**2 + v2**2 + v3**2)\n",
    "xi11, xi12, xi13, xi22, xi23, xi33, EtaEta = TksiDistr(v1, v2, v3, DX1N, DX2N, DX3N, L[0], L[1], L[2])\n",
    "\n",
    "#Subintegral expression with masks for fluid and walls, respectively:\n",
    "subInt = ((0.5*Q0*EtaEta + ((Q1/(Z+1))*EtaEta**((Z+1)*0.5)))*img[0,:,:,:].to(DEVICE) +\n",
    "          (0.5*Q0W*EtaEta + ((Q1W/(ZW+1))*EtaEta**((ZW+1)*0.5)))*(1-img[0,:,:,:].to(DEVICE))) \n",
    "#Integral\n",
    "int1 = torch.trapz(subInt)\n",
    "int2 = torch.trapz(int1)\n",
    "int3 = torch.trapz(int2)\n",
    "out = int3*dOmega #loss\n",
    "\n",
    "print(f'absolute velocity: {Vabs.min()} < abs(V) < {Vabs.max()},')\n",
    "print(f'internal power: Int = {out},')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mv(f):\n",
    "    print(f.min())\n",
    "    print(f.max())\n",
    "    print(f.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv(dv2dx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowVisualization(psi_masked.permute(1,0,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3[slices[0],:,slices[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(FIGSIZE, FIGSIZE))\n",
    "plt.plot(v3[slices[0],:,slices[2]].to('cpu'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3[:,slices[1],slices[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(FIGSIZE, FIGSIZE))\n",
    "plt.plot(v3[:,slices[1],slices[2]].to('cpu'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpsi1dx2, dpsi1dx3 = num_diff2D(psi_masked[0,0,:,:], DX2N, DX3N)\n",
    "dpsi2dx1, dpsi2dx3 = num_diff2D(psi_masked[1,0,:,:], DX1N, DX3N)\n",
    "dpsi3dx1, dpsi3dx2 = num_diff2D(psi_masked[2,0,:,:], DX1N, DX2N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = (dpsi2dx1/L[0]) - (dpsi1dx2/L[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(FIGSIZE, FIGSIZE))\n",
    "plt.plot(fun[:,slices[1]].to('cpu'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fun[:,slices[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {'Internal_power':Intch,\n",
    "#            'Internal_power_exact':Int_ex.item(),\n",
    "#            'Accuracy (in comparison with analitical solution)': acc_rel_exact}\n",
    "# run[\"config/results\"] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpGo7xQz6cny"
   },
   "source": [
    "# Links\n",
    "\n",
    "[1]. https://github.com/Mechanics-Mechatronics-and-Robotics/Mathematical_modelling/blob/main/Practice_1_by_IStebakov.ipynb\n",
    "\n",
    "[2]. https://github.com/mateuszbuda/brain-segmentation-pytorch"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
