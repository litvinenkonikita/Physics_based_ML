{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJkKJ83igGYb"
   },
   "source": [
    "# **Physics-based deep learning in application to fluids flow modelling: 2D flows**\n",
    "\n",
    "Baseline: it is supposed that the Newtonian fluid flows between 2 paralle plates with the gap of $2R$. The flow is steady, the Reynolds number is smaller than the critical one (for the pipe $Re < Re^* {\\approx} 1100...1400$ and the pipe length is greater than the critical one $L_3 > 0.16RRe$). \n",
    "\n",
    "Generalization: it is supposed that the non-Newtonian fluid flows in the 2D flow domain. The flow is steady. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydwhZV95sFoN"
   },
   "source": [
    "# Initialization\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Go3JwW4hICsK"
   },
   "outputs": [],
   "source": [
    "# Pytorch modules\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import transforms\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "# Python functions\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Status bar\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Work with files and images\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os, fnmatch\n",
    "import re\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "#Log\n",
    "import neptune.new as neptune\n",
    "from neptune.new.types import File\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neptune project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: NeptuneDeprecationWarning: `init` is deprecated, use `init_run` instead. We'll end support of it in `neptune-client==1.0.0`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/avkornaev/PhysicsBasedDL/e/PHYSIC-307\n",
      "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init(\n",
    "    project=\"avkornaev/PhysicsBasedDL\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJiMmRjMGY4Ny1hYTI1LTQxZmEtYjRmZC02YzNkYWZjYzNiNjIifQ==\",\n",
    ")  # your credentials\n",
    "\n",
    "# run = neptune.init_run(\n",
    "#     project=\"chester-i-n/Physics-based-ML\",\n",
    "#     api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJhMzE0NzU5Mi1kNzM0LTQyMzEtYWE5OC03MGQyN2Q4MmU1ZGQifQ==\",\n",
    "# )  # your credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzMpruhsYD38"
   },
   "source": [
    "## Download and preprocess image of the flow domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzMpruhsYD38"
   },
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Parallel plates narrow.png', 'Parallel plates 1x16.png', 'Parallel plates.png', 'Parallel plates 1x4.png', 'Parallel plates with notch.png', 'Parallel plates 1x4 with notch.png']\n",
      "Parallel plates.png\n"
     ]
    }
   ],
   "source": [
    "path =  Path('./')\n",
    "imgPath = path/'ToyDataset'\n",
    "imgList = fnmatch.filter(os.listdir(imgPath), '*.png') #imgPath.ls()\n",
    "imgList\n",
    "#Image number from the imgList\n",
    "imgNo = 2\n",
    "print(imgList)\n",
    "print(imgList[imgNo])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download 3D image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labeledImage = Image.open(imgPath/imgList[imgNo]) #open image\n",
    "labeledImage = ImageOps.grayscale(labeledImage).resize((SIZE, SIZE) ,resample=0)\n",
    "\n",
    "labeledImage = torch.tensor(np.array(labeledImage) == 255).float()\n",
    "plt.imshow(labeledImage)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "img = labeledImage.unsqueeze(0).unsqueeze(-1)\n",
    "img = img.repeat(1, 1, 1, SIZE)\n",
    "imgDim = img.shape[1:]\n",
    "print(f'image shape: {imgDim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzMpruhsYD38"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YsKHT1J2Ibx9"
   },
   "outputs": [],
   "source": [
    "SIZE = imgDim\n",
    "#Training\n",
    "EPOCHS = 1000\n",
    "NoOfFeatures = 32 #32\n",
    "WORK_DIR = '/root/Physics_based_loss'\n",
    "IN_CH =  1 #number of input channels\n",
    "OUT_CH = 1#number of output channels\n",
    "#Loss regularization\n",
    "REG_LOSS_COEF = 1000000\n",
    "\n",
    "#SCALE_FACTOR = 1 # muliplier for the loss function\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_NAME = \"unet\"\n",
    "EARLY_STOP_PATIENCE = EPOCHS\n",
    "DECAY = 0\n",
    "PATIENCE = 0\n",
    "CONTINUE = False\n",
    "\n",
    "parameters = {'image_size':SIZE,\n",
    "             'Epochs':EPOCHS,\n",
    "             'Model':MODEL_NAME,\n",
    "             'No_of_features':NoOfFeatures}\n",
    "\n",
    "HYPS = []\n",
    "\n",
    "hyps = {\"Epochs\":[EPOCHS],\n",
    "        \"learning_rate\": [1e-4],\n",
    "        \"scheduler\": [\"none\"],\n",
    "        \"scheduler_factor\": [0.5],\n",
    "        \"scheduler_patience\": [int(EPOCHS*0.05)],\n",
    "        \"use_bn\": [True],\n",
    "        \"Early_stop_patience\": [EARLY_STOP_PATIENCE],\n",
    "        \"Decay\": [DECAY]} # Use or not batchnorm\n",
    "    \n",
    "for i in product(*[hyps[j] for j in hyps]):\n",
    "    HYPS.append({a:b for a, b in zip(hyps, i)})\n",
    "\n",
    "#Visualization\n",
    "STEP3D = 8\n",
    "slices = [int(imgDim[0]/2), int(imgDim[1]/2), int(imgDim[2]/2)]\n",
    "vps = 10 #vector plot step \n",
    "FIGSIZE = 5 # figure size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/neptune/new/attributes/attribute.py:64: NeptuneDeprecationWarning: The object you're logging will be implicitly cast to a string. We'll end support of this behavior in `neptune-client==1.0.0`. To log the object as a string, use `str(object)` instead.\n",
      "  return self.assign(value, wait)\n"
     ]
    }
   ],
   "source": [
    "run[\"config/parameters\"] = parameters\n",
    "run[\"config/hyperparameters\"] = hyps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORhTWZZvVw7c"
   },
   "source": [
    "## Geometry of the flow domain, fluid properties and boundary conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometry\n",
    "\n",
    "It is convenient to present the flow domain $\\Omega$ in the form of a parallelepiped $x_i^- < x_i < x_i^+$ ($\\boldsymbol{L} = [l_i] = [x_i^+ - x_i^-]$, $i = 1,2,3$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L_1 x L_2 x L_3 flow domain\n",
    "L = [0.008, 0.008, 0.52]#, [m]\n",
    "R = L[0]/4 #, [m]\n",
    "\n",
    "# Normalized coordinates, normalized finite diferences, limits and elementary volume\n",
    "X1N = torch.linspace(0, 1, SIZE[0])\n",
    "X2N = torch.linspace(0, 1, SIZE[1])\n",
    "X3N = torch.linspace(0, 1, SIZE[2])\n",
    "\n",
    "DX1N = X1N[1] - X1N[0]\n",
    "DX2N = X2N[1] - X2N[0]\n",
    "DX3N = X3N[1] - X3N[0]\n",
    "\n",
    "LIM1 = [0, L[0]]\n",
    "LIM2 = [0, L[1]]\n",
    "LIM3 = [0, L[2]]\n",
    "\n",
    "dOmega = DX1N * DX2N * DX3N * L[0] * L[1] * L[2] # elementary volume\n",
    "dOmega1 = DX1N * DX3N * L[0] * L[1] * L[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boundary conditions\n",
    "1. The values of the flow rates $Q_i(x_i^-)$, $Q_i(x_i^+)$ through the edges $x_i = x_i^-$, $x_i = x_i^+$ of the flow domain are given:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flow rates Q1-,Q2-,Q3-\n",
    "Qm = [0, 0, -1E-5]\n",
    "\n",
    "#Flow rates Q1+,Q2+,Q3+\n",
    "Qp = [0, 0, 1E-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. NL layers have fixed values of the unknown function $\\boldsymbol\\Psi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DVTEMP = 'sc' #template for the velocity function differentiation\n",
    "if  DVTEMP == 'sc':\n",
    "    NL = 3\n",
    "elif DVTEMP == 'fc':\n",
    "    NL = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Properties of non-Newtonian fluid and walls that are relatively rigid body.\n",
    "The Herschel-Bulkley law is applied:\n",
    "\\begin{equation}\n",
    "    \\mu(H)=q_0+q_1H^{z-1},\n",
    "\\end{equation}\n",
    "where $q_0$, $q_1$, $z$ are the parameters obtained from rheological tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Newtonian fluid viscosity\n",
    "Q0 = 4e-3\n",
    "Q1 = 0\n",
    "Z = 1\n",
    "# Fluid density, kg/m**3\n",
    "RHO = 1000\n",
    "#Newtonian fluid analogue\n",
    "MU = Q0\n",
    "\n",
    "#Critical Reynolds number\n",
    "Re_cr = 1100\n",
    "\n",
    "#Walls viscosity\n",
    "Q0W = 1e+0#1e-0#1e+3eye \n",
    "Q1W = 0#1e-0\n",
    "ZW =1#0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check viscosity models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eta = torch.tensor([0.1, 10, 100, 1000, 10000])\n",
    "mu = Q0W + Q1W*Eta**(1-ZW)\n",
    "mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hw2AD3oWsfJb"
   },
   "source": [
    "## Additional functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JAf1YAHtV15"
   },
   "source": [
    "3D numerical derivative (not applicable in the two-dimensional case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_diff(f,dx1,dx2,dx3,template='sc'):\n",
    "    '''The following templates are applied:\n",
    "    sc - second-order central difference,\n",
    "    fc - fifth-order central difference.\n",
    "    Indexing:\n",
    "    i - index along x_1,\n",
    "    j - index along x_2,\n",
    "    k - index along x_3.\n",
    "    '''\n",
    "    #Shape\n",
    "    n1, n2, n3 = f.shape\n",
    "    \n",
    "    df_dx1, df_dx2, df_dx3 = torch.zeros(n1, n2, n3), torch.zeros(n1, n2, n3), torch.zeros(n1, n2, n3)\n",
    "    \n",
    "    #Device\n",
    "    if torch.cuda.is_available():\n",
    "        df_dx1 = df_dx1.to('cuda')\n",
    "        df_dx2 = df_dx2.to('cuda')\n",
    "        df_dx3 = df_dx3.to('cuda')\n",
    "    \n",
    "    #Derivatives\n",
    "    if template == 'sc':\n",
    "        # x1 derivative:\n",
    "        df_dx1[1:n1-1,:,:] = (f[2:,:,:] - f[:-2,:,:]) / (2 * dx1)\n",
    "        df_dx1[0,:,:] = (-f[2,:,:] + 4 * f[1,:,:] - 3 * f[0,:,:]) / (2 * dx1)\n",
    "        df_dx1[n1-1,:,:] = (3 * f[n1-1,:,:] - 4 * f[n1-2,:,:] + f[n1-3,:,:]) / (2 * dx1)\n",
    "        # x2 derivative:\n",
    "        df_dx2[:,1:n2-1, :] = (f[:, 2:, :] - f[:, :-2, :]) / (2 * dx2)\n",
    "        df_dx2[:,0, :] = (- f[:,2,:] + 4 * f[:,1,:] - 3 * f[:, 0, :]) / (2 * dx2)\n",
    "        df_dx2[:,n2-1, :] = (3 * f[:, n2 - 1, :] - 4 * f[:, n2 - 2, :] + f[:, n2 - 3, :]) / (2 * dx2)\n",
    "        # x3 derivative:\n",
    "        df_dx3[:, :, 1:n3-1] = (f[:,:,2:] - f[:,:,:-2]) / (2 * dx3)\n",
    "        df_dx3[:, :, 0] = (- f[:, :, 2] + 4 * f[:, :, 1] - 3 * f[:, :, 0]) / (2 * dx3)\n",
    "        df_dx3[:, :, n3-1] = (3 * f[:, :, n3 - 1] - 4 * f[:, :, n3 - 2] + f[:, :, n3 - 3]) / (2 * dx3)\n",
    "    elif template == 'fc':\n",
    "        # x1 derivative\n",
    "        df_dx1[2:n1-2, :, :] = (-f[4:, :,:] + 8 * f[3:n1-1, :, :] - 8 * f[1:n1-3, :, :] + f[:n1-4, :, :]) / (12 * dx1)\n",
    "        df_dx1[0, :, :] = (-3 * f[4, :, :] + 16 * f[3, :, :] - 36 * f[2, :, :] + 48 * f[1, :,:] - 25 * f[0, :, :]) / (12 * dx1)\n",
    "        df_dx1[1, :, :] = (f[4, :, :] - 6 * f[3, :, :] + 18 * f[2, :, :] - 10 * f[1, :, :] - 3 * f[0, :, :]) / (12 * dx1)\n",
    "        df_dx1[n1-2, :, :] = (3 * f[n1-1, :, :] + 10 * f[n1-2, :, :] - 18 * f[n1-3, :, :] + 6 * f[n1-4, :, :] - f[n1-5, :, :]) / (12 * dx1)\n",
    "        df_dx1[n1-1, :, :] = (25 * f[n1-1, :, :] - 48 * f[n1-2, :, :] + 36 * f[n1-3, :, :] - 16 * f[n1-4, :, :] + 3*f[n1-5, :, :]) / (12 * dx1)\n",
    "        \n",
    "        # x2 derivative\n",
    "        df_dx2[:, 2:n2-2, :] = (-f[:, 4:, :] + 8 * f[:, 3:n2-1, :] - 8 * f[:, 1:n2-3, :] + f[:, :n2-4, :]) / (12 * dx2)\n",
    "        df_dx2[:, 0, :] = (-3 * f[:,4, :] + 16 * f[:, 3, :] - 36 * f[:, 2, :] + 48 * f[:, 1, :] - 25 * f[:, 0, :]) / (12*dx2)\n",
    "        df_dx2[:, 1, :] = (f[:, 4, :] - 6 * f[:, 3, :] + 18 * f[:, 2, :] - 10 * f[:, 1, :] - 3 * f[:, 0, :]) / (12*dx2)\n",
    "        df_dx2[:, n2-2, :] = (3 * f[:, n2-1, :] + 10 * f[:, n2-2, :] - 18 * f[:, n2-3, :] + 6 * f[:, n2-4, :] - f[:, n2-5, :]) / (12*dx2)\n",
    "        df_dx2[:, n2-1, :] = (25 * f[:, n2-1, :] - 48 * f[:, n2-2, :] + 36 * f[:, n2-3, :] - 16 * f[:, n2-4, :] + 3 * f[:,n2-5, :]) / (12*dx2)       \n",
    "        # x3 derivative\n",
    "        df_dx3[:, :, 2:n3-2] = (-f[:, :, 4:] + 8 * f[:, :, 3:n3-1] - 8 * f[:, :, 1:n3-3] + f[:, :, :n3-4]) / (12 * dx3)\n",
    "        df_dx3[:, :, 0] = (-3 * f[:, :, 4] + 16 * f[:, :, 3] - 36 * f[:, :, 2] + 48 * f[:, :, 1] - 25 * f[:, :, 0]) / (12 * dx3)\n",
    "        df_dx3[:, :, 1] = (f[:, :, 4] - 6 * f[:, :, 3] + 18 * f[:, :, 2] - 10 * f[:, :, 1] - 3 * f[:, :, 0]) / (12 * dx3)\n",
    "        df_dx3[:, :, n3-2] = (3 * f[:, :, n3-1] + 10 * f[:, :, n3-2] - 18 * f[:, :, n3-3] + 6 * f[:,:,n3-4] - f[:, :, n3-5]) / (12 * dx3)\n",
    "        df_dx3[:, :, n3-1] = (25 * f[:,:, n3-1] - 48 * f[:,:, n3-2] + 36 * f[:,:, n3-3] - 16 * f[:,:, n3-4] + 3*f[:,:, n3-5]) / (12 * dx3)\n",
    "    \n",
    "    return df_dx1, df_dx2, df_dx3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D numerical derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_diff2D(f,dx1,dx2,template=DVTEMP):\n",
    "    '''The following templates are applied:\n",
    "    sc - second-order central difference,\n",
    "    fc - fifth-order central difference.\n",
    "    Indexing:\n",
    "    i - index along x_1,\n",
    "    j - index along x_2.\n",
    "    '''\n",
    "    #Shape\n",
    "    n1, n2 = f.shape\n",
    "    \n",
    "    df_dx1, df_dx2 = torch.zeros(n1, n2), torch.zeros(n1, n2)\n",
    "    \n",
    "    #Device\n",
    "    if torch.cuda.is_available():\n",
    "        df_dx1 = df_dx1.to('cuda')\n",
    "        df_dx2 = df_dx2.to('cuda')\n",
    "            \n",
    "    #Derivatives\n",
    "    if template == 'sc':\n",
    "        # x1 derivative:\n",
    "        df_dx1[1:n1-1,:] = (f[2:,:] - f[:-2,:]) / (2 * dx1)\n",
    "        df_dx1[0,:] = (-f[2,:] + 4 * f[1,:] - 3 * f[0,:]) / (2 * dx1)\n",
    "        df_dx1[n1-1,:] = (3 * f[n1-1,:] - 4 * f[n1-2,:] + f[n1-3,:]) / (2 * dx1)\n",
    "        # x2 derivative:\n",
    "        df_dx2[:,1:n2-1] = (f[:, 2:] - f[:, :-2]) / (2 * dx2)\n",
    "        df_dx2[:,0] = (- f[:,2] + 4 * f[:,1] - 3 * f[:, 0]) / (2 * dx2)\n",
    "        df_dx2[:,n2-1] = (3 * f[:, n2 - 1] - 4 * f[:, n2 - 2] + f[:, n2 - 3]) / (2 * dx2)\n",
    "    elif template == 'fc':\n",
    "        # 1st order x1 derivative:\n",
    "        # x1 derivative\n",
    "        df_dx1[2:n1-2, :] = (-f[4:, :] + 8 * f[3:n1-1, :] - 8 * f[1:n1-3, :] + f[:n1-4, :]) / (12 * dx1)\n",
    "        df_dx1[0, :] = (-3 * f[4, :] + 16 * f[3, :] - 36 * f[2, :] + 48 * f[1, :] - 25 * f[0, :]) / (12 * dx1)\n",
    "        df_dx1[1, :] = (f[4, :] - 6 * f[3, :] + 18 * f[2, :] - 10 * f[1, :] - 3 * f[0, :]) / (12 * dx1)\n",
    "        df_dx1[n1-2, :] = (3 * f[n1-1, :] + 10 * f[n1-2, :] - 18 * f[n1-3, :] + 6 * f[n1-4, :] - f[n1-5, :]) / (12 * dx1)\n",
    "        df_dx1[n1-1, :] = (25 * f[n1-1, :] - 48 * f[n1-2, :] + 36 * f[n1-3, :] - 16 * f[n1-4, :] + 3*f[n1-5, :]) / (12 * dx1)\n",
    "        \n",
    "        # x2 derivative\n",
    "        df_dx2[:, 2:n2-2] = (-f[:, 4:] + 8 * f[:, 3:n2-1] - 8 * f[:, 1:n2-3] + f[:, :n2-4]) / (12 * dx2)\n",
    "        df_dx2[:, 0] = (-3 * f[:,4] + 16 * f[:, 3] - 36 * f[:, 2] + 48 * f[:, 1] - 25 * f[:, 0]) / (12*dx2)\n",
    "        df_dx2[:, 1] = (f[:, 4] - 6 * f[:, 3] + 18 * f[:, 2] - 10 * f[:, 1] - 3 * f[:, 0]) / (12*dx2)\n",
    "        df_dx2[:, n2-2] = (3 * f[:, n2-1] + 10 * f[:, n2-2] - 18 * f[:, n2-3] + 6 * f[:, n2-4] - f[:, n2-5]) / (12*dx2)\n",
    "        df_dx2[:, n2-1] = (25 * f[:, n2-1] - 48 * f[:, n2-2] + 36 * f[:, n2-3] - 16 * f[:, n2-4] + 3 * f[:,n2-5]) / (12*dx2)    \n",
    "    \n",
    "    return df_dx1, df_dx2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D numerical integration (Simpson method) (not applicable in the two-dimensional case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_func_simpson_3d(f, dx, dy, dz):\n",
    "  '''\n",
    "  f - 3d-dimentional tensor\n",
    "  dx, dy, dz - constant step along the corresponding coordinate\n",
    "  '''\n",
    "  n1,n2,n3 = f.shape\n",
    "  # integrate by dz:\n",
    "  if n3%2 == 0:\n",
    "    J3 = (f[:,:,0:n3-2:2] + 4*f[:,:,1:n3-2:2] + f[:,:,2::2]).sum(dim=2)*dz/3 + (f[:,:,-1]+f[:,:,-2])*dz/2\n",
    "  else:\n",
    "    J3 = (f[:,:,0:n3-1:2] + 4*f[:,:,1:n3-1:2] + f[:,:,2::2]).sum(dim=2)*dz/3\n",
    "\n",
    "  # integrate by dy:\n",
    "  if n2%2 == 0:\n",
    "    J2 = (J3[:,0:n2-2:2] + 4*J3[:,1:n2-2:2] + J3[:,2::2]).sum(dim=1)*dy/3 + (J3[:,-1]+J3[:,-2])*dy/2\n",
    "  else:\n",
    "    J2 = (J3[:,0:n2-1:2] +4 *J3[:,1:n2-1:2] + J3[:,2::2]).sum(dim=1)*dy/3\n",
    "\n",
    "  # integrate by dx:\n",
    "  if n1%2 == 0:\n",
    "    J1 = (J2[0:n1-2:2] + 4*J2[1:n1-2:2] + J2[2::2]).sum(dim=0)*dx/3 + (J2[-1]+J2[-2])*dx/2\n",
    "  else:\n",
    "    J1 = (J2[0:n1-1:2] + 4*J2[1:n1-1:2] + J2[2::2]).sum(dim=0)*dx/3\n",
    "\n",
    "  return J1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D numerical integration (Simpson method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_func_simpson_2d(f, dx, dy):\n",
    "  '''\n",
    "  f - 2d-dimentional tensor\n",
    "  dx, dy - constant step along the corresponding coordinate\n",
    "  '''\n",
    "  n1, n2 = f.shape\n",
    "  # integrate by dy:\n",
    "  if n2%2 == 0:\n",
    "    J2 = (f[:,0:n2-2:2]+ 4*f[:,1:n2-2:2] + f[:,2::2]).sum(dim=1)*dy/3 + (f[:,-1]+f[:,-2])*dy/2\n",
    "  else:\n",
    "    J2 = (f[:,0:n2-1:2] +4*f[:,1:n2-1:2]+f[:,2::2]).sum(dim=1)*dy/3\n",
    "  # integrate by dx:\n",
    "  if n1%2 == 0:\n",
    "    J1 = (J2[0:n1-2:2]+ 4*J2[1:n1-2:2] + J2[2::2]).sum(dim=0)*dx/3 + (J2[-1]+J2[-2])*dx/2\n",
    "  else:\n",
    "    J1 = (J2[0:n1-1:2] +4*J2[1:n1-1:2]+J2[2::2]).sum(dim=0)*dx/3\n",
    "  return J1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_plot(x, y, u, v, FIGSIZE, vptitle='vector_plot', xlabel='$x_i$', ylabel='$x_j$',step=10):\n",
    "    gradmag = np.sqrt(u**2 + v**2)\n",
    "    plt.pcolor(x, y, gradmag, cmap='rainbow')\n",
    "    plt.colorbar()\n",
    "    plt.quiver(x[::step,::step], y[::step,::step], u[::step,::step], v[::step,::step])\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(vptitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_plot_3d(x, v, v_abs, figSize=FIGSIZE, step=1, use_color=False):\n",
    "    fig = plt.figure(figsize=(figSize, figSize))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    \n",
    "    norm = plt.Normalize()\n",
    "    colors = plt.cm.jet(norm(v_abs[::step, ::step, ::step]))\n",
    "\n",
    "    pos = np.where(img[0].rot90().cpu().detach()==1)\n",
    "    ax.scatter(pos[1], pos[0], pos[2], c='red', s=0.1, alpha=0.2)\n",
    "    ax.quiver(x[0], x[1], x[2], v[::step, ::step, ::step, 0],\n",
    "              v[::step, ::step, ::step, 1],\n",
    "              v[::step, ::step, ::step, 2],\n",
    "              color=colors.reshape(-1, 4) if use_color else 'b', length=20, normalize=False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_zticks([])\n",
    "    ax.bar3d(0, 0, 0., SIZE[0], SIZE[1], SIZE[2], alpha=0.1, edgecolor='black', color='black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flowVisualization(psi,step=15,slices=slices):\n",
    "    nr=2\n",
    "    nc=len(SIZE)\n",
    "    \n",
    "    #Velocity distribution\n",
    "    v1, v2, v3 = velocityDistr(psi[0,0,:,:].to('cpu')*0, psi[0,0,:,:].to('cpu'), psi[0,0,:,:].to('cpu')*0,\n",
    "                               DX1N.to('cpu'), DX2N.to('cpu'), DX3N.to('cpu'),\n",
    "                               L[0], L[1], L[2])\n",
    "    V = torch.stack([v1.to('cpu'),v2.to('cpu'),v3.to('cpu')])\n",
    "    print(V.shape)\n",
    "    Vabs = torch.sqrt(v1.to('cpu')**2 + v2.to('cpu')**2 + v3.to('cpu')**2)\n",
    "    \n",
    "    print('Psi function Visualization')\n",
    "    fig = plt.figure(figsize=(FIGSIZE*nc, FIGSIZE*nr))\n",
    "    for i in range(1):\n",
    "        plt.subplot(nr,nc,i+1)\n",
    "        plt.imshow(psi[0,i,::].to('cpu'))\n",
    "        plt.title(f'$\\psi_{i+1}$')\n",
    "        plt.subplot(nr,nc,i+1+nc)\n",
    "        plt.plot(psi[0,i,:,slices[i]].to('cpu'))\n",
    "        plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "#     print(f'Q1+ = {- (psi[0,1,-1,-1] - psi[0,1,-1,0])*L[1] + (psi[0,2,-1,-1] - psi[0,2,-1,0])*L[2]}, target value: {Qp[0]},')\n",
    "#     print(f'Q2+ = {- (psi[0,2,-1,-1] - psi[0,2,0,-1])*L[2] + (psi[0,0,-1,-1] - psi[0,0,-1,0])*L[0]}, target value: {Qp[1]},')\n",
    "#     print(f'Q3+ = {- (psi[0,0,-1,-1] - psi[0,0,0,-1])*L[0] + (psi[0,1,-1,-1] - psi[0,1,0,-1])*L[1]}, target value: {Qp[2]}')\n",
    "    \n",
    "    print()\n",
    "    print('Velocity distribution visualization without flow domain mask (first line) and with mask (second line)')\n",
    "\n",
    "    XN = torch.meshgrid(X1N,X2N,X3N)\n",
    "    \n",
    "    fig1 = plt.figure(figsize=(FIGSIZE*nc, FIGSIZE*nr))\n",
    "    #without flow domain mask \n",
    "    plt.subplot(nr,nc,1)\n",
    "    vector_plot(XN[1][slices[0],:,:], XN[2][slices[0],:,:], V[1], V[2],\n",
    "                FIGSIZE, vptitle='$x_1 = const$', xlabel='$x_3$', ylabel='$x_2$', step=step)\n",
    "    plt.subplot(nr,nc,2)\n",
    "    vector_plot(XN[0][:,slices[1],:], XN[2][:,slices[1],:], V[0], V[2],\n",
    "                FIGSIZE, vptitle='$x_2 = const$', xlabel='$x_3$', ylabel='$x_1$', step=step)\n",
    "    plt.subplot(nr,nc,3)\n",
    "    vector_plot(XN[0][:,:,slices[2]], XN[1][:,:,slices[2]], V[0], V[1],\n",
    "                FIGSIZE, vptitle='$x_3 = const$', xlabel='$x_2$', ylabel='$x_1$', step=step)\n",
    "    #with flow domain mask \n",
    "#     plt.subplot(nr,nc,4)\n",
    "#     vector_plot(XN[1][0,:,:], XN[2][0,:,:], V[1,slices[0],:,:]*img[0,slices[0],:,:].to('cpu'), V[2,slices[0],:,:]*img[0,slices[0],:,:].to('cpu'),\n",
    "#                 FIGSIZE, vptitle='$x_1 = const$', xlabel='$x_3$', ylabel='$x_2$', step=step)\n",
    "#     plt.subplot(nr,nc,5)\n",
    "#     vector_plot(XN[0][:,0,:], XN[2][:,0,:], V[0,:,slices[1],:]*img[0,:,slices[1],:].to('cpu'), V[2,:,slices[1],:]*img[0,:,slices[1],:].to('cpu'),\n",
    "#                 FIGSIZE, vptitle='$x_2 = const$', xlabel='$x_3$', ylabel='$x_1$', step=step)\n",
    "#     plt.subplot(nr,nc,6)\n",
    "#     vector_plot(XN[0][:,:,0], XN[1][:,:,0], V[0,:,:,slices[2]]*img[0,:,:,slices[2]].to('cpu'), V[1,:,:,slices[2]]*img[0,:,:,slices[2]].to('cpu'),\n",
    "#                 FIGSIZE, vptitle='$x_3 = const$', xlabel='$x_2$', ylabel='$x_1$', step=step)\n",
    "    \n",
    "    #Check the flow rates Q3-,Q3+\n",
    "#     Q1mch = int_func_simpson_2d(V[0, 0, :, :], L[1]*DX2N.to('cpu'), L[2]*DX3N.to('cpu'))\n",
    "#     Q1pch = int_func_simpson_2d(V[0,-1, :, :], L[1]*DX2N.to('cpu'), L[2]*DX3N.to('cpu'))\n",
    "    \n",
    "#     Q2mch = int_func_simpson_2d(V[1, :, 0, :], L[0]*DX1N.to('cpu'), L[2]*DX3N.to('cpu'))\n",
    "#     Q2pch = int_func_simpson_2d(V[1, :,-1, :], L[0]*DX1N.to('cpu'), L[2]*DX3N.to('cpu'))\n",
    "    \n",
    "#     Q3mch = int_func_simpson_2d(V[2, :, :, 0], L[0]*DX1N.to('cpu'), L[1]*DX2N.to('cpu'))\n",
    "#     Q3pch = int_func_simpson_2d(V[2, :, :,-1], L[0]*DX1N.to('cpu'), L[1]*DX2N.to('cpu'))\n",
    "    \n",
    "#     print(f'{V[0].min()} < v_1 < {V[0].max()},')\n",
    "#     print(f'{V[1].min()} < v_2 < {V[1].max()},')\n",
    "#     print(f'{V[2].min()} < v_3 < {V[2].max()},')\n",
    "#     print(f'Q1- = {Q1mch}, Q1+ = {Q1pch}')\n",
    "#     print(f'Q2- = {Q2mch}, Q2+ = {Q2pch}')\n",
    "#     print(f'Q3- = {Q3mch}, Q3+ = {Q3pch}')\n",
    "    \n",
    "#     print(f'Vabs[0,0,0] = {Vabs[0,0,0]}, Vabs[0,0,-1] = {Vabs[0,0,-1]}, Vabs[0,-1,0] = {Vabs[0,-1,0]}, Vabs[0,-1,-1] = {Vabs[0,-1,-1]}, Vabs[-1,0,0] = {Vabs[-1,0,0]}, Vabs[-1,0,-1] = {Vabs[-1,0,-1]}, Vabs[-1,-1,0] = {Vabs[-1,-1,0]}, Vabs[-1,-1,-1] = {Vabs[-1,-1,-1]},')\n",
    "  \n",
    "#     return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mH8zURs8A1Sr"
   },
   "source": [
    "## Major functions\n",
    "\n",
    "For any given function $\\boldsymbol\\Psi = [\\psi_i]$ that has fixed values on the boundaries of the flow domain together with its first, second, and third derivatives, the velocity distribution can be expressed in compact or in expanded form, respectively:\n",
    "\\begin{equation} \n",
    "    \\boldsymbol{V} = \n",
    "    \\begin{bmatrix}\n",
    "    \\epsilon_{ijk}\n",
    "    \\frac{\\partial \\psi_k(x_i,x_j)}{\\partial x_j}\n",
    "    \\end{bmatrix},\n",
    "\\end{equation}\n",
    "where $\\epsilon_{ijk}$ is the Levi-Civita symbol,\n",
    "\n",
    "\\begin{equation} \n",
    "    \\boldsymbol{V} = \n",
    "    \\begin{bmatrix}\n",
    "    \\frac{\\partial \\psi_3}{\\partial x_2} - \\frac{\\partial \\psi_2}{\\partial x_3}, &\n",
    "    \\frac{\\partial \\psi_1}{\\partial x_3} - \\frac{\\partial \\psi_3}{\\partial x_1}, &\n",
    "    \\frac{\\partial \\psi_2}{\\partial x_1} - \\frac{\\partial \\psi_1}{\\partial x_2}\n",
    "    \\end{bmatrix}.\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "WMUIipgs5t3Q"
   },
   "outputs": [],
   "source": [
    "def velocityDistr(psi1,psi2,psi3,dx1n,dx2n,dx3n,deltax1,deltax2,deltax3):\n",
    "    '''Velocity distribution [v_i] in the flow domain\n",
    "    '''\n",
    "    \n",
    "# #Psi function and it's partial derivatives are 2D functions\n",
    "#     dpsi1dx2, dpsi1dx3 = num_diff2D(psi1, dx2n, dx3n)\n",
    "#     dpsi2dx1, dpsi2dx3 = num_diff2D(psi2, dx1n, dx3n)\n",
    "#     dpsi3dx1, dpsi3dx2 = num_diff2D(psi3, dx1n, dx2n)\n",
    "    \n",
    "#     #Expand into 3D, then calculate the velocity distribution\n",
    "#     dpsi1dx2 = torch.unsqueeze(dpsi1dx2,0)\n",
    "#     dpsi1dx3 = torch.unsqueeze(dpsi1dx3,0)\n",
    "    \n",
    "#     dpsi2dx1 = torch.unsqueeze(dpsi2dx1,1)\n",
    "#     dpsi2dx3 = torch.unsqueeze(dpsi2dx3,1)\n",
    "    \n",
    "#     dpsi3dx1 = torch.unsqueeze(dpsi3dx1,2)\n",
    "#     dpsi3dx2 = torch.unsqueeze(dpsi3dx2,2)\n",
    "    \n",
    "#     v1 = (dpsi3dx2.expand(-1,-1,SIZE[2]) / deltax2) - (dpsi2dx3.expand(-1,SIZE[1],-1) / deltax3)\n",
    "#     v2 = (dpsi1dx3.expand(SIZE[0],-1,-1) / deltax3) - (dpsi3dx1.expand(-1,-1,SIZE[2]) / deltax1)\n",
    "#     v3 = (dpsi2dx1.expand(-1,SIZE[1],-1) / deltax1) - (dpsi1dx2.expand(SIZE[0],-1,-1) / deltax2)   \n",
    "\n",
    "#Psi function and it's partial derivatives are 2D functions\n",
    "    #dpsi1dx2, dpsi1dx3 = num_diff2D(psi1, dx2n, dx3n)\n",
    "    dpsi2dx1, dpsi2dx3 = num_diff2D(psi2, dx1n, dx3n)\n",
    "    #dpsi3dx1, dpsi3dx2 = num_diff2D(psi3, dx1n, dx2n)\n",
    "    \n",
    "    v1 =  - (dpsi2dx3 / deltax3)\n",
    "    v2 = dpsi2dx3 * 0\n",
    "    v3 = (dpsi2dx1 / deltax1)   \n",
    "    \n",
    "    return v1, v2, v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking into account the symmetry of the shear rate tensor $\\xi_{i,j}=\\xi_{i,j}$, the tensor has the following form:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\boldsymbol{T}_\\xi= \\frac{1}{2}   \n",
    "    \\begin{bmatrix}\n",
    "    2\\frac{\\partial v_1}{\\partial x_1}, & \\frac{\\partial v_1}{\\partial x_2} - \\frac{\\partial v_2}{\\partial x_1}, & \\frac{\\partial v_1}{\\partial x_3} - \\frac{\\partial v_3}{\\partial x_1} \\\\\n",
    "     \\frac{\\partial v_1}{\\partial x_2} - \\frac{\\partial v_2}{\\partial x_1}, & 2\\frac{\\partial v_2}{\\partial x_2}, & \\frac{\\partial v_2}{\\partial x_3} - \\frac{\\partial v_3}{\\partial x_2}  \\\\\n",
    "    \\frac{\\partial v_1}{\\partial x_3} - \\frac{\\partial v_3}{\\partial x_1}, & \\frac{\\partial v_2}{\\partial x_3} - \\frac{\\partial v_3}{\\partial x_2},  & 2\\frac{\\partial v_3}{\\partial x_3}  \\\\\n",
    "    \\end{bmatrix}.\n",
    "\\end{equation}\n",
    "\n",
    "In the general case of a three dimensional flow the shear strain rate intensity $H$ depends on all the components of the shear rate tensor:\n",
    "\\begin{equation}\n",
    "    H =\\sqrt{2(\\xi_{11}^2 + \\xi_{22}^2 + \\xi_{33}^2 + 2\\xi_{12}^2 + 2\\xi_{13}^2 + 2\\xi_{23}^2)}. \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "716qlRJoNglx"
   },
   "outputs": [],
   "source": [
    "def TksiDistr(v1,v2,v3,dx1n,dx2n,dx3n,deltax1,deltax2,deltax3):\n",
    "    '''Strain rate tensor Txi and the shear rate intensity Eta squared\n",
    "    '''    \n",
    "    \n",
    "#     dv1dx1, dv1dx2, dv1dx3 = num_diff(v1, dx1n, dx2n, dx3n)\n",
    "#     dv2dx1, dv2dx2, dv2dx3 = num_diff(v2, dx1n, dx2n, dx3n)\n",
    "#     dv3dx1, dv3dx2, dv3dx3 = num_diff(v3, dx1n, dx2n, dx3n)\n",
    "    \n",
    "#     #Txi\n",
    "#     xi11 = dv1dx1 / deltax1\n",
    "#     xi12 = 0.5 * ((dv1dx2 / deltax2) + (dv2dx1 / deltax1))\n",
    "#     xi13 = 0.5 * ((dv1dx3 / deltax3) + (dv3dx1 / deltax1))\n",
    "    \n",
    "#     xi22 = dv2dx2 / deltax2\n",
    "#     xi23 = 0.5 * ((dv2dx3 / deltax3) + (dv3dx2 / deltax2))\n",
    "    \n",
    "#     xi33 = dv3dx3 / deltax3\n",
    "    \n",
    "#     #Eta^2    \n",
    "#     EtaEta = (2 * (xi11 * xi11 + xi22 * xi22 + xi33 * xi33 + \n",
    "#                    2 * (xi12 * xi12 + xi13 * xi13 + xi23 * xi23)))\n",
    "    \n",
    "    dv1dx1, dv1dx3 = num_diff2D(v1, dx1n, dx3n)\n",
    "    dv2dx1, dv2dx3 = num_diff2D(v2, dx1n, dx3n)\n",
    "    dv3dx1, dv3dx3 = num_diff2D(v3, dx1n, dx3n)\n",
    "    \n",
    "    #Txi\n",
    "    xi11 = dv1dx1 / deltax1\n",
    "    xi12 = dv1dx1 * 0\n",
    "    xi13 = 0.5 * ((dv1dx3 / deltax3) + (dv3dx1 / deltax1))\n",
    "    \n",
    "    xi22 = dv1dx1 * 0\n",
    "    xi23 = dv1dx1 * 0\n",
    "    \n",
    "    xi33 = dv1dx1 * 0\n",
    "    \n",
    "    #Eta^2    \n",
    "    EtaEta = (2 * (xi11 * xi11 + xi22 * xi22 + xi33 * xi33 + \n",
    "                   2 * (xi12 * xi12 + xi13 * xi13 + xi23 * xi23)))\n",
    "  \n",
    "    return xi11, xi12, xi13, xi22, xi23, xi33, EtaEta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divVel(v1,v2,v3,dx1n,dx2n,dx3n,deltax1,deltax2,deltax3):\n",
    "    \n",
    "    dv1dx1, dv1dx2, dv1dx3 = num_diff(v1, dx1n, dx2n, dx3n)\n",
    "    dv2dx1, dv2dx2, dv2dx3 = num_diff(v2, dx1n, dx2n, dx3n)\n",
    "    dv3dx1, dv3dx2, dv3dx3 = num_diff(v3, dx1n, dx2n, dx3n)\n",
    "    \n",
    "    divV = dv1dx1 + dv2dx2 + dv3dx3\n",
    "    \n",
    "    return dv1dx1, dv2dx2, dv3dx3, divV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStop():\n",
    "    \"\"\"Callback for early stop train process.\n",
    "    \n",
    "    Args:\n",
    "        monitor (str): value for monitoring.\n",
    "        patience (int): Number of epochs with no improvement after which training will be stopped.\n",
    "        mode (str): One of {\"min\", \"max\"}. In min mode, training will stop when the quantity monitored has stopped decreasing.\n",
    "            In \"max\" mode it will stop when the quantity monitored has stopped increasing.\n",
    "    \n",
    "    Attributes:\n",
    "        history (dict): Dict of lists with train history. Key \"monitor\" contains list of monitoring values. \n",
    "        steps (int): Number of passed epoches. \n",
    "        best_step (int): Number of best epoch. \n",
    "        best_monitor (float): Best of monitoring value.\n",
    "        model (Model): Training model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, monitor, patience, mode):\n",
    "        self.monitor = monitor\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.history = None\n",
    "        self.steps = -1\n",
    "        self.best_step = -1\n",
    "        if self.mode == 'max':\n",
    "            self.best_monitor = 0\n",
    "        elif self.mode == 'min':\n",
    "            self.best_monitor = 1e99999\n",
    "            \n",
    "    def start(self, history, model):\n",
    "        \"\"\"Start and init callback.\n",
    "        \n",
    "        Args:\n",
    "            history (dict): Dict of lists with train history. Key \"monitor\" contains list of monitoring values. \n",
    "            model (Model): Training model.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.history = history\n",
    "        self.model = model\n",
    "        \n",
    "    def step(self, save=True):\n",
    "        \"\"\"Make a step of callback.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (event, stop):\n",
    "                event (str): Decription of event. If event not did not happen then event = ''.\n",
    "                stop (bool): Flag of stopping train process.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.steps += 1\n",
    "        \n",
    "        if self.mode == 'max':\n",
    "            if self.history[self.monitor][-1] > self.best_monitor:\n",
    "                self.best_monitor = self.history[self.monitor][-1]\n",
    "                self.best_step = self.steps\n",
    "        elif self.mode == 'min':\n",
    "            if self.history[self.monitor][-1] < self.best_monitor:\n",
    "                self.best_monitor = self.history[self.monitor][-1]\n",
    "                self.best_step = self.steps\n",
    "        \n",
    "        if self.steps - self.best_step > self.patience:\n",
    "            return 'Early stop with {}: {:.4f}'.format(self.monitor, self.history[self.monitor][self.best_step]), True\n",
    "        return None, False\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"Delete model from callback.\"\"\"\n",
    "        \n",
    "        self.model = None\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "class SaveBest():\n",
    "    \"\"\"Callback for save model if there is an improvement.\n",
    "    \n",
    "    Args:\n",
    "        monitor (str): value for monitoring.\n",
    "        model_path (str): Path for saving model.\n",
    "        mode (str): One of {\"min\", \"max\"}. In min mode, training will stop when the quantity monitored has stopped decreasing.\n",
    "            In \"max\" mode it will stop when the quantity monitored has stopped increasing.\n",
    "    \n",
    "    Attributes:\n",
    "        history (dict): Dict of lists with train history. Key \"monitor\" contains list of monitoring values. \n",
    "        steps (int): Number of passed epoches. \n",
    "        best_step (int): Number of best epoch. \n",
    "        best_monitor (float): Best of monitoring value.\n",
    "        model (Model): Training model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, monitor, model_path, mode):\n",
    "        self.monitor = monitor\n",
    "        self.model_path = model_path\n",
    "        self.mode = mode\n",
    "        self.history = None\n",
    "        self.steps = -1\n",
    "        self.best_step = -1\n",
    "        if self.mode == 'max':\n",
    "            self.best_monitor = 0\n",
    "        elif self.mode == 'min':\n",
    "            self.best_monitor = 1e99999\n",
    "    \n",
    "    def start(self, history, model):\n",
    "        \"\"\"Start and init callback. Save first version of model.\n",
    "        \n",
    "        Args:\n",
    "            history (dict): Dict of lists with train history. Key \"monitor\" contains list of monitoring values. \n",
    "            model (Model): Training model\n",
    "        \"\"\"\n",
    "        \n",
    "        self.history = history\n",
    "        self.model = model\n",
    "        torch.save(self.model.state_dict(), self.model_path)\n",
    "    \n",
    "    def step(self, save=True):\n",
    "        \"\"\"Make a step of callback.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (event, stop):\n",
    "                event (str): Decription of event. If event not did not happen then event = ''.\n",
    "                stop (bool): Flag of stopping train process.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.steps += 1\n",
    "        \n",
    "        if self.mode == 'max':\n",
    "            if self.history[self.monitor][-1] > self.best_monitor:\n",
    "                self.best_monitor = self.history[self.monitor][-1]\n",
    "                self.best_step = self.steps\n",
    "        elif self.mode == 'min':\n",
    "            if self.history[self.monitor][-1] < self.best_monitor:\n",
    "                self.best_monitor = self.history[self.monitor][-1]\n",
    "                self.best_step = self.steps\n",
    "        \n",
    "        if self.steps == self.best_step:\n",
    "            if save:\n",
    "                torch.save(self.model.state_dict(), self.model_path)\n",
    "            return 'Save model with {}: {:.4f}'.format(self.monitor, self.history[self.monitor][self.best_step]), False\n",
    "        return None, False\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"Delete model from callback.\"\"\"\n",
    "        \n",
    "        self.model = None\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, inp, optimizer,\n",
    "          criterion, epochs, print_every, callbacks, lr_scheduler, run_record, model_path):\n",
    "    \"\"\"Make model prediction on image.\n",
    "    \n",
    "    Args:\n",
    "        model (Model): Model for training.\n",
    "        inp (Tensor): Inpu image.\n",
    "        optimizer (Optimizer): Optimizer. \n",
    "        criterion (callable): Function for loss calculation.\n",
    "        epochs (int): Number of epoches.\n",
    "        print_every (int): Number of iteration for update statusbar.\n",
    "        callbacks (list): List of callbacks\n",
    "    \n",
    "    Returns:\n",
    "        history (dict): Dict of lists with train history.\n",
    "    \"\"\"\n",
    "    if 'history' in run_record[model_path]:\n",
    "        history = run_record[model_path]['history']\n",
    "    else:\n",
    "        history = {'Train loss':[]}\n",
    "    \n",
    "    if callbacks:\n",
    "        for i in callbacks:\n",
    "            i.start(history, model)\n",
    "    \n",
    "    train_print = ''\n",
    "    state_text_last = ''\n",
    "    bar = tqdm(range(epochs), desc=\"Epoch\", postfix=train_print)\n",
    "    for e in range(epochs):\n",
    "        if e < len(history['Train loss']):\n",
    "            if e > PATIENCE:\n",
    "                run[\"training/batch/loss_training\"].log(history['Train loss'][e])\n",
    "\n",
    "            if (e + 1) % print_every == 0:\n",
    "                print(f'epoch {e+1}/{epochs}, loss = {history[\"Train loss\"][e]:.4f}')\n",
    "                train_print = \"Train loss: {:.4f}\".format(history['Train loss'][e]) + ', ' + state_text_last\n",
    "                bar.postfix = train_print\n",
    "\n",
    "            if e + 1 != epochs:\n",
    "                bar.update()\n",
    "                \n",
    "            if callbacks:\n",
    "                for i in callbacks:\n",
    "                    i.step(False)\n",
    "            continue\n",
    "                \n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0\n",
    "\n",
    "        stop = False\n",
    "        \n",
    "        steps = 0\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model.forward(inp)\n",
    "            \n",
    "        loss = criterion(out)\n",
    "        if e > PATIENCE:\n",
    "            run[\"training/batch/loss_training\"].log(loss)\n",
    "\n",
    "        loss.backward()\n",
    "                \n",
    "        optimizer.step()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            running_loss = loss.item()\n",
    "        \n",
    "        if (e + 1) % print_every == 0:\n",
    "            print(f'epoch {e+1}/{epochs}, loss = {running_loss:.4f}')\n",
    "            train_print = \"Train loss: {:.4f}\".format(running_loss) + ', ' + state_text_last\n",
    "            bar.postfix = train_print\n",
    "            model.train()\n",
    "            \n",
    "        \n",
    "        history['Train loss'].append(running_loss)\n",
    "        \n",
    "        run_record[model_path]['history'] = history\n",
    "        \n",
    "        with open(f'{WORK_DIR}/history/{MODEL_NAME}_history.json', 'w') as fp:\n",
    "            json.dump(run_record, fp)\n",
    "        \n",
    "        if lr_scheduler:\n",
    "            if \"OneCycleLR\" in str(lr_scheduler):\n",
    "                lr_scheduler.step()\n",
    "            else:\n",
    "                lr_scheduler.step(running_loss)\n",
    "        \n",
    "        if callbacks:\n",
    "            for i in callbacks:\n",
    "                state_text, state = i.step()\n",
    "                if state_text:\n",
    "                    state_text_last = state_text\n",
    "                if state:\n",
    "                    stop = True\n",
    "        if stop:\n",
    "            train_print = \"Train loss: {:.4f}\".format(running_loss) + ', ' + state_text_last\n",
    "            bar.postfix = train_print\n",
    "            if callbacks:\n",
    "                for i in callbacks:\n",
    "                    i.stop()\n",
    "            model = None\n",
    "            inputs = None\n",
    "            targets = None\n",
    "            outputs = None\n",
    "            loss = None\n",
    "            sm = None\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            break\n",
    "            \n",
    "        if e + 1 != epochs:\n",
    "            bar.update()\n",
    "                        \n",
    "        inputs = None\n",
    "        targets = None\n",
    "        outputs = None\n",
    "        loss = None\n",
    "        sm = None\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "      \n",
    "    bar.update()\n",
    "    bar.close()\n",
    "    \n",
    "    if callbacks:\n",
    "        for i in callbacks:\n",
    "            i.stop()\n",
    "    \n",
    "    model = None\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "def plot_train_history(history):\n",
    "    \"\"\"Plot train history.\n",
    "    \n",
    "    Args:\n",
    "        history (dict): Dict of lists with train history..\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (FIGSIZE * 2, FIGSIZE))\n",
    "    \n",
    "    ax.plot(history['Train loss'], c = 'r')\n",
    "    ax.set_title('Loss')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend(['Train'])\n",
    "    ax.set_yscale('log')\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def dict2str(dict1):\n",
    "    out = str(dict1).replace(\"}\", \"\")\n",
    "    out = str(out).replace(\"{\", \"\")\n",
    "    out = str(out).replace(\"\\\"\", \"\")\n",
    "    out = str(out).replace(\"\\'\", \"\")\n",
    "    out = str(out).replace(\":\", \"\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical solution: flow between 2 parallel plates\n",
    "\n",
    "Velocity distribution has one non-zero component $v_3$ that depends on one coordinate $v_3 = v_3(x_1)$:\n",
    "\n",
    "\\begin{equation}\n",
    "    {v_3} = Ð¡_0\\frac{x_1^2}{2\\mu} + C_1x_1,\n",
    "\\end{equation}\n",
    "where $Ð¡_0 = {-12{\\mu}Q_3}/{(2R)^3}$, $Ð¡_1 = {6Q_3}/{(2R)^2}$, $Ð¡_0L_3 = {\\partial p}/{\\partial x_3}$, ${\\partial p}/{\\partial x_3}$ is the pressure drop along the axis of the cylinder.\n",
    "\n",
    "The flow rate trough the edges (surfaces $S_3^-$, $S_3^+$) is given and equal to:\n",
    "\n",
    "\\begin{equation}\n",
    "    {Q_3} = \\iint_{S_3} v_3 ,dx_1dx_2.\n",
    "\\end{equation}\n",
    "\n",
    "The power of external forces $Ext$ (equal to the power of internal forces $Int$) : \n",
    "\n",
    "\\begin{equation}\n",
    "    {Ext} = (p_1 - p_0)\\iint_{S_3} v_3 \\,dx_1\\,dx_2 =  \\frac{\\partial p}{\\partial x_3}L_3Q_3.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "Given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fluid viscosity: mu = 0.004,\n",
      "flow rate along x_3 axis: Q3 = 1e-05.\n"
     ]
    }
   ],
   "source": [
    "print(f'fluid viscosity: mu = {MU},')\n",
    "print(f'flow rate along x_3 axis: Q3 = {Qp[2]}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pressure drop along x_3 axis: dpdx3 = -487.5,\n",
      "maximum velocity: v3 = 0.4687210023403168,\n",
      "internal power: Int = 0.004875,\n",
      "Reynolds number Re = 468.72100830078125 is smaller than critical Re < 1100: True\n",
      "Pipe length L_3 = 0.52 is longer than critical L_cr = 0.1499907225370407: True\n",
      "Pipe radius R = 0.002.\n"
     ]
    }
   ],
   "source": [
    "h = 2*R\n",
    "C0 = -12*MU*Qp[2]/(h**3*L[1])\n",
    "C1 = 6*Qp[2]/(h**2*L[1])\n",
    "psiex = C0*(X1N**3)*h**3/(6*MU) + C1*(X1N**2/2)*h**2\n",
    "v3a = C0*(X1N**2)*h**2/(2*MU) + C1*(X1N)*h\n",
    "v3amax = v3a.max() \n",
    "\n",
    "dpdx3a = C0*L[2]\n",
    "Int = - dpdx3a * Qp[2]\n",
    "\n",
    "Re = RHO*v3amax*h/MU\n",
    "Lcr = 0.16*R*Re\n",
    "\n",
    "print(f'pressure drop along x_3 axis: dpdx3 = {dpdx3a},')\n",
    "print(f'maximum velocity: v3 = {v3amax},')\n",
    "print(f'internal power: Int = {Int},')\n",
    "print(f'Reynolds number Re = {Re} is smaller than critical Re < {Re_cr}: {Re<Re_cr}')\n",
    "print(f'Pipe length L_3 = {L[2]} is longer than critical L_cr = {Lcr}: {L[2]>Lcr}')\n",
    "print(f'Pipe radius R = {R}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v3a.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning solution\n",
    "## Flow domain visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64, 64, 64]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nr=1\n",
    "nc=len(SIZE)\n",
    "\n",
    "plt.figure(figsize=(nc*FIGSIZE,nr*FIGSIZE))\n",
    "\n",
    "plt.subplot(nr,nc,1)\n",
    "plt.contourf(img[0,slices[0],:,:]*0)#times zero in case of 2D flows\n",
    "plt.colorbar()\n",
    "\n",
    "plt.title('$x_1 = const$')\n",
    "\n",
    "plt.subplot(nr,nc,2)\n",
    "plt.contourf(img[0,:,slices[1],:])\n",
    "plt.colorbar()\n",
    "plt.title('$x_2 = const$')\n",
    "\n",
    "plt.subplot(nr,nc,3)\n",
    "plt.contourf(img[0,:,:,slices[2]]*0)#times zero in case of 2D flows\n",
    "plt.colorbar()\n",
    "plt.title('$x_3 = const$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(1.))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.min(),img.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaVb_Ejsmynq"
   },
   "source": [
    "## Kinematic properties\n",
    "The flow rate through a cross-section $x_i = const$ can be expressed as follows:\n",
    "\n",
    "\\begin{equation} \n",
    "    \\label{eq:flowRate}\n",
    "    Q_i(x_i) = -\\epsilon_{ijk}(\\psi_j(x_i,x_k^+) - \\psi_j(x_i,x_k^-))l_j,\n",
    "\\end{equation}\n",
    "where $\\epsilon_{ijk}$ is the Levi-Civita symbol, $l_j = (x_j^+ - x_j^-)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\boldsymbol\\Psi$ on borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00125, tensor([0.0000, 0.0012, 0.0000]), tensor([0, 0, 0]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psimm = torch.tensor([0, 0, 0])\n",
    "psipp = torch.tensor([0, Qp[2]/L[1], 0]) #similar to analytical solution for a pipe\n",
    "\n",
    "psi_norm = Qp[2]/L[1] # flow between 2 plates\n",
    "psi_norm, psipp, psimm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\boldsymbol\\Psi$ initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 128])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#psi1(x_2,x_3)\n",
    "psi1 = torch.linspace(psimm[0], psipp[0], SIZE[1], dtype=torch.float32)\n",
    "psi1 = torch.unsqueeze(psi1,1)\n",
    "psi1 = psi1.expand(-1,SIZE[2])\n",
    "\n",
    "#psi2(x_1,x_3)\n",
    "psi2 = torch.linspace(psimm[1], psipp[1], SIZE[0], dtype=torch.float32)\n",
    "psi2 = torch.unsqueeze(psi2,1)\n",
    "psi2 = psi2.expand(-1,SIZE[2])\n",
    "\n",
    "#psi3(x_1,x_2)\n",
    "psi3 = torch.linspace(psimm[2], psipp[2], SIZE[0], dtype=torch.float32)\n",
    "psi3 = torch.unsqueeze(psi3,1)\n",
    "psi3 = psi3.expand(-1,SIZE[1])\n",
    "\n",
    "psi = torch.unsqueeze(psi1.clone(),0) #[psi1, psi2, psi3]\n",
    "\n",
    "psi.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert $\\boldsymbol\\Psi$ into tensor 3 x 1 x SIZE[0] x SIZE[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128, 128])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#psi = torch.stack(psi)\n",
    "psi = torch.unsqueeze(psi,1)\n",
    "psi.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix constant values in NL first and last layers and set the boundary conditions (set flow rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1):\n",
    "#     print(i)\n",
    "#     psi[i,0,:NL,:]  = psimm[i]\n",
    "#     psi[i,0,-NL:,:] = psipp[i]\n",
    "psi[:,:,:NL,:]  = psimm[1]\n",
    "psi[:,:,-NL:,:] = psipp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128, 128])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "Gb4BFZNWnBsh",
    "outputId": "0dde0211-4908-4885-e6ac-4fc8f130ed54"
   },
   "outputs": [],
   "source": [
    "#flowVisualization(psi.permute(1,0,2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPeLHoR31p1D"
   },
   "source": [
    "## Create model\n",
    "Unet architecture [2] is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "PID82zl-cxN4"
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=1, init_features=4, use_bn=True):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\", use_bn=use_bn)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\", use_bn=use_bn)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\", use_bn=use_bn)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\", use_bn=use_bn)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\", use_bn=use_bn)\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(\n",
    "            features * 16, features * 8, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\", use_bn=use_bn)\n",
    "        self.upconv3 = nn.ConvTranspose2d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\", use_bn=use_bn)\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features * 4, features * 2, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\", use_bn=use_bn)\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features * 2, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\", use_bn=use_bn)\n",
    "        self.decoder0 = UNet._block(features, features, name=\"dec1\", use_bn=use_bn)\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        dec0 = self.decoder0(dec1)\n",
    "        return self.conv(dec0)*psi_norm #torch.tanh(self.conv(dec0))*psi_abs_limit #torch.sigmoid(self.conv(dec0))*psipp.max()\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name, use_bn):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    *[(name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                      (name + \"relu1\", nn.ReLU(inplace=True))][0 if use_bn else 1:],\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    *[(name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                      (name + \"relu2\", nn.ReLU(inplace=True))][0 if use_bn else 1:],\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_loss(psi):\n",
    "    \n",
    "    #Fix psi function on the boundaries\n",
    "    psi_masked = psi.clone()\n",
    "    psi_masked[:,:,:NL,:]  = psimm[1]\n",
    "    psi_masked[:,:,-NL:,:] = psipp[1]\n",
    "    \n",
    "    v1, v2, v3 = velocityDistr(psi_masked[0,0,:,:]*0, psi_masked[0,0,:,:], psi_masked[0,0,:,:]*0, DX1N, DX2N, DX3N, L[0], L[1], L[2])\n",
    "    \n",
    "    xi11, xi12, xi13, xi22, xi23, xi33, EtaEta = TksiDistr(v1, v2, v3, DX1N, DX2N, DX3N, L[0], L[1], L[2])\n",
    "    \n",
    "    #Subintegral expression with masks for fluid and walls, respectively:\n",
    "    subInt = ((0.5*Q0*EtaEta + ((Q1/(Z+1))*EtaEta**((Z+1)*0.5)))*img[0,:,slices[1],:] + \n",
    "              (0.5*Q0W*EtaEta + ((Q1W/(ZW+1))*EtaEta**((ZW+1)*0.5)))*(1-img[0,:,slices[1],:])) #+ REG_LOSS_COEF*(Qp[2] + psi_masked[0,0,-1,-1]*L[0] - psi_masked[1,0,-1,-1]*L[1])**2)\n",
    "  \n",
    "    #Integral\n",
    "    out = int_func_simpson_2d(subInt, DX1N*L[0], DX3N*L[2])*L[1]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0079), tensor(1.6247e-11))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DX2N, dOmega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhZutgNIyYhH"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparams: \n",
      " Epochs 1000, learning_rate 0.0001, scheduler none, scheduler_factor 0.5, scheduler_patience 50, use_bn True, Early_stop_patience 1000, Decay 0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/root/Physics_based_loss/models/unet_Epochs 1000, learning_rate 0.0001, scheduler none, scheduler_factor 0.5, scheduler_patience 50, use_bn True, Early_stop_patience 1000, Decay 0.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-364f2a8ea63e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_record\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"learning_rate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDECAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/Physics_based_loss/models/unet_Epochs 1000, learning_rate 0.0001, scheduler none, scheduler_factor 0.5, scheduler_patience 50, use_bn True, Early_stop_patience 1000, Decay 0.pth'"
     ]
    }
   ],
   "source": [
    "os.makedirs(WORK_DIR + '/models', exist_ok=True)\n",
    "os.makedirs(WORK_DIR + '/history', exist_ok=True)\n",
    "\n",
    "x = psi\n",
    "\n",
    "# ÐŸÐµÑ€ÐµÐ¼ÐµÑ‰ÐµÐ½Ð¸Ðµ Ð½Ð° GPU\n",
    "x = x.to(DEVICE)\n",
    "dOmega = dOmega.to(DEVICE)\n",
    "\n",
    "psimm = psimm.to(DEVICE)\n",
    "psipp = psipp.to(DEVICE)\n",
    "\n",
    "img = img.to(DEVICE)\n",
    "\n",
    "DX1N = DX1N.to(DEVICE)\n",
    "DX2N = DX2N.to(DEVICE)\n",
    "DX3N = DX3N.to(DEVICE)\n",
    "\n",
    "if CONTINUE:\n",
    "    with open(f'{WORK_DIR}/history/{MODEL_NAME}_history.json', 'r') as fp:\n",
    "        run_record = json.load(fp)\n",
    "else:\n",
    "    run_record = {}\n",
    "\n",
    "for hyp in HYPS:\n",
    "    print('hyperparams: \\n', dict2str(hyp)) \n",
    "    \n",
    "    model_path = (f'{WORK_DIR}/models/{MODEL_NAME}_{dict2str(hyp)}.pth')\n",
    "\n",
    "    if model_path in run_record:\n",
    "        if 'final_val_metric' in run_record[model_path]:\n",
    "            continue\n",
    "    else:\n",
    "        run_record[model_path] = {'hyperparams': hyp}\n",
    "            \n",
    "    callbacks = [SaveBest(f'Train loss', model_path, 'min'),\n",
    "                 EarlyStop(f'Train loss', EARLY_STOP_PATIENCE, 'min')]\n",
    "\n",
    "    model = UNet(in_channels=IN_CH, out_channels=OUT_CH, init_features=NoOfFeatures, use_bn=hyp[\"use_bn\"])\n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "    # Ð Ð°ÑÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð´Ð¾Ð¾Ð±ÑƒÑ‡Ð¸Ñ‚ÑŒ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n",
    "    model.load_state_dict(torch.load(f'{WORK_DIR}/models/{MODEL_NAME}_best.pth'))\n",
    "    \n",
    "    if model_path in run_record:\n",
    "        model.load_state_dict(torch.load(model_path))    \n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=hyp[\"learning_rate\"], weight_decay=DECAY)\n",
    "    \n",
    "    criterion = power_loss\n",
    "    \n",
    "    #Log model, criterion, and optimizer\n",
    "    run[\"config/model\"] = type(model).__name__\n",
    "    run[\"config/criterion\"] = type(criterion).__name__\n",
    "    run[\"config/optimizer\"] = type(optimizer).__name__\n",
    "\n",
    "    \n",
    "    if hyp[\"scheduler\"] == \"step\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "                                                                  patience=hyp[\"scheduler_patience\"],\n",
    "                                                                  min_lr=1e-6, factor=hyp[\"scheduler_factor\"])\n",
    "    elif hyp[\"scheduler\"] == \"cycle\":\n",
    "        lr_scheduler = scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hyp[\"learning_rate\"] * 20,\n",
    "                                                                       steps_per_epoch=1, epochs=EPOCHS,\n",
    "                                                                       pct_start=0.125,\n",
    "                                                                       div_factor=hyp[\"scheduler_factor\"] ** -1,\n",
    "                                                                       final_div_factor=(hyp[\"scheduler_factor\"] ** -1) * 50)\n",
    "    else:\n",
    "        lr_scheduler = None\n",
    "    \n",
    "    history = train(model, x, optimizer, power_loss,\n",
    "                    epochs=EPOCHS, print_every=100,\n",
    "                    callbacks=callbacks, lr_scheduler=lr_scheduler, run_record=run_record, model_path=model_path)\n",
    "\n",
    "    run_record[model_path] = {'hyperparams': hyp,\n",
    "                              'history': history,\n",
    "                              'final_val_metric': callbacks[1].best_monitor}\n",
    "    \n",
    "    with open(f'{WORK_DIR}/history/{MODEL_NAME}_history.json', 'w') as fp:\n",
    "        json.dump(run_record, fp)\n",
    "\n",
    "    print(f\"Best Train loss %4.4f\" % (callbacks[1].best_monitor))\n",
    "\n",
    "    model = None\n",
    "    optimizer = None\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "best_val_metric = None\n",
    "best_hyperparams = None\n",
    "best_run = None\n",
    "best_model_path = None\n",
    "\n",
    "for key, train_info in run_record.items():\n",
    "    if best_val_metric is None or best_val_metric > train_info['final_val_metric']:\n",
    "        best_val_metric = train_info['final_val_metric']\n",
    "        best_hyperparams = train_info['hyperparams']\n",
    "        best_run = train_info\n",
    "        best_model_path = key\n",
    "\n",
    "with open(f'{WORK_DIR}/history/{MODEL_NAME}_history.json', 'w') as fp:\n",
    "    json.dump(run_record, fp)\n",
    "\n",
    "best_hyp = str(best_hyperparams).replace(\"}\", \"\")\n",
    "best_hyp = best_hyp.replace(\"{\", \"\")\n",
    "best_hyp = best_hyp.replace(\"'\", \"\")\n",
    "\n",
    "print(f\"Best Train loss: %4.4f, best hyperparams: %s\" % (best_val_metric, best_hyp))\n",
    "\n",
    "model = UNet(in_channels=IN_CH, out_channels=OUT_CH, init_features=NoOfFeatures, use_bn=best_hyperparams[\"use_bn\"])\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "torch.save(model.state_dict(), f'{WORK_DIR}/models/{MODEL_NAME}_best.pth')\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "psi = model.forward(x)\n",
    "\n",
    "plot_train_history(best_run['history'])\n",
    "\n",
    "simulation_time = time.time() - start_time\n",
    "print(f'Final loss: {power_loss(psi).cpu().item() :.3f}')\n",
    "print('simulation time:{:.0f}m {:.0f}s'.format(\n",
    "      simulation_time // 60, simulation_time % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhZutgNIyYhH"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet(in_channels=IN_CH, out_channels=OUT_CH, init_features=NoOfFeatures, use_bn=best_hyperparams[\"use_bn\"])\n",
    "# model.load_state_dict(torch.load(best_model_path))\n",
    "# model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix psi function on the boundaries\n",
    "psi_masked = psi.clone().detach()\n",
    "psi_masked[:,:,:NL,:]  = psimm[1].to('cpu')\n",
    "psi_masked[:,:,-NL:,:] = psipp[1].to('cpu')\n",
    "    \n",
    "\n",
    "v1, v2, v3 = velocityDistr(psi_masked[0,0,:,:]*0, psi_masked[0,0,:,:], psi_masked[0,0,:,:]*0, DX1N, DX2N, DX3N, L[0], L[1], L[2])\n",
    "\n",
    "#dv1dx1, dv2dx2, dv3dx3, divV  = divVel(v1, v2, v3, DX1N, DX2N, DX3N, L[0], L[1], L[2])\n",
    "\n",
    "#V = torch.stack([v1,v2,v3])\n",
    "#Vabs = torch.sqrt(v1**2 + v2**2 + v3**2)\n",
    "xi11, xi12, xi13, xi22, xi23, xi33, EtaEta = TksiDistr(v1, v2, v3, DX1N, DX2N, DX3N, L[0], L[1], L[2])\n",
    "\n",
    "#Subintegral expression with masks for fluid and walls, respectively:\n",
    "subInt = ((0.5*Q0*EtaEta + ((Q1/(Z+1))*EtaEta**((Z+1)*0.5)))*img[0,:,slices[1],:].to(DEVICE) +\n",
    "          (0.5*Q0W*EtaEta + ((Q1W/(ZW+1))*EtaEta**((ZW+1)*0.5)))*(1-img[0,:,slices[1],:].to(DEVICE))) \n",
    "#Integral\n",
    "out = int_func_simpson_2d(subInt, DX1N*L[0], DX3N*L[2])*L[1]\n",
    "    \n",
    "print(f'internal power: Int = {out},')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EtaEta.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subInt.size(),psi.size(),v3.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowVisualization(psi_masked.permute(1,0,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(v3.cpu().detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum velocity value in a slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3max = v3[:, slices[2]].max()\n",
    "v3max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean velocity in the flow domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.meshgrid(np.arange(0, SIZE[0], STEP3D),\n",
    "                np.arange(0, SIZE[1], STEP3D),\n",
    "                np.arange(0, SIZE[2], STEP3D))\n",
    "v_all = torch.stack((v1.cpu() * img[0].cpu(), v2.cpu() * img[0].cpu(), v3.cpu() * img[0].cpu()), 3)\n",
    "v_abs = torch.sqrt(v_all[:, :, :, 0]**2 + v_all[:, :, :, 1]**2 + v_all[:, :, :, 2]**2)\n",
    "print(v_all.size())\n",
    "vector_plot_3d(x, v_all.cpu().detach().rot90(), v_abs.rot90(), figSize=FIGSIZE*4, step = STEP3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1A, X2A = torch.meshgrid(X1N, X2N)\n",
    "fig, ax = plt.subplots(figsize=(FIGSIZE*2, FIGSIZE*2),subplot_kw={\"projection\": \"3d\"})\n",
    "surf = ax.plot_surface(np.array(X1A),np.array(X2A), np.array(v3[:,:,slices[2]].to('cpu')), cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "plt.title('$v_3$ $(x_1,x_2,x_3=const)$')\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'Loss':out,\n",
    "          \n",
    "           }\n",
    "run[\"config/results\"] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpGo7xQz6cny"
   },
   "source": [
    "# Links\n",
    "\n",
    "[1]. https://github.com/Mechanics-Mechatronics-and-Robotics/Mathematical_modelling/blob/main/Practice_1_by_IStebakov.ipynb\n",
    "\n",
    "[2]. https://github.com/mateuszbuda/brain-segmentation-pytorch"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
