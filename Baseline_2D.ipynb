{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJkKJ83igGYb"
   },
   "source": [
    "# **Physics-based deep learning in application to fluids flow modelling: 2D flows**\n",
    "\n",
    "Baseline: it is supposed that the Newtonian fluid flows between 2 paralle plates with the gap of $2R$. The flow is steady, the Reynolds number is smaller than the critical one (for the pipe $Re < Re^* {\\approx} 1100...1400$ and the pipe length is greater than the critical one $L_3 > 0.16RRe$). \n",
    "\n",
    "Generalization: it is supposed that the non-Newtonian fluid flows in the 2D flow domain. The flow is steady. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydwhZV95sFoN"
   },
   "source": [
    "# Initialization\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Go3JwW4hICsK"
   },
   "outputs": [],
   "source": [
    "# Pytorch modules\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import transforms\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "# Python functions\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Status bar\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Work with files and images\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os, fnmatch\n",
    "import re\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "#Log\n",
    "import neptune.new as neptune\n",
    "from neptune.new.types import File\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neptune project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: NeptuneDeprecationWarning: `init` is deprecated, use `init_run` instead. We'll end support of it in `neptune-client==1.0.0`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/avkornaev/PhysicsBasedDL/e/PHYSIC-327\n",
      "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init(\n",
    "    project=\"avkornaev/PhysicsBasedDL\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJiMmRjMGY4Ny1hYTI1LTQxZmEtYjRmZC02YzNkYWZjYzNiNjIifQ==\",\n",
    ")  # your credentials\n",
    "\n",
    "# run = neptune.init_run(\n",
    "#     project=\"chester-i-n/Physics-based-ML\",\n",
    "#     api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJhMzE0NzU5Mi1kNzM0LTQyMzEtYWE5OC03MGQyN2Q4MmU1ZGQifQ==\",\n",
    "# )  # your credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzMpruhsYD38"
   },
   "source": [
    "## Download and preprocess image of the flow domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzMpruhsYD38"
   },
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Parallel plates narrow.png', 'Parallel plates 1x16.png', 'Parallel plates.png', 'Parallel plates 1x4.png', 'Parallel plates with notch.png', 'Parallel plates 1x4 with notch.png']\n",
      "Parallel plates.png\n"
     ]
    }
   ],
   "source": [
    "path =  Path('./')\n",
    "imgPath = path/'ToyDataset'\n",
    "imgList = fnmatch.filter(os.listdir(imgPath), '*.png') #imgPath.ls()\n",
    "imgList\n",
    "#Image number from the imgList\n",
    "imgNo = 2\n",
    "print(imgList)\n",
    "print(imgList[imgNo])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download 3D image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labeledImage = Image.open(imgPath/imgList[imgNo]) #open image\n",
    "labeledImage = ImageOps.grayscale(labeledImage).resize((SIZE, SIZE) ,resample=0)\n",
    "\n",
    "labeledImage = torch.tensor(np.array(labeledImage) == 255).float()\n",
    "plt.imshow(labeledImage)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "img = labeledImage.unsqueeze(0).unsqueeze(-1)\n",
    "img = img.repeat(1, 1, 1, SIZE)\n",
    "imgDim = img.shape[1:]\n",
    "print(f'image shape: {imgDim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzMpruhsYD38"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YsKHT1J2Ibx9"
   },
   "outputs": [],
   "source": [
    "SIZE = imgDim\n",
    "#Training\n",
    "EPOCHS = 30000\n",
    "NoOfFeatures = 32 #32\n",
    "WORK_DIR = '/root/Physics_based_loss'\n",
    "IN_CH =  1 #number of input channels\n",
    "OUT_CH = 1#number of output channels\n",
    "#Loss regularization\n",
    "REG_LOSS_COEF = 1000000\n",
    "\n",
    "#SCALE_FACTOR = 1 # muliplier for the loss function\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_NAME = \"unet\"\n",
    "EARLY_STOP_PATIENCE = EPOCHS\n",
    "DECAY = 0\n",
    "PATIENCE = 0\n",
    "CONTINUE = False\n",
    "START_WITH_SAVED = True\n",
    "\n",
    "parameters = {'image_size':SIZE,\n",
    "             'Epochs':EPOCHS,\n",
    "             'Model':MODEL_NAME,\n",
    "             'No_of_features':NoOfFeatures}\n",
    "\n",
    "HYPS = []\n",
    "\n",
    "hyps = {\"Epochs\":[EPOCHS],\n",
    "        \"learning_rate\": [1e-4],\n",
    "        \"scheduler\": [\"none\"],\n",
    "        \"scheduler_factor\": [0.5],\n",
    "        \"scheduler_patience\": [int(EPOCHS*0.05)],\n",
    "        \"use_bn\": [True],\n",
    "        \"Early_stop_patience\": [EARLY_STOP_PATIENCE],\n",
    "        \"Decay\": [DECAY]} # Use or not batchnorm\n",
    "    \n",
    "for i in product(*[hyps[j] for j in hyps]):\n",
    "    HYPS.append({a:b for a, b in zip(hyps, i)})\n",
    "\n",
    "#Visualization\n",
    "STEP3D = 8\n",
    "slices = [int(imgDim[0]/2), int(imgDim[1]/2), int(imgDim[2]/2)]\n",
    "vps = 10 #vector plot step \n",
    "FIGSIZE = 5 # figure size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/neptune/new/attributes/attribute.py:64: NeptuneDeprecationWarning: The object you're logging will be implicitly cast to a string. We'll end support of this behavior in `neptune-client==1.0.0`. To log the object as a string, use `str(object)` instead.\n",
      "  return self.assign(value, wait)\n"
     ]
    }
   ],
   "source": [
    "run[\"config/parameters\"] = parameters\n",
    "run[\"config/hyperparameters\"] = hyps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORhTWZZvVw7c"
   },
   "source": [
    "## Geometry of the flow domain, fluid properties and boundary conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometry\n",
    "\n",
    "It is convenient to present the flow domain $\\Omega$ in the form of a parallelepiped $x_i^- < x_i < x_i^+$ ($\\boldsymbol{L} = [l_i] = [x_i^+ - x_i^-]$, $i = 1,2,3$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L_1 x L_2 x L_3 flow domain\n",
    "L = [0.016, 0.016, 0.52]#, [m]\n",
    "R = L[0]/8 #, [m]\n",
    "\n",
    "# Normalized coordinates, normalized finite diferences, limits and elementary volume\n",
    "X1N = torch.linspace(0, 1, SIZE[0])\n",
    "X2N = torch.linspace(0, 1, SIZE[1])\n",
    "X3N = torch.linspace(0, 1, SIZE[2])\n",
    "\n",
    "DX1N = X1N[1] - X1N[0]\n",
    "DX2N = X2N[1] - X2N[0]\n",
    "DX3N = X3N[1] - X3N[0]\n",
    "\n",
    "LIM1 = [0, L[0]]\n",
    "LIM2 = [0, L[1]]\n",
    "LIM3 = [0, L[2]]\n",
    "\n",
    "dOmega = DX1N * DX2N * DX3N * L[0] * L[1] * L[2] # elementary volume\n",
    "dOmega1 = DX1N * DX3N * L[0] * L[1] * L[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boundary conditions\n",
    "1. The values of the flow rates $Q_i(x_i^-)$, $Q_i(x_i^+)$ through the edges $x_i = x_i^-$, $x_i = x_i^+$ of the flow domain are given:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flow rates Q1-,Q2-,Q3-\n",
    "Qm = [0, 0, -1E-5]\n",
    "\n",
    "#Flow rates Q1+,Q2+,Q3+\n",
    "Qp = [0, 0, 1E-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. NL layers have fixed values of the unknown function $\\boldsymbol\\Psi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DVTEMP = 'fc' #template for the velocity function differentiation\n",
    "if  DVTEMP == 'sc':\n",
    "    NL = 3\n",
    "elif DVTEMP == 'fc':\n",
    "    NL = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Properties of non-Newtonian fluid and walls that are relatively rigid body.\n",
    "The Herschel-Bulkley law is applied:\n",
    "\\begin{equation}\n",
    "    \\mu(H)=q_0+q_1H^{z-1},\n",
    "\\end{equation}\n",
    "where $q_0$, $q_1$, $z$ are the parameters obtained from rheological tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Newtonian fluid viscosity\n",
    "Q0 = 4e-3\n",
    "Q1 = 0\n",
    "Z = 1\n",
    "# Fluid density, kg/m**3\n",
    "RHO = 1000\n",
    "#Newtonian fluid analogue\n",
    "MU = Q0\n",
    "\n",
    "#Critical Reynolds number\n",
    "Re_cr = 1100\n",
    "\n",
    "#Walls viscosity\n",
    "Q0W = 1e+0#1e-0#1e+3eye \n",
    "Q1W = 100#1e-0\n",
    "ZW =2#0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check viscosity models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1001.0000,   11.0000,    2.0000,    1.1000,    1.0100])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eta = torch.tensor([0.1, 10, 100, 1000, 10000])\n",
    "mu = Q0W + Q1W*Eta**(1-ZW)\n",
    "mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hw2AD3oWsfJb"
   },
   "source": [
    "## Additional functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JAf1YAHtV15"
   },
   "source": [
    "3D numerical derivative (not applicable in the two-dimensional case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_diff(f,dx1,dx2,dx3,template='sc'):\n",
    "    '''The following templates are applied:\n",
    "    sc - second-order central difference,\n",
    "    fc - fifth-order central difference.\n",
    "    Indexing:\n",
    "    i - index along x_1,\n",
    "    j - index along x_2,\n",
    "    k - index along x_3.\n",
    "    '''\n",
    "    #Shape\n",
    "    n1, n2, n3 = f.shape\n",
    "    \n",
    "    df_dx1, df_dx2, df_dx3 = torch.zeros(n1, n2, n3), torch.zeros(n1, n2, n3), torch.zeros(n1, n2, n3)\n",
    "    \n",
    "    #Device\n",
    "    if torch.cuda.is_available():\n",
    "        df_dx1 = df_dx1.to('cuda')\n",
    "        df_dx2 = df_dx2.to('cuda')\n",
    "        df_dx3 = df_dx3.to('cuda')\n",
    "    \n",
    "    #Derivatives\n",
    "    if template == 'sc':\n",
    "        # x1 derivative:\n",
    "        df_dx1[1:n1-1,:,:] = (f[2:,:,:] - f[:-2,:,:]) / (2 * dx1)\n",
    "        df_dx1[0,:,:] = (-f[2,:,:] + 4 * f[1,:,:] - 3 * f[0,:,:]) / (2 * dx1)\n",
    "        df_dx1[n1-1,:,:] = (3 * f[n1-1,:,:] - 4 * f[n1-2,:,:] + f[n1-3,:,:]) / (2 * dx1)\n",
    "        # x2 derivative:\n",
    "        df_dx2[:,1:n2-1, :] = (f[:, 2:, :] - f[:, :-2, :]) / (2 * dx2)\n",
    "        df_dx2[:,0, :] = (- f[:,2,:] + 4 * f[:,1,:] - 3 * f[:, 0, :]) / (2 * dx2)\n",
    "        df_dx2[:,n2-1, :] = (3 * f[:, n2 - 1, :] - 4 * f[:, n2 - 2, :] + f[:, n2 - 3, :]) / (2 * dx2)\n",
    "        # x3 derivative:\n",
    "        df_dx3[:, :, 1:n3-1] = (f[:,:,2:] - f[:,:,:-2]) / (2 * dx3)\n",
    "        df_dx3[:, :, 0] = (- f[:, :, 2] + 4 * f[:, :, 1] - 3 * f[:, :, 0]) / (2 * dx3)\n",
    "        df_dx3[:, :, n3-1] = (3 * f[:, :, n3 - 1] - 4 * f[:, :, n3 - 2] + f[:, :, n3 - 3]) / (2 * dx3)\n",
    "    elif template == 'fc':\n",
    "        # x1 derivative\n",
    "        df_dx1[2:n1-2, :, :] = (-f[4:, :,:] + 8 * f[3:n1-1, :, :] - 8 * f[1:n1-3, :, :] + f[:n1-4, :, :]) / (12 * dx1)\n",
    "        df_dx1[0, :, :] = (-3 * f[4, :, :] + 16 * f[3, :, :] - 36 * f[2, :, :] + 48 * f[1, :,:] - 25 * f[0, :, :]) / (12 * dx1)\n",
    "        df_dx1[1, :, :] = (f[4, :, :] - 6 * f[3, :, :] + 18 * f[2, :, :] - 10 * f[1, :, :] - 3 * f[0, :, :]) / (12 * dx1)\n",
    "        df_dx1[n1-2, :, :] = (3 * f[n1-1, :, :] + 10 * f[n1-2, :, :] - 18 * f[n1-3, :, :] + 6 * f[n1-4, :, :] - f[n1-5, :, :]) / (12 * dx1)\n",
    "        df_dx1[n1-1, :, :] = (25 * f[n1-1, :, :] - 48 * f[n1-2, :, :] + 36 * f[n1-3, :, :] - 16 * f[n1-4, :, :] + 3*f[n1-5, :, :]) / (12 * dx1)\n",
    "        \n",
    "        # x2 derivative\n",
    "        df_dx2[:, 2:n2-2, :] = (-f[:, 4:, :] + 8 * f[:, 3:n2-1, :] - 8 * f[:, 1:n2-3, :] + f[:, :n2-4, :]) / (12 * dx2)\n",
    "        df_dx2[:, 0, :] = (-3 * f[:,4, :] + 16 * f[:, 3, :] - 36 * f[:, 2, :] + 48 * f[:, 1, :] - 25 * f[:, 0, :]) / (12*dx2)\n",
    "        df_dx2[:, 1, :] = (f[:, 4, :] - 6 * f[:, 3, :] + 18 * f[:, 2, :] - 10 * f[:, 1, :] - 3 * f[:, 0, :]) / (12*dx2)\n",
    "        df_dx2[:, n2-2, :] = (3 * f[:, n2-1, :] + 10 * f[:, n2-2, :] - 18 * f[:, n2-3, :] + 6 * f[:, n2-4, :] - f[:, n2-5, :]) / (12*dx2)\n",
    "        df_dx2[:, n2-1, :] = (25 * f[:, n2-1, :] - 48 * f[:, n2-2, :] + 36 * f[:, n2-3, :] - 16 * f[:, n2-4, :] + 3 * f[:,n2-5, :]) / (12*dx2)       \n",
    "        # x3 derivative\n",
    "        df_dx3[:, :, 2:n3-2] = (-f[:, :, 4:] + 8 * f[:, :, 3:n3-1] - 8 * f[:, :, 1:n3-3] + f[:, :, :n3-4]) / (12 * dx3)\n",
    "        df_dx3[:, :, 0] = (-3 * f[:, :, 4] + 16 * f[:, :, 3] - 36 * f[:, :, 2] + 48 * f[:, :, 1] - 25 * f[:, :, 0]) / (12 * dx3)\n",
    "        df_dx3[:, :, 1] = (f[:, :, 4] - 6 * f[:, :, 3] + 18 * f[:, :, 2] - 10 * f[:, :, 1] - 3 * f[:, :, 0]) / (12 * dx3)\n",
    "        df_dx3[:, :, n3-2] = (3 * f[:, :, n3-1] + 10 * f[:, :, n3-2] - 18 * f[:, :, n3-3] + 6 * f[:,:,n3-4] - f[:, :, n3-5]) / (12 * dx3)\n",
    "        df_dx3[:, :, n3-1] = (25 * f[:,:, n3-1] - 48 * f[:,:, n3-2] + 36 * f[:,:, n3-3] - 16 * f[:,:, n3-4] + 3*f[:,:, n3-5]) / (12 * dx3)\n",
    "    \n",
    "    return df_dx1, df_dx2, df_dx3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D numerical derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_diff2D(f,dx1,dx2,template=DVTEMP):\n",
    "    '''The following templates are applied:\n",
    "    sc - second-order central difference,\n",
    "    fc - fifth-order central difference.\n",
    "    Indexing:\n",
    "    i - index along x_1,\n",
    "    j - index along x_2.\n",
    "    '''\n",
    "    #Shape\n",
    "    n1, n2 = f.shape\n",
    "    \n",
    "    df_dx1, df_dx2 = torch.zeros(n1, n2), torch.zeros(n1, n2)\n",
    "    \n",
    "    #Device\n",
    "    if torch.cuda.is_available():\n",
    "        df_dx1 = df_dx1.to('cuda')\n",
    "        df_dx2 = df_dx2.to('cuda')\n",
    "            \n",
    "    #Derivatives\n",
    "    if template == 'sc':\n",
    "        # x1 derivative:\n",
    "        df_dx1[1:n1-1,:] = (f[2:,:] - f[:-2,:]) / (2 * dx1)\n",
    "        df_dx1[0,:] = (-f[2,:] + 4 * f[1,:] - 3 * f[0,:]) / (2 * dx1)\n",
    "        df_dx1[n1-1,:] = (3 * f[n1-1,:] - 4 * f[n1-2,:] + f[n1-3,:]) / (2 * dx1)\n",
    "        # x2 derivative:\n",
    "        df_dx2[:,1:n2-1] = (f[:, 2:] - f[:, :-2]) / (2 * dx2)\n",
    "        df_dx2[:,0] = (- f[:,2] + 4 * f[:,1] - 3 * f[:, 0]) / (2 * dx2)\n",
    "        df_dx2[:,n2-1] = (3 * f[:, n2 - 1] - 4 * f[:, n2 - 2] + f[:, n2 - 3]) / (2 * dx2)\n",
    "    elif template == 'fc':\n",
    "        # 1st order x1 derivative:\n",
    "        # x1 derivative\n",
    "        df_dx1[2:n1-2, :] = (-f[4:, :] + 8 * f[3:n1-1, :] - 8 * f[1:n1-3, :] + f[:n1-4, :]) / (12 * dx1)\n",
    "        df_dx1[0, :] = (-3 * f[4, :] + 16 * f[3, :] - 36 * f[2, :] + 48 * f[1, :] - 25 * f[0, :]) / (12 * dx1)\n",
    "        df_dx1[1, :] = (f[4, :] - 6 * f[3, :] + 18 * f[2, :] - 10 * f[1, :] - 3 * f[0, :]) / (12 * dx1)\n",
    "        df_dx1[n1-2, :] = (3 * f[n1-1, :] + 10 * f[n1-2, :] - 18 * f[n1-3, :] + 6 * f[n1-4, :] - f[n1-5, :]) / (12 * dx1)\n",
    "        df_dx1[n1-1, :] = (25 * f[n1-1, :] - 48 * f[n1-2, :] + 36 * f[n1-3, :] - 16 * f[n1-4, :] + 3*f[n1-5, :]) / (12 * dx1)\n",
    "        \n",
    "        # x2 derivative\n",
    "        df_dx2[:, 2:n2-2] = (-f[:, 4:] + 8 * f[:, 3:n2-1] - 8 * f[:, 1:n2-3] + f[:, :n2-4]) / (12 * dx2)\n",
    "        df_dx2[:, 0] = (-3 * f[:,4] + 16 * f[:, 3] - 36 * f[:, 2] + 48 * f[:, 1] - 25 * f[:, 0]) / (12*dx2)\n",
    "        df_dx2[:, 1] = (f[:, 4] - 6 * f[:, 3] + 18 * f[:, 2] - 10 * f[:, 1] - 3 * f[:, 0]) / (12*dx2)\n",
    "        df_dx2[:, n2-2] = (3 * f[:, n2-1] + 10 * f[:, n2-2] - 18 * f[:, n2-3] + 6 * f[:, n2-4] - f[:, n2-5]) / (12*dx2)\n",
    "        df_dx2[:, n2-1] = (25 * f[:, n2-1] - 48 * f[:, n2-2] + 36 * f[:, n2-3] - 16 * f[:, n2-4] + 3 * f[:,n2-5]) / (12*dx2)    \n",
    "    \n",
    "    return df_dx1, df_dx2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D numerical integration (Simpson method) (not applicable in the two-dimensional case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_func_simpson_3d(f, dx, dy, dz):\n",
    "  '''\n",
    "  f - 3d-dimentional tensor\n",
    "  dx, dy, dz - constant step along the corresponding coordinate\n",
    "  '''\n",
    "  n1,n2,n3 = f.shape\n",
    "  # integrate by dz:\n",
    "  if n3%2 == 0:\n",
    "    J3 = (f[:,:,0:n3-2:2] + 4*f[:,:,1:n3-2:2] + f[:,:,2::2]).sum(dim=2)*dz/3 + (f[:,:,-1]+f[:,:,-2])*dz/2\n",
    "  else:\n",
    "    J3 = (f[:,:,0:n3-1:2] + 4*f[:,:,1:n3-1:2] + f[:,:,2::2]).sum(dim=2)*dz/3\n",
    "\n",
    "  # integrate by dy:\n",
    "  if n2%2 == 0:\n",
    "    J2 = (J3[:,0:n2-2:2] + 4*J3[:,1:n2-2:2] + J3[:,2::2]).sum(dim=1)*dy/3 + (J3[:,-1]+J3[:,-2])*dy/2\n",
    "  else:\n",
    "    J2 = (J3[:,0:n2-1:2] +4 *J3[:,1:n2-1:2] + J3[:,2::2]).sum(dim=1)*dy/3\n",
    "\n",
    "  # integrate by dx:\n",
    "  if n1%2 == 0:\n",
    "    J1 = (J2[0:n1-2:2] + 4*J2[1:n1-2:2] + J2[2::2]).sum(dim=0)*dx/3 + (J2[-1]+J2[-2])*dx/2\n",
    "  else:\n",
    "    J1 = (J2[0:n1-1:2] + 4*J2[1:n1-1:2] + J2[2::2]).sum(dim=0)*dx/3\n",
    "\n",
    "  return J1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D numerical integration (Simpson method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_func_simpson_2d(f, dx, dy):\n",
    "  '''\n",
    "  f - 2d-dimentional tensor\n",
    "  dx, dy - constant step along the corresponding coordinate\n",
    "  '''\n",
    "  n1, n2 = f.shape\n",
    "  # integrate by dy:\n",
    "  if n2%2 == 0:\n",
    "    J2 = (f[:,0:n2-2:2]+ 4*f[:,1:n2-2:2] + f[:,2::2]).sum(dim=1)*dy/3 + (f[:,-1]+f[:,-2])*dy/2\n",
    "  else:\n",
    "    J2 = (f[:,0:n2-1:2] +4*f[:,1:n2-1:2]+f[:,2::2]).sum(dim=1)*dy/3\n",
    "  # integrate by dx:\n",
    "  if n1%2 == 0:\n",
    "    J1 = (J2[0:n1-2:2]+ 4*J2[1:n1-2:2] + J2[2::2]).sum(dim=0)*dx/3 + (J2[-1]+J2[-2])*dx/2\n",
    "  else:\n",
    "    J1 = (J2[0:n1-1:2] +4*J2[1:n1-1:2]+J2[2::2]).sum(dim=0)*dx/3\n",
    "  return J1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_plot(x, y, u, v, FIGSIZE, vptitle='vector_plot', xlabel='$x_i$', ylabel='$x_j$',step=10):\n",
    "    gradmag = np.sqrt(u**2 + v**2)\n",
    "    plt.pcolor(x, y, gradmag, cmap='rainbow')\n",
    "    plt.colorbar()\n",
    "    plt.quiver(x[::step,::step], y[::step,::step], u[::step,::step], v[::step,::step])\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(vptitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_plot_3d(x, v, v_abs, figSize=FIGSIZE, step=1, use_color=False):\n",
    "    fig = plt.figure(figsize=(figSize, figSize))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    \n",
    "    norm = plt.Normalize()\n",
    "    colors = plt.cm.jet(norm(v_abs[::step, ::step, ::step]))\n",
    "\n",
    "    pos = np.where(img[0].rot90().cpu().detach()==1)\n",
    "    ax.scatter(pos[1], pos[0], pos[2], c='red', s=0.1, alpha=0.2)\n",
    "    ax.quiver(x[0], x[1], x[2], v[::step, ::step, ::step, 0],\n",
    "              v[::step, ::step, ::step, 1],\n",
    "              v[::step, ::step, ::step, 2],\n",
    "              color=colors.reshape(-1, 4) if use_color else 'b', length=20, normalize=False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_zticks([])\n",
    "    ax.bar3d(0, 0, 0., SIZE[0], SIZE[1], SIZE[2], alpha=0.1, edgecolor='black', color='black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flowVisualization(psi,step=15,slices=slices):\n",
    "    nr=2\n",
    "    nc=len(SIZE)\n",
    "    \n",
    "    #Velocity distribution\n",
    "    v1, v2, v3 = velocityDistr(psi[0,0,:,:].to('cpu')*0, psi[0,0,:,:].to('cpu'), psi[0,0,:,:].to('cpu')*0,\n",
    "                               DX1N.to('cpu'), DX2N.to('cpu'), DX3N.to('cpu'),\n",
    "                               L[0], L[1], L[2])\n",
    "    V = torch.stack([v1.to('cpu'),v2.to('cpu'),v3.to('cpu')])\n",
    "    print(V.shape)\n",
    "    Vabs = torch.sqrt(v1.to('cpu')**2 + v2.to('cpu')**2 + v3.to('cpu')**2)\n",
    "    \n",
    "    print('Psi function Visualization')\n",
    "    fig = plt.figure(figsize=(FIGSIZE*nc, FIGSIZE*nr))\n",
    "    for i in range(1):\n",
    "        plt.subplot(nr,nc,i+1)\n",
    "        plt.imshow(psi[0,i,::].to('cpu'))\n",
    "        plt.title(f'$\\psi_{i+1}$')\n",
    "        plt.subplot(nr,nc,i+1+nc)\n",
    "        plt.plot(psi[0,i,:,slices[i]].to('cpu'))\n",
    "        plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "#     print(f'Q1+ = {- (psi[0,1,-1,-1] - psi[0,1,-1,0])*L[1] + (psi[0,2,-1,-1] - psi[0,2,-1,0])*L[2]}, target value: {Qp[0]},')\n",
    "#     print(f'Q2+ = {- (psi[0,2,-1,-1] - psi[0,2,0,-1])*L[2] + (psi[0,0,-1,-1] - psi[0,0,-1,0])*L[0]}, target value: {Qp[1]},')\n",
    "#     print(f'Q3+ = {- (psi[0,0,-1,-1] - psi[0,0,0,-1])*L[0] + (psi[0,1,-1,-1] - psi[0,1,0,-1])*L[1]}, target value: {Qp[2]}')\n",
    "    \n",
    "    print()\n",
    "    print('Velocity distribution visualization without flow domain mask (first line) and with mask (second line)')\n",
    "\n",
    "    XN = torch.meshgrid(X1N,X2N,X3N)\n",
    "    \n",
    "    fig1 = plt.figure(figsize=(FIGSIZE*nc, FIGSIZE*nr))\n",
    "    #without flow domain mask \n",
    "    plt.subplot(nr,nc,1)\n",
    "    vector_plot(XN[1][slices[0],:,:], XN[2][slices[0],:,:], V[1], V[2],\n",
    "                FIGSIZE, vptitle='$x_1 = const$', xlabel='$x_3$', ylabel='$x_2$', step=step)\n",
    "    plt.subplot(nr,nc,2)\n",
    "    vector_plot(XN[0][:,slices[1],:], XN[2][:,slices[1],:], V[0], V[2],\n",
    "                FIGSIZE, vptitle='$x_2 = const$', xlabel='$x_3$', ylabel='$x_1$', step=step)\n",
    "    plt.subplot(nr,nc,3)\n",
    "    vector_plot(XN[0][:,:,slices[2]], XN[1][:,:,slices[2]], V[0], V[1],\n",
    "                FIGSIZE, vptitle='$x_3 = const$', xlabel='$x_2$', ylabel='$x_1$', step=step)\n",
    "    #with flow domain mask \n",
    "    plt.subplot(nr,nc,4)\n",
    "    vector_plot(XN[1][slices[0],:,:], XN[2][slices[0],:,:], V[1]*img[0,slices[0],:,:].to('cpu'), V[2]*img[0,slices[0],:,:].to('cpu'),\n",
    "                FIGSIZE, vptitle='$x_1 = const$', xlabel='$x_3$', ylabel='$x_2$', step=step)\n",
    "    plt.subplot(nr,nc,5)\n",
    "    vector_plot(XN[0][:,slices[1],:], XN[2][:,slices[1],:], V[0]*img[0,:,slices[1],:].to('cpu'), V[2]*img[0,:,slices[1],:].to('cpu'),\n",
    "                FIGSIZE, vptitle='$x_2 = const$', xlabel='$x_3$', ylabel='$x_1$', step=step)\n",
    "    plt.subplot(nr,nc,6)\n",
    "    vector_plot(XN[0][:,:,slices[2]], XN[1][:,:,slices[2]], V[0]*img[0,:,:,slices[2]].to('cpu'), V[1]*img[0,:,:,slices[2]].to('cpu'),\n",
    "                FIGSIZE, vptitle='$x_3 = const$', xlabel='$x_2$', ylabel='$x_1$', step=step)\n",
    "    \n",
    "    #Check the flow rates Q3-,Q3+\n",
    "#     Q1mch = int_func_simpson_2d(V[0, 0, :, :], L[1]*DX2N.to('cpu'), L[2]*DX3N.to('cpu'))\n",
    "#     Q1pch = int_func_simpson_2d(V[0,-1, :, :], L[1]*DX2N.to('cpu'), L[2]*DX3N.to('cpu'))\n",
    "    \n",
    "#     Q2mch = int_func_simpson_2d(V[1, :, 0, :], L[0]*DX1N.to('cpu'), L[2]*DX3N.to('cpu'))\n",
    "#     Q2pch = int_func_simpson_2d(V[1, :,-1, :], L[0]*DX1N.to('cpu'), L[2]*DX3N.to('cpu'))\n",
    "    \n",
    "#     Q3mch = int_func_simpson_2d(V[2, :, :, 0], L[0]*DX1N.to('cpu'), L[1]*DX2N.to('cpu'))\n",
    "#     Q3pch = int_func_simpson_2d(V[2, :, :,-1], L[0]*DX1N.to('cpu'), L[1]*DX2N.to('cpu'))\n",
    "    \n",
    "#     print(f'{V[0].min()} < v_1 < {V[0].max()},')\n",
    "#     print(f'{V[1].min()} < v_2 < {V[1].max()},')\n",
    "#     print(f'{V[2].min()} < v_3 < {V[2].max()},')\n",
    "#     print(f'Q1- = {Q1mch}, Q1+ = {Q1pch}')\n",
    "#     print(f'Q2- = {Q2mch}, Q2+ = {Q2pch}')\n",
    "#     print(f'Q3- = {Q3mch}, Q3+ = {Q3pch}')\n",
    "    \n",
    "#     print(f'Vabs[0,0,0] = {Vabs[0,0,0]}, Vabs[0,0,-1] = {Vabs[0,0,-1]}, Vabs[0,-1,0] = {Vabs[0,-1,0]}, Vabs[0,-1,-1] = {Vabs[0,-1,-1]}, Vabs[-1,0,0] = {Vabs[-1,0,0]}, Vabs[-1,0,-1] = {Vabs[-1,0,-1]}, Vabs[-1,-1,0] = {Vabs[-1,-1,0]}, Vabs[-1,-1,-1] = {Vabs[-1,-1,-1]},')\n",
    "  \n",
    "#     return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mH8zURs8A1Sr"
   },
   "source": [
    "## Major functions\n",
    "\n",
    "For any given function $\\boldsymbol\\Psi = [\\psi_i]$ that has fixed values on the boundaries of the flow domain together with its first, second, and third derivatives, the velocity distribution can be expressed in compact or in expanded form, respectively:\n",
    "\\begin{equation} \n",
    "    \\boldsymbol{V} = \n",
    "    \\begin{bmatrix}\n",
    "    \\epsilon_{ijk}\n",
    "    \\frac{\\partial \\psi_k(x_i,x_j)}{\\partial x_j}\n",
    "    \\end{bmatrix},\n",
    "\\end{equation}\n",
    "where $\\epsilon_{ijk}$ is the Levi-Civita symbol,\n",
    "\n",
    "\\begin{equation} \n",
    "    \\boldsymbol{V} = \n",
    "    \\begin{bmatrix}\n",
    "    \\frac{\\partial \\psi_3}{\\partial x_2} - \\frac{\\partial \\psi_2}{\\partial x_3}, &\n",
    "    \\frac{\\partial \\psi_1}{\\partial x_3} - \\frac{\\partial \\psi_3}{\\partial x_1}, &\n",
    "    \\frac{\\partial \\psi_2}{\\partial x_1} - \\frac{\\partial \\psi_1}{\\partial x_2}\n",
    "    \\end{bmatrix}.\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "WMUIipgs5t3Q"
   },
   "outputs": [],
   "source": [
    "def velocityDistr(psi1,psi2,psi3,dx1n,dx2n,dx3n,deltax1,deltax2,deltax3):\n",
    "    '''Velocity distribution [v_i] in the flow domain\n",
    "    '''\n",
    "    \n",
    "# #Psi function and it's partial derivatives are 2D functions\n",
    "#     dpsi1dx2, dpsi1dx3 = num_diff2D(psi1, dx2n, dx3n)\n",
    "#     dpsi2dx1, dpsi2dx3 = num_diff2D(psi2, dx1n, dx3n)\n",
    "#     dpsi3dx1, dpsi3dx2 = num_diff2D(psi3, dx1n, dx2n)\n",
    "    \n",
    "#     #Expand into 3D, then calculate the velocity distribution\n",
    "#     dpsi1dx2 = torch.unsqueeze(dpsi1dx2,0)\n",
    "#     dpsi1dx3 = torch.unsqueeze(dpsi1dx3,0)\n",
    "    \n",
    "#     dpsi2dx1 = torch.unsqueeze(dpsi2dx1,1)\n",
    "#     dpsi2dx3 = torch.unsqueeze(dpsi2dx3,1)\n",
    "    \n",
    "#     dpsi3dx1 = torch.unsqueeze(dpsi3dx1,2)\n",
    "#     dpsi3dx2 = torch.unsqueeze(dpsi3dx2,2)\n",
    "    \n",
    "#     v1 = (dpsi3dx2.expand(-1,-1,SIZE[2]) / deltax2) - (dpsi2dx3.expand(-1,SIZE[1],-1) / deltax3)\n",
    "#     v2 = (dpsi1dx3.expand(SIZE[0],-1,-1) / deltax3) - (dpsi3dx1.expand(-1,-1,SIZE[2]) / deltax1)\n",
    "#     v3 = (dpsi2dx1.expand(-1,SIZE[1],-1) / deltax1) - (dpsi1dx2.expand(SIZE[0],-1,-1) / deltax2)   \n",
    "\n",
    "#Psi function and it's partial derivatives are 2D functions\n",
    "    #dpsi1dx2, dpsi1dx3 = num_diff2D(psi1, dx2n, dx3n)\n",
    "    dpsi2dx1, dpsi2dx3 = num_diff2D(psi2, dx1n, dx3n)\n",
    "    #dpsi3dx1, dpsi3dx2 = num_diff2D(psi3, dx1n, dx2n)\n",
    "    \n",
    "    v1 =  - (dpsi2dx3 / deltax3)\n",
    "    v2 = dpsi2dx3 * 0\n",
    "    v3 = (dpsi2dx1 / deltax1)   \n",
    "    \n",
    "    return v1, v2, v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking into account the symmetry of the shear rate tensor $\\xi_{i,j}=\\xi_{i,j}$, the tensor has the following form:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\boldsymbol{T}_\\xi= \\frac{1}{2}   \n",
    "    \\begin{bmatrix}\n",
    "    2\\frac{\\partial v_1}{\\partial x_1}, & \\frac{\\partial v_1}{\\partial x_2} - \\frac{\\partial v_2}{\\partial x_1}, & \\frac{\\partial v_1}{\\partial x_3} - \\frac{\\partial v_3}{\\partial x_1} \\\\\n",
    "     \\frac{\\partial v_1}{\\partial x_2} - \\frac{\\partial v_2}{\\partial x_1}, & 2\\frac{\\partial v_2}{\\partial x_2}, & \\frac{\\partial v_2}{\\partial x_3} - \\frac{\\partial v_3}{\\partial x_2}  \\\\\n",
    "    \\frac{\\partial v_1}{\\partial x_3} - \\frac{\\partial v_3}{\\partial x_1}, & \\frac{\\partial v_2}{\\partial x_3} - \\frac{\\partial v_3}{\\partial x_2},  & 2\\frac{\\partial v_3}{\\partial x_3}  \\\\\n",
    "    \\end{bmatrix}.\n",
    "\\end{equation}\n",
    "\n",
    "In the general case of a three dimensional flow the shear strain rate intensity $H$ depends on all the components of the shear rate tensor:\n",
    "\\begin{equation}\n",
    "    H =\\sqrt{2(\\xi_{11}^2 + \\xi_{22}^2 + \\xi_{33}^2 + 2\\xi_{12}^2 + 2\\xi_{13}^2 + 2\\xi_{23}^2)}. \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "716qlRJoNglx"
   },
   "outputs": [],
   "source": [
    "def TksiDistr(v1,v2,v3,dx1n,dx2n,dx3n,deltax1,deltax2,deltax3):\n",
    "    '''Strain rate tensor Txi and the shear rate intensity Eta squared\n",
    "    '''    \n",
    "    \n",
    "#     dv1dx1, dv1dx2, dv1dx3 = num_diff(v1, dx1n, dx2n, dx3n)\n",
    "#     dv2dx1, dv2dx2, dv2dx3 = num_diff(v2, dx1n, dx2n, dx3n)\n",
    "#     dv3dx1, dv3dx2, dv3dx3 = num_diff(v3, dx1n, dx2n, dx3n)\n",
    "    \n",
    "#     #Txi\n",
    "#     xi11 = dv1dx1 / deltax1\n",
    "#     xi12 = 0.5 * ((dv1dx2 / deltax2) + (dv2dx1 / deltax1))\n",
    "#     xi13 = 0.5 * ((dv1dx3 / deltax3) + (dv3dx1 / deltax1))\n",
    "    \n",
    "#     xi22 = dv2dx2 / deltax2\n",
    "#     xi23 = 0.5 * ((dv2dx3 / deltax3) + (dv3dx2 / deltax2))\n",
    "    \n",
    "#     xi33 = dv3dx3 / deltax3\n",
    "    \n",
    "#     #Eta^2    \n",
    "#     EtaEta = (2 * (xi11 * xi11 + xi22 * xi22 + xi33 * xi33 + \n",
    "#                    2 * (xi12 * xi12 + xi13 * xi13 + xi23 * xi23)))\n",
    "    \n",
    "    dv1dx1, dv1dx3 = num_diff2D(v1, dx1n, dx3n)\n",
    "    dv2dx1, dv2dx3 = num_diff2D(v2, dx1n, dx3n)\n",
    "    dv3dx1, dv3dx3 = num_diff2D(v3, dx1n, dx3n)\n",
    "    \n",
    "    #Txi\n",
    "    xi11 = dv1dx1 / deltax1\n",
    "    xi12 = dv1dx1 * 0\n",
    "    xi13 = 0.5 * ((dv1dx3 / deltax3) + (dv3dx1 / deltax1))\n",
    "    \n",
    "    xi22 = dv1dx1 * 0\n",
    "    xi23 = dv1dx1 * 0\n",
    "    \n",
    "    xi33 = dv1dx1 * 0\n",
    "    \n",
    "    #Eta^2    \n",
    "    EtaEta = (2 * (xi11 * xi11 + xi22 * xi22 + xi33 * xi33 + \n",
    "                   2 * (xi12 * xi12 + xi13 * xi13 + xi23 * xi23)))\n",
    "  \n",
    "    return xi11, xi12, xi13, xi22, xi23, xi33, EtaEta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divVel(v1,v2,v3,dx1n,dx2n,dx3n,deltax1,deltax2,deltax3):\n",
    "    \n",
    "    dv1dx1, dv1dx2, dv1dx3 = num_diff(v1, dx1n, dx2n, dx3n)\n",
    "    dv2dx1, dv2dx2, dv2dx3 = num_diff(v2, dx1n, dx2n, dx3n)\n",
    "    dv3dx1, dv3dx2, dv3dx3 = num_diff(v3, dx1n, dx2n, dx3n)\n",
    "    \n",
    "    divV = dv1dx1 + dv2dx2 + dv3dx3\n",
    "    \n",
    "    return dv1dx1, dv2dx2, dv3dx3, divV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStop():\n",
    "    \"\"\"Callback for early stop train process.\n",
    "    \n",
    "    Args:\n",
    "        monitor (str): value for monitoring.\n",
    "        patience (int): Number of epochs with no improvement after which training will be stopped.\n",
    "        mode (str): One of {\"min\", \"max\"}. In min mode, training will stop when the quantity monitored has stopped decreasing.\n",
    "            In \"max\" mode it will stop when the quantity monitored has stopped increasing.\n",
    "    \n",
    "    Attributes:\n",
    "        history (dict): Dict of lists with train history. Key \"monitor\" contains list of monitoring values. \n",
    "        steps (int): Number of passed epoches. \n",
    "        best_step (int): Number of best epoch. \n",
    "        best_monitor (float): Best of monitoring value.\n",
    "        model (Model): Training model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, monitor, patience, mode):\n",
    "        self.monitor = monitor\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.history = None\n",
    "        self.steps = -1\n",
    "        self.best_step = -1\n",
    "        if self.mode == 'max':\n",
    "            self.best_monitor = 0\n",
    "        elif self.mode == 'min':\n",
    "            self.best_monitor = 1e99999\n",
    "            \n",
    "    def start(self, history, model):\n",
    "        \"\"\"Start and init callback.\n",
    "        \n",
    "        Args:\n",
    "            history (dict): Dict of lists with train history. Key \"monitor\" contains list of monitoring values. \n",
    "            model (Model): Training model.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.history = history\n",
    "        self.model = model\n",
    "        \n",
    "    def step(self, save=True):\n",
    "        \"\"\"Make a step of callback.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (event, stop):\n",
    "                event (str): Decription of event. If event not did not happen then event = ''.\n",
    "                stop (bool): Flag of stopping train process.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.steps += 1\n",
    "        \n",
    "        if self.mode == 'max':\n",
    "            if self.history[self.monitor][-1] > self.best_monitor:\n",
    "                self.best_monitor = self.history[self.monitor][-1]\n",
    "                self.best_step = self.steps\n",
    "        elif self.mode == 'min':\n",
    "            if self.history[self.monitor][-1] < self.best_monitor:\n",
    "                self.best_monitor = self.history[self.monitor][-1]\n",
    "                self.best_step = self.steps\n",
    "        \n",
    "        if self.steps - self.best_step > self.patience:\n",
    "            return 'Early stop with {}: {:.4f}'.format(self.monitor, self.history[self.monitor][self.best_step]), True\n",
    "        return None, False\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"Delete model from callback.\"\"\"\n",
    "        \n",
    "        self.model = None\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "class SaveBest():\n",
    "    \"\"\"Callback for save model if there is an improvement.\n",
    "    \n",
    "    Args:\n",
    "        monitor (str): value for monitoring.\n",
    "        model_path (str): Path for saving model.\n",
    "        mode (str): One of {\"min\", \"max\"}. In min mode, training will stop when the quantity monitored has stopped decreasing.\n",
    "            In \"max\" mode it will stop when the quantity monitored has stopped increasing.\n",
    "    \n",
    "    Attributes:\n",
    "        history (dict): Dict of lists with train history. Key \"monitor\" contains list of monitoring values. \n",
    "        steps (int): Number of passed epoches. \n",
    "        best_step (int): Number of best epoch. \n",
    "        best_monitor (float): Best of monitoring value.\n",
    "        model (Model): Training model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, monitor, model_path, mode):\n",
    "        self.monitor = monitor\n",
    "        self.model_path = model_path\n",
    "        self.mode = mode\n",
    "        self.history = None\n",
    "        self.steps = -1\n",
    "        self.best_step = -1\n",
    "        if self.mode == 'max':\n",
    "            self.best_monitor = 0\n",
    "        elif self.mode == 'min':\n",
    "            self.best_monitor = 1e99999\n",
    "    \n",
    "    def start(self, history, model):\n",
    "        \"\"\"Start and init callback. Save first version of model.\n",
    "        \n",
    "        Args:\n",
    "            history (dict): Dict of lists with train history. Key \"monitor\" contains list of monitoring values. \n",
    "            model (Model): Training model\n",
    "        \"\"\"\n",
    "        \n",
    "        self.history = history\n",
    "        self.model = model\n",
    "        torch.save(self.model.state_dict(), self.model_path)\n",
    "    \n",
    "    def step(self, save=True):\n",
    "        \"\"\"Make a step of callback.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (event, stop):\n",
    "                event (str): Decription of event. If event not did not happen then event = ''.\n",
    "                stop (bool): Flag of stopping train process.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.steps += 1\n",
    "        \n",
    "        if self.mode == 'max':\n",
    "            if self.history[self.monitor][-1] > self.best_monitor:\n",
    "                self.best_monitor = self.history[self.monitor][-1]\n",
    "                self.best_step = self.steps\n",
    "        elif self.mode == 'min':\n",
    "            if self.history[self.monitor][-1] < self.best_monitor:\n",
    "                self.best_monitor = self.history[self.monitor][-1]\n",
    "                self.best_step = self.steps\n",
    "        \n",
    "        if self.steps == self.best_step:\n",
    "            if save:\n",
    "                torch.save(self.model.state_dict(), self.model_path)\n",
    "            return 'Save model with {}: {:.4f}'.format(self.monitor, self.history[self.monitor][self.best_step]), False\n",
    "        return None, False\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"Delete model from callback.\"\"\"\n",
    "        \n",
    "        self.model = None\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, inp, optimizer,\n",
    "          criterion, epochs, print_every, callbacks, lr_scheduler, run_record, model_path):\n",
    "    \"\"\"Make model prediction on image.\n",
    "    \n",
    "    Args:\n",
    "        model (Model): Model for training.\n",
    "        inp (Tensor): Inpu image.\n",
    "        optimizer (Optimizer): Optimizer. \n",
    "        criterion (callable): Function for loss calculation.\n",
    "        epochs (int): Number of epoches.\n",
    "        print_every (int): Number of iteration for update statusbar.\n",
    "        callbacks (list): List of callbacks\n",
    "    \n",
    "    Returns:\n",
    "        history (dict): Dict of lists with train history.\n",
    "    \"\"\"\n",
    "    if 'history' in run_record[model_path]:\n",
    "        history = run_record[model_path]['history']\n",
    "    else:\n",
    "        history = {'Train loss':[]}\n",
    "    \n",
    "    if callbacks:\n",
    "        for i in callbacks:\n",
    "            i.start(history, model)\n",
    "    \n",
    "    train_print = ''\n",
    "    state_text_last = ''\n",
    "    bar = tqdm(range(epochs), desc=\"Epoch\", postfix=train_print)\n",
    "    for e in range(epochs):\n",
    "        if e < len(history['Train loss']):\n",
    "            if e > PATIENCE:\n",
    "                run[\"training/batch/loss_training\"].log(history['Train loss'][e])\n",
    "\n",
    "            if (e + 1) % print_every == 0:\n",
    "                print(f'epoch {e+1}/{epochs}, loss = {history[\"Train loss\"][e]:.4f}')\n",
    "                train_print = \"Train loss: {:.4f}\".format(history['Train loss'][e]) + ', ' + state_text_last\n",
    "                bar.postfix = train_print\n",
    "\n",
    "            if e + 1 != epochs:\n",
    "                bar.update()\n",
    "                \n",
    "            if callbacks:\n",
    "                for i in callbacks:\n",
    "                    i.step(False)\n",
    "            continue\n",
    "                \n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0\n",
    "\n",
    "        stop = False\n",
    "        \n",
    "        steps = 0\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model.forward(inp)\n",
    "            \n",
    "        loss = criterion(out)\n",
    "        if e > PATIENCE:\n",
    "            run[\"training/batch/loss_training\"].log(loss)\n",
    "\n",
    "        loss.backward()\n",
    "                \n",
    "        optimizer.step()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            running_loss = loss.item()\n",
    "        \n",
    "        if (e + 1) % print_every == 0:\n",
    "            print(f'epoch {e+1}/{epochs}, loss = {running_loss:.4f}')\n",
    "            train_print = \"Train loss: {:.4f}\".format(running_loss) + ', ' + state_text_last\n",
    "            bar.postfix = train_print\n",
    "            model.train()\n",
    "            \n",
    "        \n",
    "        history['Train loss'].append(running_loss)\n",
    "        \n",
    "        run_record[model_path]['history'] = history\n",
    "        \n",
    "        with open(f'{WORK_DIR}/history/{MODEL_NAME}_history.json', 'w') as fp:\n",
    "            json.dump(run_record, fp)\n",
    "        \n",
    "        if lr_scheduler:\n",
    "            if \"OneCycleLR\" in str(lr_scheduler):\n",
    "                lr_scheduler.step()\n",
    "            else:\n",
    "                lr_scheduler.step(running_loss)\n",
    "        \n",
    "        if callbacks:\n",
    "            for i in callbacks:\n",
    "                state_text, state = i.step()\n",
    "                if state_text:\n",
    "                    state_text_last = state_text\n",
    "                if state:\n",
    "                    stop = True\n",
    "        if stop:\n",
    "            train_print = \"Train loss: {:.4f}\".format(running_loss) + ', ' + state_text_last\n",
    "            bar.postfix = train_print\n",
    "            if callbacks:\n",
    "                for i in callbacks:\n",
    "                    i.stop()\n",
    "            model = None\n",
    "            inputs = None\n",
    "            targets = None\n",
    "            outputs = None\n",
    "            loss = None\n",
    "            sm = None\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            break\n",
    "            \n",
    "        if e + 1 != epochs:\n",
    "            bar.update()\n",
    "                        \n",
    "        inputs = None\n",
    "        targets = None\n",
    "        outputs = None\n",
    "        loss = None\n",
    "        sm = None\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "      \n",
    "    bar.update()\n",
    "    bar.close()\n",
    "    \n",
    "    if callbacks:\n",
    "        for i in callbacks:\n",
    "            i.stop()\n",
    "    \n",
    "    model = None\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "def plot_train_history(history):\n",
    "    \"\"\"Plot train history.\n",
    "    \n",
    "    Args:\n",
    "        history (dict): Dict of lists with train history..\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (FIGSIZE * 2, FIGSIZE))\n",
    "    \n",
    "    ax.plot(history['Train loss'], c = 'r')\n",
    "    ax.set_title('Loss')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend(['Train'])\n",
    "    ax.set_yscale('log')\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def dict2str(dict1):\n",
    "    out = str(dict1).replace(\"}\", \"\")\n",
    "    out = str(out).replace(\"{\", \"\")\n",
    "    out = str(out).replace(\"\\\"\", \"\")\n",
    "    out = str(out).replace(\"\\'\", \"\")\n",
    "    out = str(out).replace(\":\", \"\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical solution: flow between 2 parallel plates\n",
    "\n",
    "Velocity distribution has one non-zero component $v_3$ that depends on one coordinate $v_3 = v_3(x_1)$:\n",
    "\n",
    "\\begin{equation}\n",
    "    {v_3} = Ð¡_0\\frac{x_1^2}{2\\mu} + C_1x_1,\n",
    "\\end{equation}\n",
    "where $Ð¡_0 = {-12{\\mu}Q_3}/{(2R)^3}$, $Ð¡_1 = {6Q_3}/{(2R)^2}$, $Ð¡_0L_3 = {\\partial p}/{\\partial x_3}$, ${\\partial p}/{\\partial x_3}$ is the pressure drop along the axis of the cylinder.\n",
    "\n",
    "The flow rate trough the edges (surfaces $S_3^-$, $S_3^+$) is given and equal to:\n",
    "\n",
    "\\begin{equation}\n",
    "    {Q_3} = \\iint_{S_3} v_3 ,dx_1dx_2.\n",
    "\\end{equation}\n",
    "\n",
    "The power of external forces $Ext$ (equal to the power of internal forces $Int$) : \n",
    "\n",
    "\\begin{equation}\n",
    "    {Ext} = (p_1 - p_0)\\iint_{S_3} v_3 \\,dx_1\\,dx_2 =  \\frac{\\partial p}{\\partial x_3}L_3Q_3.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "Given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fluid viscosity: mu = 0.004,\n",
      "flow rate along x_3 axis: Q3 = 1e-05.\n"
     ]
    }
   ],
   "source": [
    "print(f'fluid viscosity: mu = {MU},')\n",
    "print(f'flow rate along x_3 axis: Q3 = {Qp[2]}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pressure drop along x_3 axis: dpdx3 = -243.75,\n",
      "maximum velocity: v3 = 0.23431597650051117,\n",
      "internal power: Int = 0.0024375,\n",
      "Reynolds number Re = 234.31597900390625 is smaller than critical Re < 1100: True\n",
      "Pipe length L_3 = 0.52 is longer than critical L_cr = 0.07498110830783844: True\n",
      "Pipe radius R = 0.002.\n"
     ]
    }
   ],
   "source": [
    "h = 2*R\n",
    "C0 = -12*MU*Qp[2]/(h**3*L[1])\n",
    "C1 = 6*Qp[2]/(h**2*L[1])\n",
    "psiex = C0*(X1N**3)*h**3/(6*MU) + C1*(X1N**2/2)*h**2\n",
    "v3a = C0*(X1N**2)*h**2/(2*MU) + C1*(X1N)*h\n",
    "v3amax = v3a.max() \n",
    "\n",
    "dpdx3a = C0*L[2]\n",
    "Int = - dpdx3a * Qp[2]\n",
    "\n",
    "Re = RHO*v3amax*h/MU\n",
    "Lcr = 0.16*R*Re\n",
    "\n",
    "print(f'pressure drop along x_3 axis: dpdx3 = {dpdx3a},')\n",
    "print(f'maximum velocity: v3 = {v3amax},')\n",
    "print(f'internal power: Int = {Int},')\n",
    "print(f'Reynolds number Re = {Re} is smaller than critical Re < {Re_cr}: {Re<Re_cr}')\n",
    "print(f'Pipe length L_3 = {L[2]} is longer than critical L_cr = {Lcr}: {L[2]>Lcr}')\n",
    "print(f'Pipe radius R = {R}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v3a.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning solution\n",
    "## Flow domain visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 32, 32]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nr=1\n",
    "nc=len(SIZE)\n",
    "\n",
    "plt.figure(figsize=(nc*FIGSIZE,nr*FIGSIZE))\n",
    "\n",
    "plt.subplot(nr,nc,1)\n",
    "plt.contourf(img[0,slices[0],:,:])#times zero in case of 2D flows\n",
    "plt.colorbar()\n",
    "\n",
    "plt.title('$x_1 = const$')\n",
    "\n",
    "plt.subplot(nr,nc,2)\n",
    "plt.contourf(img[0,:,slices[1],:])\n",
    "plt.colorbar()\n",
    "plt.title('$x_2 = const$')\n",
    "\n",
    "plt.subplot(nr,nc,3)\n",
    "plt.contourf(img[0,:,:,slices[2]])#times zero in case of 2D flows\n",
    "plt.colorbar()\n",
    "plt.title('$x_3 = const$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(1.))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.min(),img.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaVb_Ejsmynq"
   },
   "source": [
    "## Kinematic properties\n",
    "The flow rate through a cross-section $x_i = const$ can be expressed as follows:\n",
    "\n",
    "\\begin{equation} \n",
    "    \\label{eq:flowRate}\n",
    "    Q_i(x_i) = -\\epsilon_{ijk}(\\psi_j(x_i,x_k^+) - \\psi_j(x_i,x_k^-))l_j,\n",
    "\\end{equation}\n",
    "where $\\epsilon_{ijk}$ is the Levi-Civita symbol, $l_j = (x_j^+ - x_j^-)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\boldsymbol\\Psi$ on borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.000625, tensor([0.0000, 0.0006, 0.0000]), tensor([0, 0, 0]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psimm = torch.tensor([0, 0, 0])\n",
    "psipp = torch.tensor([0, Qp[2]/L[1], 0]) #similar to analytical solution for a pipe\n",
    "\n",
    "psi_norm = Qp[2]/L[1] # flow between 2 plates\n",
    "psi_norm, psipp, psimm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\boldsymbol\\Psi$ initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#psi1(x_2,x_3)\n",
    "psi1 = torch.linspace(psimm[0], psipp[0], SIZE[1], dtype=torch.float32)\n",
    "psi1 = torch.unsqueeze(psi1,1)\n",
    "psi1 = psi1.expand(-1,SIZE[2])\n",
    "\n",
    "#psi2(x_1,x_3)\n",
    "psi2 = torch.linspace(psimm[1], psipp[1], SIZE[0], dtype=torch.float32)\n",
    "psi2 = torch.unsqueeze(psi2,1)\n",
    "psi2 = psi2.expand(-1,SIZE[2])\n",
    "\n",
    "#psi3(x_1,x_2)\n",
    "psi3 = torch.linspace(psimm[2], psipp[2], SIZE[0], dtype=torch.float32)\n",
    "psi3 = torch.unsqueeze(psi3,1)\n",
    "psi3 = psi3.expand(-1,SIZE[1])\n",
    "\n",
    "psi = torch.unsqueeze(psi1.clone(),0) #[psi1, psi2, psi3]\n",
    "\n",
    "psi.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert $\\boldsymbol\\Psi$ into tensor 3 x 1 x SIZE[0] x SIZE[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 64])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#psi = torch.stack(psi)\n",
    "psi = torch.unsqueeze(psi,1)\n",
    "psi.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix constant values in NL first and last layers and set the boundary conditions (set flow rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1):\n",
    "#     print(i)\n",
    "#     psi[i,0,:NL,:]  = psimm[i]\n",
    "#     psi[i,0,-NL:,:] = psipp[i]\n",
    "psi[:,:,:NL,:]  = psimm[1]\n",
    "psi[:,:,-NL:,:] = psipp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 64])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "Gb4BFZNWnBsh",
    "outputId": "0dde0211-4908-4885-e6ac-4fc8f130ed54"
   },
   "outputs": [],
   "source": [
    "#flowVisualization(psi.permute(1,0,2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPeLHoR31p1D"
   },
   "source": [
    "## Create model\n",
    "Unet architecture [2] is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "PID82zl-cxN4"
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=1, init_features=4, use_bn=True):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\", use_bn=use_bn)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\", use_bn=use_bn)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\", use_bn=use_bn)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\", use_bn=use_bn)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\", use_bn=use_bn)\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(\n",
    "            features * 16, features * 8, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\", use_bn=use_bn)\n",
    "        self.upconv3 = nn.ConvTranspose2d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\", use_bn=use_bn)\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features * 4, features * 2, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\", use_bn=use_bn)\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features * 2, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\", use_bn=use_bn)\n",
    "        self.decoder0 = UNet._block(features, features, name=\"dec1\", use_bn=use_bn)\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        dec0 = self.decoder0(dec1)\n",
    "        return self.conv(dec0)*psi_norm #torch.tanh(self.conv(dec0))*psi_abs_limit #torch.sigmoid(self.conv(dec0))*psipp.max()\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name, use_bn):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    *[(name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                      (name + \"relu1\", nn.ReLU(inplace=True))][0 if use_bn else 1:],\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    *[(name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                      (name + \"relu2\", nn.ReLU(inplace=True))][0 if use_bn else 1:],\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_loss(psi):\n",
    "    \n",
    "    #Fix psi function on the boundaries\n",
    "    psi_masked = psi.clone()\n",
    "    psi_masked[:,:,:NL,:]  = psimm[1]\n",
    "    psi_masked[:,:,-NL:,:] = psipp[1]\n",
    "    \n",
    "    v1, v2, v3 = velocityDistr(psi_masked[0,0,:,:]*0, psi_masked[0,0,:,:], psi_masked[0,0,:,:]*0, DX1N, DX2N, DX3N, L[0], L[1], L[2])\n",
    "    \n",
    "    xi11, xi12, xi13, xi22, xi23, xi33, EtaEta = TksiDistr(v1, v2, v3, DX1N, DX2N, DX3N, L[0], L[1], L[2])\n",
    "    \n",
    "    #Subintegral expression with masks for fluid and walls, respectively:\n",
    "    subInt = ((0.5*Q0*EtaEta + ((Q1/(Z+1))*EtaEta**((Z+1)*0.5)))*img[0,:,slices[1],:] + \n",
    "              (0.5*Q0W*EtaEta + ((Q1W/(ZW+1))*EtaEta**((ZW+1)*0.5)))*(1-img[0,:,slices[1],:])) #+ REG_LOSS_COEF*(Qp[2] + psi_masked[0,0,-1,-1]*L[0] - psi_masked[1,0,-1,-1]*L[1])**2)\n",
    "  \n",
    "    #Integral\n",
    "    out = int_func_simpson_2d(subInt, DX1N, DX3N)*L[0]*L[1]*L[2]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0159), tensor(5.3238e-10))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DX2N, dOmega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhZutgNIyYhH"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparams: \n",
      " Epochs 30000, learning_rate 0.0001, scheduler none, scheduler_factor 0.5, scheduler_patience 1500, use_bn True, Early_stop_patience 30000, Decay 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543e9e5e55fb406c87e65090c31c8a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100/30000, loss = 537.6150\n",
      "epoch 200/30000, loss = 189.8463\n",
      "epoch 300/30000, loss = 103.3782\n",
      "epoch 400/30000, loss = 67.7253\n",
      "epoch 500/30000, loss = 49.2218\n",
      "epoch 600/30000, loss = 37.8022\n",
      "epoch 700/30000, loss = 30.1834\n",
      "epoch 800/30000, loss = 24.7775\n",
      "epoch 900/30000, loss = 20.7577\n",
      "epoch 1000/30000, loss = 17.7157\n",
      "epoch 1100/30000, loss = 15.3475\n",
      "epoch 1200/30000, loss = 13.4673\n",
      "epoch 1300/30000, loss = 11.9373\n",
      "epoch 1400/30000, loss = 10.6771\n",
      "epoch 1500/30000, loss = 9.6200\n",
      "epoch 1600/30000, loss = 8.7135\n",
      "epoch 1700/30000, loss = 7.9353\n",
      "epoch 1800/30000, loss = 7.2527\n",
      "epoch 1900/30000, loss = 6.6549\n",
      "epoch 2000/30000, loss = 6.1272\n",
      "epoch 2100/30000, loss = 5.6629\n",
      "epoch 2200/30000, loss = 5.2532\n",
      "epoch 2300/30000, loss = 4.8864\n",
      "epoch 2400/30000, loss = 4.5521\n",
      "epoch 2500/30000, loss = 4.2491\n",
      "epoch 2600/30000, loss = 3.9750\n",
      "epoch 2700/30000, loss = 3.7221\n",
      "epoch 2800/30000, loss = 3.4904\n",
      "epoch 2900/30000, loss = 3.2817\n",
      "epoch 3000/30000, loss = 3.0928\n",
      "epoch 3100/30000, loss = 2.9189\n",
      "epoch 3200/30000, loss = 2.7592\n",
      "epoch 3300/30000, loss = 2.6114\n",
      "epoch 3400/30000, loss = 2.4749\n",
      "epoch 3500/30000, loss = 2.3472\n",
      "epoch 3600/30000, loss = 2.2278\n",
      "epoch 3700/30000, loss = 2.1166\n",
      "epoch 3800/30000, loss = 2.0122\n",
      "epoch 3900/30000, loss = 1.9139\n",
      "epoch 4000/30000, loss = 1.8212\n",
      "epoch 4100/30000, loss = 1.7336\n",
      "epoch 4200/30000, loss = 1.6523\n",
      "epoch 4300/30000, loss = 1.5748\n",
      "epoch 4400/30000, loss = 1.5017\n",
      "epoch 4500/30000, loss = 1.4327\n",
      "epoch 4600/30000, loss = 1.3680\n",
      "epoch 4700/30000, loss = 1.3070\n",
      "epoch 4800/30000, loss = 1.2486\n",
      "epoch 4900/30000, loss = 1.1932\n",
      "epoch 5000/30000, loss = 1.1405\n",
      "epoch 5100/30000, loss = 1.0907\n",
      "epoch 5200/30000, loss = 1.0437\n",
      "epoch 5300/30000, loss = 0.9992\n",
      "epoch 5400/30000, loss = 0.9572\n",
      "epoch 5500/30000, loss = 0.9170\n",
      "epoch 5600/30000, loss = 0.8788\n",
      "epoch 5700/30000, loss = 0.8418\n",
      "epoch 5800/30000, loss = 0.8068\n",
      "epoch 5900/30000, loss = 0.7734\n",
      "epoch 6000/30000, loss = 0.7415\n",
      "epoch 6100/30000, loss = 0.7107\n",
      "epoch 6200/30000, loss = 0.6814\n",
      "epoch 6300/30000, loss = 0.6537\n",
      "epoch 6400/30000, loss = 0.6271\n",
      "epoch 6500/30000, loss = 0.6016\n",
      "epoch 6600/30000, loss = 0.5772\n",
      "epoch 6700/30000, loss = 0.5537\n",
      "epoch 6800/30000, loss = 0.5313\n",
      "epoch 6900/30000, loss = 0.5101\n",
      "epoch 7000/30000, loss = 0.4901\n",
      "epoch 7100/30000, loss = 0.4715\n",
      "epoch 7200/30000, loss = 0.4535\n",
      "epoch 7300/30000, loss = 0.4364\n",
      "epoch 7400/30000, loss = 0.4201\n",
      "epoch 7500/30000, loss = 0.4046\n",
      "epoch 7600/30000, loss = 0.3899\n",
      "epoch 7700/30000, loss = 0.3756\n",
      "epoch 7800/30000, loss = 0.3619\n",
      "epoch 7900/30000, loss = 0.3488\n",
      "epoch 8000/30000, loss = 0.3363\n",
      "epoch 8100/30000, loss = 0.3242\n",
      "epoch 8200/30000, loss = 0.3126\n",
      "epoch 8300/30000, loss = 0.3016\n",
      "epoch 8400/30000, loss = 0.2911\n",
      "epoch 8500/30000, loss = 0.2810\n",
      "epoch 8600/30000, loss = 0.2712\n",
      "epoch 8700/30000, loss = 0.2619\n",
      "epoch 8800/30000, loss = 0.2530\n",
      "epoch 8900/30000, loss = 0.2442\n",
      "epoch 9000/30000, loss = 0.2356\n",
      "epoch 9100/30000, loss = 0.2271\n",
      "epoch 9200/30000, loss = 0.2191\n",
      "epoch 9300/30000, loss = 0.2114\n",
      "epoch 9400/30000, loss = 0.2040\n",
      "epoch 9500/30000, loss = 0.1969\n",
      "epoch 9600/30000, loss = 0.1899\n",
      "epoch 9700/30000, loss = 0.1831\n",
      "epoch 9800/30000, loss = 0.1765\n",
      "epoch 9900/30000, loss = 0.1702\n",
      "epoch 10000/30000, loss = 0.1640\n",
      "epoch 10100/30000, loss = 0.1582\n",
      "epoch 10200/30000, loss = 0.1522\n",
      "epoch 10300/30000, loss = 0.1464\n",
      "epoch 10400/30000, loss = 0.1408\n",
      "epoch 10500/30000, loss = 0.1353\n",
      "epoch 10600/30000, loss = 0.1301\n",
      "epoch 10700/30000, loss = 0.1249\n",
      "epoch 10800/30000, loss = 0.1200\n",
      "epoch 10900/30000, loss = 0.1152\n",
      "epoch 11000/30000, loss = 0.1106\n",
      "epoch 11100/30000, loss = 0.1060\n",
      "epoch 11200/30000, loss = 0.1016\n",
      "epoch 11300/30000, loss = 0.0974\n",
      "epoch 11400/30000, loss = 0.0934\n",
      "epoch 11500/30000, loss = 0.0896\n",
      "epoch 11600/30000, loss = 0.0860\n",
      "epoch 11700/30000, loss = 6566.6382\n",
      "epoch 11800/30000, loss = 2166.7300\n",
      "epoch 11900/30000, loss = 1305.2964\n",
      "epoch 12000/30000, loss = 953.3411\n",
      "epoch 12100/30000, loss = 749.0955\n",
      "epoch 12200/30000, loss = 607.1776\n",
      "epoch 12300/30000, loss = 503.9492\n",
      "epoch 12400/30000, loss = 426.5549\n",
      "epoch 12500/30000, loss = 367.6355\n",
      "epoch 12600/30000, loss = 323.5560\n",
      "epoch 12700/30000, loss = 288.1398\n",
      "epoch 12800/30000, loss = 257.6643\n",
      "epoch 12900/30000, loss = 234.3265\n",
      "epoch 13000/30000, loss = 214.7418\n",
      "epoch 13100/30000, loss = 197.8175\n",
      "epoch 13200/30000, loss = 181.4971\n",
      "epoch 13300/30000, loss = 167.0917\n",
      "epoch 13400/30000, loss = 154.4660\n",
      "epoch 13500/30000, loss = 143.4707\n",
      "epoch 13600/30000, loss = 134.0403\n",
      "epoch 13700/30000, loss = 125.2257\n",
      "epoch 13800/30000, loss = 117.1906\n",
      "epoch 13900/30000, loss = 109.8159\n",
      "epoch 14000/30000, loss = 103.4186\n",
      "epoch 14100/30000, loss = 97.7633\n",
      "epoch 14200/30000, loss = 92.7001\n",
      "epoch 14300/30000, loss = 88.0732\n",
      "epoch 14400/30000, loss = 83.7751\n",
      "epoch 14500/30000, loss = 79.6726\n",
      "epoch 14600/30000, loss = 75.7457\n",
      "epoch 14700/30000, loss = 72.0387\n",
      "epoch 14800/30000, loss = 68.5035\n",
      "epoch 14900/30000, loss = 64.8508\n",
      "epoch 15000/30000, loss = 61.1834\n",
      "epoch 15100/30000, loss = 57.7290\n",
      "epoch 15200/30000, loss = 54.3825\n",
      "epoch 15300/30000, loss = 51.2450\n",
      "epoch 15400/30000, loss = 48.2519\n",
      "epoch 15500/30000, loss = 45.4859\n",
      "epoch 15600/30000, loss = 42.8300\n",
      "epoch 15700/30000, loss = 40.2209\n",
      "epoch 15800/30000, loss = 37.6435\n",
      "epoch 15900/30000, loss = 35.0735\n",
      "epoch 16000/30000, loss = 32.6902\n",
      "epoch 16100/30000, loss = 30.5732\n",
      "epoch 16200/30000, loss = 28.6599\n",
      "epoch 16300/30000, loss = 26.9111\n",
      "epoch 16400/30000, loss = 25.2933\n",
      "epoch 16500/30000, loss = 23.7841\n",
      "epoch 16600/30000, loss = 22.3308\n",
      "epoch 16700/30000, loss = 20.9761\n",
      "epoch 16800/30000, loss = 19.6979\n",
      "epoch 16900/30000, loss = 18.5348\n",
      "epoch 17000/30000, loss = 17.3952\n",
      "epoch 17100/30000, loss = 16.2628\n",
      "epoch 17200/30000, loss = 15.2217\n",
      "epoch 17300/30000, loss = 14.2367\n",
      "epoch 17400/30000, loss = 13.3328\n",
      "epoch 17500/30000, loss = 12.4872\n",
      "epoch 17600/30000, loss = 11.6868\n",
      "epoch 17700/30000, loss = 10.9574\n",
      "epoch 17800/30000, loss = 10.2793\n",
      "epoch 17900/30000, loss = 9.6069\n",
      "epoch 18000/30000, loss = 8.9155\n",
      "epoch 18100/30000, loss = 8.2941\n",
      "epoch 18200/30000, loss = 7.7143\n",
      "epoch 18300/30000, loss = 7.1899\n",
      "epoch 18400/30000, loss = 6.7062\n",
      "epoch 18500/30000, loss = 6.2339\n",
      "epoch 18600/30000, loss = 5.8000\n",
      "epoch 18700/30000, loss = 5.4181\n",
      "epoch 18800/30000, loss = 5.0699\n",
      "epoch 18900/30000, loss = 4.7450\n",
      "epoch 19000/30000, loss = 4.4411\n",
      "epoch 19100/30000, loss = 4.1523\n",
      "epoch 19200/30000, loss = 3.8821\n",
      "epoch 19300/30000, loss = 3.6323\n",
      "epoch 19400/30000, loss = 3.4064\n",
      "epoch 19500/30000, loss = 3.1989\n",
      "epoch 19600/30000, loss = 3.0078\n",
      "epoch 19700/30000, loss = 2.8271\n",
      "epoch 19800/30000, loss = 2.6564\n",
      "epoch 19900/30000, loss = 2.4955\n",
      "epoch 20000/30000, loss = 2.3472\n",
      "epoch 20100/30000, loss = 2.2102\n",
      "epoch 20200/30000, loss = 2.0833\n",
      "epoch 20300/30000, loss = 1.9672\n",
      "epoch 20400/30000, loss = 1.8584\n",
      "epoch 20500/30000, loss = 1.7557\n",
      "epoch 20600/30000, loss = 1.6571\n",
      "epoch 20700/30000, loss = 1.5641\n",
      "epoch 20800/30000, loss = 1.4767\n",
      "epoch 20900/30000, loss = 1.3924\n",
      "epoch 21000/30000, loss = 1.3122\n",
      "epoch 21100/30000, loss = 1.2377\n",
      "epoch 21200/30000, loss = 1.1681\n",
      "epoch 21300/30000, loss = 1.1027\n",
      "epoch 21400/30000, loss = 1.0397\n",
      "epoch 21500/30000, loss = 0.9792\n",
      "epoch 21600/30000, loss = 0.9205\n",
      "epoch 21700/30000, loss = 0.8632\n",
      "epoch 21800/30000, loss = 0.8100\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(WORK_DIR + '/models', exist_ok=True)\n",
    "os.makedirs(WORK_DIR + '/history', exist_ok=True)\n",
    "\n",
    "x = psi\n",
    "\n",
    "# ÐŸÐµÑ€ÐµÐ¼ÐµÑ‰ÐµÐ½Ð¸Ðµ Ð½Ð° GPU\n",
    "x = x.to(DEVICE)\n",
    "dOmega = dOmega.to(DEVICE)\n",
    "\n",
    "psimm = psimm.to(DEVICE)\n",
    "psipp = psipp.to(DEVICE)\n",
    "\n",
    "img = img.to(DEVICE)\n",
    "\n",
    "DX1N = DX1N.to(DEVICE)\n",
    "DX2N = DX2N.to(DEVICE)\n",
    "DX3N = DX3N.to(DEVICE)\n",
    "\n",
    "if CONTINUE:\n",
    "    with open(f'{WORK_DIR}/history/{MODEL_NAME}_history.json', 'r') as fp:\n",
    "        run_record = json.load(fp)\n",
    "else:\n",
    "    run_record = {}\n",
    "\n",
    "for hyp in HYPS:\n",
    "    print('hyperparams: \\n', dict2str(hyp)) \n",
    "    \n",
    "    model_path = (f'{WORK_DIR}/models/{MODEL_NAME}_{dict2str(hyp)}.pth')\n",
    "\n",
    "    if model_path in run_record:\n",
    "        if 'final_val_metric' in run_record[model_path]:\n",
    "            continue\n",
    "    else:\n",
    "        run_record[model_path] = {'hyperparams': hyp}\n",
    "            \n",
    "    callbacks = [SaveBest(f'Train loss', model_path, 'min'),\n",
    "                 EarlyStop(f'Train loss', EARLY_STOP_PATIENCE, 'min')]\n",
    "\n",
    "    model = UNet(in_channels=IN_CH, out_channels=OUT_CH, init_features=NoOfFeatures, use_bn=hyp[\"use_bn\"])\n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "    # Train the saved model\n",
    "    if CONTINUE == True or START_WITH_SAVED == True:\n",
    "        model.load_state_dict(torch.load(f'{WORK_DIR}/models/{MODEL_NAME}_best.pth'))\n",
    "    \n",
    "    if 'history' in run_record[model_path]:\n",
    "        model.load_state_dict(torch.load(model_path))    \n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=hyp[\"learning_rate\"], weight_decay=DECAY)\n",
    "    \n",
    "    criterion = power_loss\n",
    "    \n",
    "    #Log model, criterion, and optimizer\n",
    "    run[\"config/model\"] = type(model).__name__\n",
    "    run[\"config/criterion\"] = type(criterion).__name__\n",
    "    run[\"config/optimizer\"] = type(optimizer).__name__\n",
    "\n",
    "    \n",
    "    if hyp[\"scheduler\"] == \"step\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "                                                                  patience=hyp[\"scheduler_patience\"],\n",
    "                                                                  min_lr=1e-6, factor=hyp[\"scheduler_factor\"])\n",
    "    elif hyp[\"scheduler\"] == \"cycle\":\n",
    "        lr_scheduler = scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hyp[\"learning_rate\"] * 20,\n",
    "                                                                       steps_per_epoch=1, epochs=EPOCHS,\n",
    "                                                                       pct_start=0.125,\n",
    "                                                                       div_factor=hyp[\"scheduler_factor\"] ** -1,\n",
    "                                                                       final_div_factor=(hyp[\"scheduler_factor\"] ** -1) * 50)\n",
    "    else:\n",
    "        lr_scheduler = None\n",
    "    \n",
    "    history = train(model, x, optimizer, power_loss,\n",
    "                    epochs=EPOCHS, print_every=100,\n",
    "                    callbacks=callbacks, lr_scheduler=lr_scheduler, run_record=run_record, model_path=model_path)\n",
    "\n",
    "    run_record[model_path] = {'hyperparams': hyp,\n",
    "                              'history': history,\n",
    "                              'final_val_metric': callbacks[1].best_monitor}\n",
    "    \n",
    "    with open(f'{WORK_DIR}/history/{MODEL_NAME}_history.json', 'w') as fp:\n",
    "        json.dump(run_record, fp)\n",
    "\n",
    "    print(f\"Best Train loss %4.4f\" % (callbacks[1].best_monitor))\n",
    "\n",
    "    model = None\n",
    "    optimizer = None\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "best_val_metric = None\n",
    "best_hyperparams = None\n",
    "best_run = None\n",
    "best_model_path = None\n",
    "\n",
    "for key, train_info in run_record.items():\n",
    "    if best_val_metric is None or best_val_metric > train_info['final_val_metric']:\n",
    "        best_val_metric = train_info['final_val_metric']\n",
    "        best_hyperparams = train_info['hyperparams']\n",
    "        best_run = train_info\n",
    "        best_model_path = key\n",
    "\n",
    "with open(f'{WORK_DIR}/history/{MODEL_NAME}_history.json', 'w') as fp:\n",
    "    json.dump(run_record, fp)\n",
    "\n",
    "best_hyp = str(best_hyperparams).replace(\"}\", \"\")\n",
    "best_hyp = best_hyp.replace(\"{\", \"\")\n",
    "best_hyp = best_hyp.replace(\"'\", \"\")\n",
    "\n",
    "print(f\"Best Train loss: %4.4f, best hyperparams: %s\" % (best_val_metric, best_hyp))\n",
    "\n",
    "model = UNet(in_channels=IN_CH, out_channels=OUT_CH, init_features=NoOfFeatures, use_bn=best_hyperparams[\"use_bn\"])\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "torch.save(model.state_dict(), f'{WORK_DIR}/models/{MODEL_NAME}_best.pth')\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "psi = model.forward(x)\n",
    "\n",
    "plot_train_history(best_run['history'])\n",
    "\n",
    "simulation_time = time.time() - start_time\n",
    "print(f'Final loss: {power_loss(psi).cpu().item() :.3f}')\n",
    "print('simulation time:{:.0f}m {:.0f}s'.format(\n",
    "      simulation_time // 60, simulation_time % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhZutgNIyYhH"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet(in_channels=IN_CH, out_channels=OUT_CH, init_features=NoOfFeatures, use_bn=best_hyperparams[\"use_bn\"])\n",
    "# model.load_state_dict(torch.load(best_model_path))\n",
    "# model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix psi function on the boundaries\n",
    "psi_masked = psi.clone().detach()\n",
    "psi_masked[:,:,:NL,:]  = psimm[1].to('cpu')\n",
    "psi_masked[:,:,-NL:,:] = psipp[1].to('cpu')\n",
    "    \n",
    "\n",
    "v1, v2, v3 = velocityDistr(psi_masked[0,0,:,:]*0, psi_masked[0,0,:,:], psi_masked[0,0,:,:]*0, DX1N, DX2N, DX3N, L[0], L[1], L[2])\n",
    "\n",
    "#dv1dx1, dv2dx2, dv3dx3, divV  = divVel(v1, v2, v3, DX1N, DX2N, DX3N, L[0], L[1], L[2])\n",
    "\n",
    "#V = torch.stack([v1,v2,v3])\n",
    "#Vabs = torch.sqrt(v1**2 + v2**2 + v3**2)\n",
    "xi11, xi12, xi13, xi22, xi23, xi33, EtaEta = TksiDistr(v1, v2, v3, DX1N, DX2N, DX3N, L[0], L[1], L[2])\n",
    "\n",
    "#Subintegral expression with masks for fluid and walls, respectively:\n",
    "subInt = ((0.5*Q0*EtaEta + ((Q1/(Z+1))*EtaEta**((Z+1)*0.5)))*img[0,:,slices[1],:].to(DEVICE) +\n",
    "          (0.5*Q0W*EtaEta + ((Q1W/(ZW+1))*EtaEta**((ZW+1)*0.5)))*(1-img[0,:,slices[1],:].to(DEVICE))) \n",
    "#Integral\n",
    "out = int_func_simpson_2d(subInt, DX1N, DX3N)*L[0]*L[1]*L[2]\n",
    "    \n",
    "print(f'internal power: Int = {out},')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{EtaEta.min()} < Eta < {EtaEta.max()}, mean value {EtaEta.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowVisualization(psi_masked.permute(1,0,2,3),step=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(v3.cpu().detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum velocity value in a slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3max = v3[:, slices[2]].max()\n",
    "v3max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean velocity in the flow domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.meshgrid(np.arange(0, SIZE[0], STEP3D),\n",
    "                np.arange(0, SIZE[1], STEP3D),\n",
    "                np.arange(0, SIZE[2], STEP3D))\n",
    "v_all = torch.stack((v1.cpu() * img[0].cpu(), v2.cpu() * img[0].cpu(), v3.cpu() * img[0].cpu()), 3)\n",
    "v_abs = torch.sqrt(v_all[:, :, :, 0]**2 + v_all[:, :, :, 1]**2 + v_all[:, :, :, 2]**2)\n",
    "print(v_all.size())\n",
    "vector_plot_3d(x, v_all.cpu().detach().rot90(), v_abs.rot90(), figSize=FIGSIZE*4, step = STEP3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1A, X2A = torch.meshgrid(X1N, X2N)\n",
    "fig, ax = plt.subplots(figsize=(FIGSIZE*2, FIGSIZE*2),subplot_kw={\"projection\": \"3d\"})\n",
    "surf = ax.plot_surface(np.array(X1A),np.array(X2A), np.array(v3[:,:].to('cpu')), cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "plt.title('$v_3$ $(x_1,x_2,x_3=const)$')\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'Loss':out,\n",
    "          \n",
    "           }\n",
    "run[\"config/results\"] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpGo7xQz6cny"
   },
   "source": [
    "# Links\n",
    "\n",
    "[1]. https://github.com/Mechanics-Mechatronics-and-Robotics/Mathematical_modelling/blob/main/Practice_1_by_IStebakov.ipynb\n",
    "\n",
    "[2]. https://github.com/mateuszbuda/brain-segmentation-pytorch"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
